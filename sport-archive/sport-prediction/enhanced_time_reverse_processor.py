#!/usr/bin/env python3
"""
üïí FORD√çTOTT ID≈êRENDI PDF FELDOLGOZ√ì
========================================

C√©lja: A legfrissebb PDF-ekt≈ël visszafel√© haladva feldolgozni az arch√≠vumot
- J√∂v≈ëbeli meccsek kinyer√©se (holnapi meccsek list√°ja)
- T√∂rt√©nelmi adatok ment√©se
- Id≈ërendi sorrend: 2025.06.27 ‚Üí 2019

K√©sz√≠tette: Sport Prediction System
D√°tum: 2025-06-28
"""

import os
import sys
import json
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
import glob

# Saj√°t modulok import√°l√°sa
sys.path.append('/home/bandi/Documents/code/2025/sport-prediction')
from szerencsemix_football_extractor import SzerencseMixFootballExtractor

class TimeReverseProcessor:
    def __init__(self):
        self.base_dir = Path('/home/bandi/Documents/code/2025/sport-prediction')
        self.archive_dir = self.base_dir / 'data' / 'szerencsemix_archive' / 'organized'
        self.db_path = self.base_dir / 'data' / 'football_database.db'
        self.extractor = SzerencseMixFootballExtractor()

        # St√°tusz k√∂vet√©s
        self.stats = {
            'processed_files': 0,
            'successful_extractions': 0,
            'failed_extractions': 0,
            'future_matches_found': 0,
            'historical_matches_found': 0,
            'processing_start': datetime.now(),
            'errors': []
        }

        print("üïí FORD√çTOTT ID≈êRENDI FELDOLGOZ√ì")
        print("="*50)
        print(f"üìÅ Arch√≠vum: {self.archive_dir}")
        print(f"üóÑÔ∏è Adatb√°zis: {self.db_path}")
        print()

    def get_all_pdfs_time_sorted(self):
        """
        √ñsszes PDF f√°jl lek√©r√©se ford√≠tott id≈ërendi sorrendben
        Returns: List[tuple] - (pdf_path, extracted_date)
        """
        pdf_files = []

        print("üìä PDF f√°jlok felt√©rk√©pez√©se...")

        # V√©gigmegy√ºnk az √©veken (ford√≠tott sorrendben)
        years = sorted([d for d in self.archive_dir.iterdir() if d.is_dir()], reverse=True)

        for year_dir in years:
            year = year_dir.name
            print(f"  üìÖ {year} feldolgoz√°sa...")

            # H√≥napok (ford√≠tott sorrendben)
            months = sorted([d for d in year_dir.iterdir() if d.is_dir()], reverse=True)

            for month_dir in months:
                month = month_dir.name

                # PDF f√°jlok a h√≥napban
                pdf_pattern = month_dir / "*.pdf"
                month_pdfs = glob.glob(str(pdf_pattern))

                for pdf_path in month_pdfs:
                    # D√°tum kinyer√©se a f√°jln√©vb≈ël
                    filename = Path(pdf_path).name
                    try:
                        # P√©lda: Web__51sz__P__06-27_2025.06.27.pdf
                        if '_2025.' in filename:
                            date_part = filename.split('_2025.')[1].replace('.pdf', '')
                            extracted_date = datetime.strptime(f"2025.{date_part}", "%Y.%m.%d")
                        elif '_2024.' in filename:
                            date_part = filename.split('_2024.')[1].replace('.pdf', '')
                            extracted_date = datetime.strptime(f"2024.{date_part}", "%Y.%m.%d")
                        elif '_2023.' in filename:
                            date_part = filename.split('_2023.')[1].replace('.pdf', '')
                            extracted_date = datetime.strptime(f"2023.{date_part}", "%Y.%m.%d")
                        elif '_2022.' in filename:
                            date_part = filename.split('_2022.')[1].replace('.pdf', '')
                            extracted_date = datetime.strptime(f"2022.{date_part}", "%Y.%m.%d")
                        elif '_2021.' in filename:
                            date_part = filename.split('_2021.')[1].replace('.pdf', '')
                            extracted_date = datetime.strptime(f"2021.{date_part}", "%Y.%m.%d")
                        elif '_2020.' in filename:
                            date_part = filename.split('_2020.')[1].replace('.pdf', '')
                            extracted_date = datetime.strptime(f"2020.{date_part}", "%Y.%m.%d")
                        elif '_2019.' in filename:
                            date_part = filename.split('_2019.')[1].replace('.pdf', '')
                            extracted_date = datetime.strptime(f"2019.{date_part}", "%Y.%m.%d")
                        else:
                            print(f"    ‚ö†Ô∏è Ismeretlen d√°tum form√°tum: {filename}")
                            continue

                        pdf_files.append((pdf_path, extracted_date))

                    except Exception as e:
                        print(f"    ‚ùå Hiba a d√°tum feldolgoz√°s√°ban ({filename}): {e}")
                        continue

        # Id≈ërendi rendez√©s (legfrissebb el≈ësz√∂r)
        pdf_files.sort(key=lambda x: x[1], reverse=True)

        print(f"üìÅ √ñsszesen {len(pdf_files)} PDF f√°jl tal√°lhat√≥.")
        print()

        return pdf_files

    def process_pdf_for_future_matches(self, pdf_path, pdf_date):
        """
        Egy PDF feldolgoz√°sa j√∂v≈ëbeli meccsek keres√©s√©re
        """
        try:
            print(f"  ‚ö° {Path(pdf_path).name} feldolgoz√°sa...")

            # PDF feldolgoz√°s
            result = self.extractor.extract_matches(pdf_path)

            if not result.get('success', False):
                print(f"    ‚ùå Sikertelen feldolgoz√°s: {result.get('error', 'Ismeretlen hiba')}")
                self.stats['failed_extractions'] += 1
                return None

            matches = result.get('matches', [])
            if not matches:
                print(f"    ‚ö†Ô∏è Nincs meccs tal√°lat")
                self.stats['failed_extractions'] += 1
                return None

            print(f"    ‚úÖ {len(matches)} meccs tal√°lat")
            self.stats['successful_extractions'] += 1

            # J√∂v≈ëbeli vs t√∂rt√©nelmi meccsek sz√©tv√°laszt√°sa
            today = datetime.now().date()
            future_matches = []
            historical_matches = []

            for match in matches:
                match_date_str = match.get('date', '')
                try:
                    match_date = datetime.strptime(match_date_str, '%Y-%m-%d').date()

                    if match_date > today:
                        future_matches.append(match)
                        self.stats['future_matches_found'] += 1
                    else:
                        historical_matches.append(match)
                        self.stats['historical_matches_found'] += 1

                except ValueError:
                    print(f"    ‚ö†Ô∏è Hib√°s d√°tum form√°tum: {match_date_str}")
                    continue

            return {
                'pdf_path': pdf_path,
                'pdf_date': pdf_date,
                'total_matches': len(matches),
                'future_matches': future_matches,
                'historical_matches': historical_matches,
                'extraction_success': True
            }

        except Exception as e:
            print(f"    ‚ùå Hiba a feldolgoz√°s sor√°n: {e}")
            self.stats['errors'].append(f"{Path(pdf_path).name}: {e}")
            self.stats['failed_extractions'] += 1
            return None

    def get_tomorrows_matches(self, limit_pdfs=10):
        """
        Holnapi meccsek list√°j√°nak l√©trehoz√°sa
        """
        tomorrow = (datetime.now() + timedelta(days=1)).date()
        print(f"üîç HOLNAPI MECCSEK KERES√âSE ({tomorrow})")
        print("="*50)

        pdf_files = self.get_all_pdfs_time_sorted()
        tomorrows_matches = []
        processed_count = 0

        for pdf_path, pdf_date in pdf_files:
            if processed_count >= limit_pdfs:
                print(f"‚èπÔ∏è El√©rte a limit-et: {limit_pdfs} PDF")
                break

            result = self.process_pdf_for_future_matches(pdf_path, pdf_date)
            processed_count += 1
            self.stats['processed_files'] += 1

            if result and result['future_matches']:
                for match in result['future_matches']:
                    match_date_str = match.get('date', '')
                    try:
                        match_date = datetime.strptime(match_date_str, '%Y-%m-%d').date()
                        if match_date == tomorrow:
                            tomorrows_matches.append({
                                'date': match_date_str,
                                'time': match.get('time', 'N/A'),
                                'home_team': match.get('home_team', 'N/A'),
                                'away_team': match.get('away_team', 'N/A'),
                                'league': match.get('league', 'N/A'),
                                'odds': match.get('odds', {}),
                                'source_pdf': Path(pdf_path).name,
                                'confidence': match.get('confidence', 0.0)
                            })
                    except ValueError:
                        continue

        # Eredm√©nyek
        print()
        print(f"üèÜ HOLNAPI MECCSEK EREDM√âNYE")
        print("="*40)
        print(f"üìÖ Holnap d√°tuma: {tomorrow}")
        print(f"‚öΩ Tal√°lat: {len(tomorrows_matches)} meccs")

        if tomorrows_matches:
            print()
            print("üìã HOLNAPI MECCSEK LIST√ÅJA:")
            print("-" * 60)
            for i, match in enumerate(tomorrows_matches, 1):
                print(f"{i:2d}. {match['time']:>5} | {match['home_team']:<20} vs {match['away_team']:<20}")
                print(f"     Liga: {match['league']} | Bizonyoss√°g: {match['confidence']:.2f}")
                print(f"     Forr√°s: {match['source_pdf']}")
                if match['odds']:
                    odds_str = " | ".join([f"{k}: {v}" for k, v in match['odds'].items()])
                    print(f"     Szorz√≥k: {odds_str}")
                print()
        else:
            print("‚ùå Nincs holnapi meccs tal√°lat")

        return tomorrows_matches

    def save_historical_data_sample(self, limit_pdfs=20):
        """
        T√∂rt√©nelmi adatok mint√°ja ment√©se
        """
        print(f"üìä T√ñRT√âNELMI ADATOK MINTAV√âTELE")
        print("="*50)

        pdf_files = self.get_all_pdfs_time_sorted()
        all_historical = []
        processed_count = 0

        for pdf_path, pdf_date in pdf_files:
            if processed_count >= limit_pdfs:
                print(f"‚èπÔ∏è El√©rte a limit-et: {limit_pdfs} PDF")
                break

            result = self.process_pdf_for_future_matches(pdf_path, pdf_date)
            processed_count += 1

            if result and result['historical_matches']:
                all_historical.extend(result['historical_matches'])

        # Eredm√©nyek ment√©se JSON f√°jlba
        output_file = self.base_dir / 'data' / 'historical_sample.json'

        sample_data = {
            'extraction_date': datetime.now().isoformat(),
            'processed_pdfs': processed_count,
            'total_historical_matches': len(all_historical),
            'matches': all_historical[:100]  # Els≈ë 100 meccs
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(sample_data, f, indent=2, ensure_ascii=False)

        print(f"üíæ T√∂rt√©nelmi adatok mentve: {output_file}")
        print(f"üìä √ñsszesen {len(all_historical)} t√∂rt√©nelmi meccs feldolgozva")
        print(f"üìÑ JSON f√°jlban az els≈ë 100 meccs r√©szletei")

        return all_historical

    def print_processing_summary(self):
        """
        Feldolgoz√°si √∂sszes√≠t≈ë ki√≠r√°sa
        """
        processing_time = datetime.now() - self.stats['processing_start']

        print()
        print("üìã FELDOLGOZ√ÅSI √ñSSZES√çT≈ê")
        print("="*50)
        print(f"‚è±Ô∏è Feldolgoz√°si id≈ë: {processing_time}")
        print(f"üìÅ Feldolgozott PDF-ek: {self.stats['processed_files']}")
        print(f"‚úÖ Sikeres kinyer√©sek: {self.stats['successful_extractions']}")
        print(f"‚ùå Sikertelen kinyer√©sek: {self.stats['failed_extractions']}")
        print(f"üîÆ J√∂v≈ëbeli meccsek: {self.stats['future_matches_found']}")
        print(f"üìö T√∂rt√©nelmi meccsek: {self.stats['historical_matches_found']}")

        if self.stats['errors']:
            print()
            print("‚ö†Ô∏è HIB√ÅK:")
            for error in self.stats['errors'][:5]:  # Els≈ë 5 hiba
                print(f"  - {error}")
            if len(self.stats['errors']) > 5:
                print(f"  ... √©s m√©g {len(self.stats['errors']) - 5} hiba")

def main():
    """
    F≈ë feldolgoz√°si folyamat
    """
    processor = TimeReverseProcessor()

    try:
        # 1. Holnapi meccsek keres√©se
        tomorrows_matches = processor.get_tomorrows_matches(limit_pdfs=15)

        # 2. T√∂rt√©nelmi adatok mintav√©tele
        historical_sample = processor.save_historical_data_sample(limit_pdfs=25)

        # 3. √ñsszes√≠t≈ë
        processor.print_processing_summary()

        # 4. Holnapi meccsek JSON ment√©se
        if tomorrows_matches:
            tomorrow_file = processor.base_dir / 'data' / 'tomorrows_matches.json'
            with open(tomorrow_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'date': (datetime.now() + timedelta(days=1)).date().isoformat(),
                    'extraction_time': datetime.now().isoformat(),
                    'matches_count': len(tomorrows_matches),
                    'matches': tomorrows_matches
                }, f, indent=2, ensure_ascii=False)
            print(f"üíæ Holnapi meccsek mentve: {tomorrow_file}")

        print()
        print("üèÅ FELDOLGOZ√ÅS BEFEJEZVE!")

    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Feldolgoz√°s megszak√≠tva!")
        processor.print_processing_summary()
    except Exception as e:
        print(f"\n‚ùå Kritikus hiba: {e}")
        processor.print_processing_summary()

if __name__ == "__main__":
    main()
