#!/usr/bin/env python3
"""
üïí EGYSZER≈∞ FORD√çTOTT ID≈êRENDI PDF FELDOLGOZ√ì
==============================================

C√©lja: A legfrissebb PDF-ekt≈ël visszafel√© haladva feldolgozni az arch√≠vumot
- J√∂v≈ëbeli meccsek kinyer√©se (holnapi meccsek list√°ja)
- T√∂rt√©nelmi adatok ment√©se
- Id≈ërendi sorrend: 2025.06.27 ‚Üí 2019

K√©sz√≠tette: Sport Prediction System
D√°tum: 2025-06-28
"""

import os
import sys
import json
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
import glob

# Saj√°t modulok import√°l√°sa
sys.path.append('/home/bandi/Documents/code/2025/sport-prediction')
from real_pdf_processor import RealPdfProcessor

class SimpleTimeReverseProcessor:
    def __init__(self):
        self.base_dir = Path('/home/bandi/Documents/code/2025/sport-prediction')
        self.archive_dir = self.base_dir / 'data' / 'szerencsemix_archive' / 'organized'
        self.db_path = self.base_dir / 'data' / 'football_database.db'
        self.processor = RealPdfProcessor()

        # St√°tusz k√∂vet√©s
        self.stats = {
            'processed_files': 0,
            'successful_extractions': 0,
            'failed_extractions': 0,
            'future_matches_found': 0,
            'historical_matches_found': 0,
            'processing_start': datetime.now(),
            'errors': []
        }

        print("üïí EGYSZER≈∞ FORD√çTOTT ID≈êRENDI FELDOLGOZ√ì")
        print("="*55)
        print(f"üìÅ Arch√≠vum: {self.archive_dir}")
        print(f"üóÑÔ∏è Adatb√°zis: {self.db_path}")
        print()

    def get_recent_pdfs_sorted(self, limit=20):
        """
        Legfrissebb PDF f√°jlok lek√©r√©se ford√≠tott id≈ërendi sorrendben
        """
        pdf_files = []

        print("üìä PDF f√°jlok felt√©rk√©pez√©se...")

        # 2025-√∂s f√°jlok keres√©se (legfrissebb el≈ësz√∂r)
        year_2025 = self.archive_dir / '2025'
        if year_2025.exists():
            months = sorted([d for d in year_2025.iterdir() if d.is_dir()], reverse=True)
            for month_dir in months:
                pdf_pattern = month_dir / "*.pdf"
                month_pdfs = sorted(glob.glob(str(pdf_pattern)), reverse=True)

                for pdf_path in month_pdfs:
                    filename = Path(pdf_path).name
                    try:
                        # D√°tum kinyer√©se a f√°jln√©vb≈ël
                        if '_2025.' in filename:
                            date_part = filename.split('_2025.')[1].replace('.pdf', '')
                            extracted_date = datetime.strptime(f"2025.{date_part}", "%Y.%m.%d")
                            pdf_files.append((pdf_path, extracted_date))
                    except Exception as e:
                        print(f"    ‚ö†Ô∏è D√°tum hiba ({filename}): {e}")
                        continue

        # Id≈ërendi rendez√©s (legfrissebb el≈ësz√∂r)
        pdf_files.sort(key=lambda x: x[1], reverse=True)

        # Limit√°l√°s
        if limit:
            pdf_files = pdf_files[:limit]

        print(f"üìÅ {len(pdf_files)} legfrissebb PDF f√°jl kiv√°lasztva.")
        print()

        return pdf_files

    def process_single_pdf(self, pdf_path, pdf_date):
        """
        Egy PDF feldolgoz√°sa
        """
        try:
            print(f"  ‚ö° {Path(pdf_path).name} feldolgoz√°sa...")

            # PDF sz√∂veg kinyer√©se
            text = self.processor.extract_text_with_pdftotext(Path(pdf_path))

            if not text:
                print(f"    ‚ùå Sz√∂veg kinyer√©s sikertelen")
                self.stats['failed_extractions'] += 1
                return None

            # Meccsek felismer√©se
            pdf_date_str = pdf_date.strftime('%Y-%m-%d')
            matches_result = self.processor.parse_matches_from_text(text, pdf_date_str)

            if not matches_result:
                print(f"    ‚ö†Ô∏è Nincs meccs tal√°lat")
                self.stats['failed_extractions'] += 1
                return None

            future_matches = matches_result.get('future_matches', [])
            historical_matches = matches_result.get('historical_matches', [])

            total_matches = len(future_matches) + len(historical_matches)

            if total_matches > 0:
                print(f"    ‚úÖ {total_matches} meccs tal√°lat (j√∂v≈ë: {len(future_matches)}, m√∫lt: {len(historical_matches)})")
                self.stats['successful_extractions'] += 1
                self.stats['future_matches_found'] += len(future_matches)
                self.stats['historical_matches_found'] += len(historical_matches)
            else:
                print(f"    ‚ö†Ô∏è Nincs meccs tal√°lat")
                self.stats['failed_extractions'] += 1
                return None

            return {
                'pdf_path': pdf_path,
                'pdf_date': pdf_date,
                'total_matches': total_matches,
                'future_matches': future_matches,
                'historical_matches': historical_matches,
                'extraction_success': True
            }

        except Exception as e:
            print(f"    ‚ùå Hiba a feldolgoz√°s sor√°n: {e}")
            self.stats['errors'].append(f"{Path(pdf_path).name}: {e}")
            self.stats['failed_extractions'] += 1
            return None

    def find_tomorrows_matches(self, limit_pdfs=15):
        """
        Holnapi meccsek keres√©se
        """
        tomorrow = (datetime.now() + timedelta(days=1)).date()
        print(f"üîç HOLNAPI MECCSEK KERES√âSE ({tomorrow})")
        print("="*50)

        pdf_files = self.get_recent_pdfs_sorted(limit_pdfs)
        tomorrows_matches = []
        processed_count = 0

        for pdf_path, pdf_date in pdf_files:
            result = self.process_single_pdf(pdf_path, pdf_date)
            processed_count += 1
            self.stats['processed_files'] += 1

            if result and result['future_matches']:
                for match in result['future_matches']:
                    match_date_str = match.get('date', '')
                    try:
                        if match_date_str:
                            match_date = datetime.strptime(match_date_str, '%Y-%m-%d').date()
                            if match_date == tomorrow:
                                tomorrows_matches.append({
                                    'date': match_date_str,
                                    'time': match.get('time', 'N/A'),
                                    'home_team': match.get('home_team', 'N/A'),
                                    'away_team': match.get('away_team', 'N/A'),
                                    'league': match.get('league', 'N/A'),
                                    'odds': match.get('odds', {}),
                                    'source_pdf': Path(pdf_path).name,
                                    'confidence': match.get('confidence', 0.0),
                                    'raw_line': match.get('raw_line', '')
                                })
                    except ValueError:
                        continue

        # Eredm√©nyek
        print()
        print(f"üèÜ HOLNAPI MECCSEK EREDM√âNYE")
        print("="*40)
        print(f"üìÖ Holnap d√°tuma: {tomorrow}")
        print(f"‚öΩ Tal√°lat: {len(tomorrows_matches)} meccs")

        if tomorrows_matches:
            print()
            print("üìã HOLNAPI MECCSEK LIST√ÅJA:")
            print("-" * 70)
            for i, match in enumerate(tomorrows_matches, 1):
                print(f"{i:2d}. {match['time']:>5} | {match['home_team']:<25} vs {match['away_team']:<25}")
                print(f"     Liga: {match['league']} | Bizonyoss√°g: {match['confidence']:.2f}")
                print(f"     Forr√°s: {match['source_pdf']}")
                if match.get('raw_line'):
                    print(f"     Eredeti: {match['raw_line'][:60]}...")
                print()
        else:
            print("‚ùå Nincs holnapi meccs tal√°lat")

        return tomorrows_matches

    def collect_historical_sample(self, limit_pdfs=25):
        """
        T√∂rt√©nelmi adatok mintav√©telez√©se
        """
        print(f"üìä T√ñRT√âNELMI ADATOK MINTAV√âTELE")
        print("="*50)

        pdf_files = self.get_recent_pdfs_sorted(limit_pdfs)
        all_historical = []
        processed_count = 0

        for pdf_path, pdf_date in pdf_files:
            result = self.process_single_pdf(pdf_path, pdf_date)
            processed_count += 1

            if result and result['historical_matches']:
                for match in result['historical_matches']:
                    match['source_pdf'] = Path(pdf_path).name
                    all_historical.append(match)

        # Eredm√©nyek ment√©se
        output_file = self.base_dir / 'data' / 'historical_sample_simple.json'

        sample_data = {
            'extraction_date': datetime.now().isoformat(),
            'processed_pdfs': processed_count,
            'total_historical_matches': len(all_historical),
            'sample_matches': all_historical[:50]  # Els≈ë 50 meccs r√©szletei
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(sample_data, f, indent=2, ensure_ascii=False)

        print(f"üíæ T√∂rt√©nelmi adatok mint√°ja mentve: {output_file}")
        print(f"üìä √ñsszesen {len(all_historical)} t√∂rt√©nelmi meccs feldolgozva")
        print(f"üìÑ JSON f√°jlban az els≈ë 50 meccs r√©szletei")

        return all_historical

    def print_processing_summary(self):
        """
        Feldolgoz√°si √∂sszes√≠t≈ë ki√≠r√°sa
        """
        processing_time = datetime.now() - self.stats['processing_start']

        print()
        print("üìã FELDOLGOZ√ÅSI √ñSSZES√çT≈ê")
        print("="*50)
        print(f"‚è±Ô∏è Feldolgoz√°si id≈ë: {processing_time}")
        print(f"üìÅ Feldolgozott PDF-ek: {self.stats['processed_files']}")
        print(f"‚úÖ Sikeres kinyer√©sek: {self.stats['successful_extractions']}")
        print(f"‚ùå Sikertelen kinyer√©sek: {self.stats['failed_extractions']}")
        print(f"üîÆ J√∂v≈ëbeli meccsek: {self.stats['future_matches_found']}")
        print(f"üìö T√∂rt√©nelmi meccsek: {self.stats['historical_matches_found']}")

        success_rate = 0
        if self.stats['processed_files'] > 0:
            success_rate = (self.stats['successful_extractions'] / self.stats['processed_files']) * 100
        print(f"üìà Sikeres feldolgoz√°s ar√°nya: {success_rate:.1f}%")

        if self.stats['errors']:
            print()
            print("‚ö†Ô∏è HIB√ÅK:")
            for error in self.stats['errors'][:5]:  # Els≈ë 5 hiba
                print(f"  - {error}")
            if len(self.stats['errors']) > 5:
                print(f"  ... √©s m√©g {len(self.stats['errors']) - 5} hiba")

def main():
    """
    F≈ë feldolgoz√°si folyamat
    """
    processor = SimpleTimeReverseProcessor()

    try:
        # 1. Holnapi meccsek keres√©se
        print("1Ô∏è‚É£ HOLNAPI MECCSEK KERES√âSE")
        tomorrows_matches = processor.find_tomorrows_matches(limit_pdfs=15)

        print()
        print("2Ô∏è‚É£ T√ñRT√âNELMI ADATOK MINTAV√âTELE")
        # 2. T√∂rt√©nelmi adatok mintav√©tele
        historical_sample = processor.collect_historical_sample(limit_pdfs=20)

        # 3. √ñsszes√≠t≈ë
        processor.print_processing_summary()

        # 4. Holnapi meccsek JSON ment√©se
        if tomorrows_matches:
            tomorrow_file = processor.base_dir / 'data' / 'tomorrows_matches.json'
            with open(tomorrow_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'date': (datetime.now() + timedelta(days=1)).date().isoformat(),
                    'extraction_time': datetime.now().isoformat(),
                    'matches_count': len(tomorrows_matches),
                    'matches': tomorrows_matches
                }, f, indent=2, ensure_ascii=False)
            print(f"üíæ Holnapi meccsek mentve: {tomorrow_file}")

        print()
        print("üèÅ FELDOLGOZ√ÅS BEFEJEZVE!")

    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Feldolgoz√°s megszak√≠tva!")
        processor.print_processing_summary()
    except Exception as e:
        print(f"\n‚ùå Kritikus hiba: {e}")
        processor.print_processing_summary()

if __name__ == "__main__":
    main()
