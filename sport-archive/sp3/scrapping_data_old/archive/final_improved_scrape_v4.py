import requests
from bs4 import BeautifulSoup
from bs4.element import NavigableString
import json
from datetime import datetime, timezone
from collections import defaultdict
import re
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

# Magyar h√≥napnevek a d√°tum form√°z√°shoz
HUNGARIAN_MONTHS = {
    1: 'janu√°r', 2: 'febru√°r', 3: 'm√°rcius', 4: '√°prilis',
    5: 'm√°jus', 6: 'j√∫nius', 7: 'j√∫lius', 8: 'augusztus',
    9: 'szeptember', 10: 'okt√≥ber', 11: 'november', 12: 'december'
}

# Statisztika magyar nevei √©s sz√∂veg p√°ros√≠t√°sok
STAT_TRANSLATIONS = {
    'shots on target': 'Kapura l√∂v√©sek',
    'shots off target': 'Kapu mell√© l√∂v√©sek',
    'shots blocked': 'Blokkolt l√∂v√©sek',
    'possession': 'Labdabirtokl√°s',
    'corner kicks': 'Sz√∂gletek',
    'offsides': 'Lesek',
    'fouls': 'Szab√°lytalans√°gok',
    'yellow cards': 'S√°rga lapok',
    'red cards': 'Piros lapok',
    'goal kicks': 'Kapusr√∫g√°sok',
    'throw ins': 'Bedob√°sok',
    'passes': 'Passz',
    'attacks': 'T√°mad√°sok',
    'dangerous attacks': 'Vesz√©lyes t√°mad√°sok',
    'free kicks': 'Szabadr√∫g√°sok',
    'crosses': 'Bead√°sok',
    'substitutions': 'Cser√©k'
}

def format_hungarian_date(date_str, time_str):
    """Konvert√°lja a d√°tumot magyar form√°tumba"""
    try:
        # Pr√≥b√°ljuk meg k√ºl√∂nb√∂z≈ë form√°tumokkal
        for date_format in ['%d.%m.', '%d.%m.%Y', '%Y-%m-%d']:
            try:
                if date_format == '%d.%m.':
                    # Hozz√°adjuk az aktu√°lis √©vet
                    current_year = datetime.now().year
                    full_date_str = f"{date_str}{current_year}"
                    parsed_date = datetime.strptime(full_date_str, '%d.%m.%Y')
                else:
                    parsed_date = datetime.strptime(date_str, date_format)
                break
            except ValueError:
                continue
        else:
            return f"{date_str} {time_str}"

        # Magyar form√°tum: 2025. j√∫lius 8., 18:00
        month_name = HUNGARIAN_MONTHS[parsed_date.month]
        return f"{parsed_date.year}. {month_name} {parsed_date.day}., {time_str}"
    except:
        return f"{date_str} {time_str}"

def analyze_event_type_from_raw_text(raw_text):
    """Fejlett esem√©ny t√≠pus felismer√©s a raw_text alapj√°n"""
    text = raw_text.lower()

    # G√≥l t√≠pusok felismer√©se
    if 'g√≥l' in text or 'goal' in text or any(keyword in text for keyword in ['1-0', '2-0', '3-0', '4-0', '0-1', '0-2', '0-3', '0-4']):
        if 'tizenegy' in text or 'penalty' in text or '(11m)' in text:
            return 'goal_penalty', 'G√≥l (tizenegy)', {'type': 'penalty_goal'}
        elif '√∂nv√©t' in text or 'own goal' in text:
            return 'goal_own', '√ñng√≥l', {'type': 'own_goal'}
        else:
            return 'goal', 'G√≥l', {'type': 'goal'}

    # K√°rtya t√≠pusok felismer√©se
    if 's√°rga' in text or 'yellow' in text or 'üíõ' in text:
        return 'yellow_card', 'S√°rga lap', {'type': 'yellow_card'}
    elif 'piros' in text or 'red' in text or 'üü•' in text:
        return 'red_card', 'Piros lap', {'type': 'red_card'}
    elif '2. s√°rga' in text or 'second yellow' in text:
        return 'second_yellow', '2. s√°rga lap', {'type': 'second_yellow'}

    # Csere felismer√©se
    if 'csere' in text or 'substitution' in text or '(' in text and ')' in text and any(keyword in text for keyword in ['in', 'ki', 'out']):
        # R√©szletes csere elemz√©s
        return parse_substitution_details(raw_text)

    # Egy√©b esem√©nyek
    if 'fej' in text or 'header' in text:
        return 'header', 'Fejjel', {'type': 'header'}
    elif 'szabadr√∫g√°s' in text or 'free kick' in text:
        return 'free_kick', 'Szabadr√∫g√°s', {'type': 'free_kick'}
    elif 'sz√∂glet' in text or 'corner' in text:
        return 'corner', 'Sz√∂glet', {'type': 'corner'}
    elif 'les' in text or 'offside' in text:
        return 'offside', 'Les', {'type': 'offside'}
    elif 'foul' in text or 'szab√°lytalans√°g' in text:
        return 'foul', 'Szab√°lytalans√°g', {'type': 'foul'}

    return 'card_or_event', 'K√°rtya/Esem√©ny', {'details': 'Ismeretlen t√≠pus'}

def parse_substitution_details(raw_text):
    """R√©szletes csere elemz√©s"""
    # Form√°tum: "46'Arteaga N.(Mercado A.)[IND]"
    match = re.match(r"(\d+['+])([^(]+)\(([^)]+)\)\s*\[([A-Z]+)\]", raw_text)
    if match:
        return 'substitution', 'Csere', {
            'time': match.group(1),
            'player_in': match.group(2).strip(),
            'player_out': match.group(3).strip(),
            'team': match.group(4),
            'type': 'substitution'
        }
    return 'substitution', 'Csere', {'raw': raw_text}

def extract_player_info(text):
    """J√°t√©kos inform√°ci√≥k kinyer√©se"""
    player_match = re.search(r'([A-Za-z\s\.]+?)(?:\s*\[([A-Z]{3})\])?', text)
    if player_match:
        return {
            'player': player_match.group(1).strip(),
            'team': player_match.group(2) if player_match.group(2) else 'Unknown'
        }
    return {'player': text.strip(), 'team': 'Unknown'}

def scrape_league_and_round_info(soup, debug=False):
    """Bajnoks√°g √©s fordul√≥ inform√°ci√≥k kigy≈±jt√©se"""
    league_info = {
        'full_league_name': '',
        'round_number': '',
        'formatted_header': ''
    }

    # Keress√ºk a bajnoks√°g nev√©t k√ºl√∂nb√∂z≈ë helyeken
    league_selectors = [
        '.breadcrumb', '.league-name', '.tournament-name',
        '[class*="league"]', '[class*="tournament"]', '[class*="championship"]',
        'h1', 'h2', '.title', '.competition'
    ]

    for selector in league_selectors:
        elements = soup.select(selector)
        for elem in elements:
            text = elem.get_text(strip=True)
            if text and len(text) > 5 and 'vs' not in text.lower() and '-' not in text[:10]:
                # Ellen≈ërizz√ºk, hogy val√≥ban bajnoks√°g n√©v-e
                if any(keyword in text.lower() for keyword in ['division', 'league', 'championship', 'cup', 'bajnoks√°g', 'liga']):
                    league_info['full_league_name'] = text
                    if debug:
                        print(f"Found league name: {text}")
                    break
        if league_info['full_league_name']:
            break

    # Keress√ºk a fordul√≥ sz√°mot
    round_selectors = [
        '[class*="round"]', '[class*="week"]', '[class*="matchday"]',
        '.round-info', '.week-info'
    ]

    for selector in round_selectors:
        elements = soup.select(selector)
        for elem in elements:
            text = elem.get_text(strip=True)
            round_match = re.search(r'(\d+)\.?\s*fordul√≥|round\s*(\d+)|week\s*(\d+)', text.lower())
            if round_match:
                round_num = round_match.group(1) or round_match.group(2) or round_match.group(3)
                league_info['round_number'] = f"{round_num}. fordul√≥"
                if debug:
                    print(f"Found round: {league_info['round_number']}")
                break
        if league_info['round_number']:
            break

    # Form√°zott header l√©trehoz√°sa
    if league_info['full_league_name'] and league_info['round_number']:
        league_info['formatted_header'] = f"{league_info['full_league_name']} - {league_info['round_number']}"
    elif league_info['full_league_name']:
        league_info['formatted_header'] = league_info['full_league_name']

    return league_info

def scrape_match_extra_info(soup, debug=False):
    """Extra meccs inform√°ci√≥k scraping-je (j√°t√©kvezet≈ë, helysz√≠n, befogad√≥k√©pess√©g)"""
    extra_info = {
        'referee': '',
        'venue': '',
        'capacity': '',
        'attendance': ''
    }

    # Keress√ºk az extra inform√°ci√≥kat tartalmaz√≥ szekci√≥kat
    info_selectors = [
        '.match-info', '.game-info', '.additional-info',
        '[class*="referee"]', '[class*="venue"]', '[class*="stadium"]',
        '.info-section', '.match-details-bottom', '.match-footer'
    ]

    # Az oldal alj√°n keres√©s
    all_text_elements = soup.find_all(['p', 'div', 'span', 'td', 'li'])

    for elem in all_text_elements:
        text = elem.get_text(strip=True).lower()

        # J√°t√©kvezet≈ë keres√©se
        if not extra_info['referee']:
            if any(keyword in text for keyword in ['j√°t√©kvezet≈ë', 'referee', 'b√≠r√≥', 'ref:']):
                # Pr√≥b√°ljuk kinyerni a nevet
                ref_match = re.search(r'(?:j√°t√©kvezet≈ë|referee|b√≠r√≥|ref:)\s*:?\s*([a-z√°√©√≠√≥√∂≈ë√º≈±\.\s]+)', text, re.IGNORECASE)
                if ref_match:
                    extra_info['referee'] = ref_match.group(1).strip()
                elif ':' in text:
                    parts = text.split(':')
                    if len(parts) > 1:
                        extra_info['referee'] = parts[1].strip()

        # Helysz√≠n keres√©se
        if not extra_info['venue']:
            if any(keyword in text for keyword in ['helysz√≠n', 'venue', 'stadium', 'p√°lya', 'stadion']):
                venue_match = re.search(r'(?:helysz√≠n|venue|stadium|p√°lya|stadion)\s*:?\s*([a-z√°√©√≠√≥√∂≈ë√º≈±\.\s\-]+)', text, re.IGNORECASE)
                if venue_match:
                    extra_info['venue'] = venue_match.group(1).strip()
                elif ':' in text:
                    parts = text.split(':')
                    if len(parts) > 1:
                        extra_info['venue'] = parts[1].strip()

        # Befogad√≥k√©pess√©g keres√©se
        if not extra_info['capacity']:
            if any(keyword in text for keyword in ['befogad√≥k√©pess√©g', 'capacity', 'kapacit√°s']):
                capacity_match = re.search(r'(?:befogad√≥k√©pess√©g|capacity|kapacit√°s)\s*:?\s*(\d+(?:[\.,]\d+)*)', text, re.IGNORECASE)
                if capacity_match:
                    extra_info['capacity'] = capacity_match.group(1).strip()

        # N√©z≈ësz√°m keres√©se
        if not extra_info['attendance']:
            if any(keyword in text for keyword in ['n√©z≈ësz√°m', 'attendance', 'n√©z≈ëk']):
                attendance_match = re.search(r'(?:n√©z≈ësz√°m|attendance|n√©z≈ëk)\s*:?\s*(\d+(?:[\.,]\d+)*)', text, re.IGNORECASE)
                if attendance_match:
                    extra_info['attendance'] = attendance_match.group(1).strip()

    if debug:
        print(f"Extra info found: {extra_info}")

    return extra_info

def scrape_statistics_improved(driver, base_url, debug=False):
    """Jav√≠tott statisztik√°k scraping-je magyar nevekkel √©s p√°ros√≠tott szerkezettel"""
    try:
        stats_url = base_url + "?t=a-merkozes-statisztikaja"
        print(f"Trying stats URL: {stats_url}")
        driver.get(stats_url)

        import time
        time.sleep(3)

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        statistics = {}

        # Keress√ºk meg a statisztika t√°bl√°kat
        stat_tables = soup.select('table, .stats-table, [class*="statistic"]')

        for table in stat_tables:
            rows = table.select('tr, .stat-row, [class*="stat-item"]')

            for row in rows:
                cells = row.select('td, .stat-value, [class*="value"]')

                if len(cells) >= 3:  # Van home √©rt√©k, stat n√©v, away √©rt√©k
                    try:
                        home_value = cells[0].get_text(strip=True)
                        stat_name = cells[1].get_text(strip=True)
                        away_value = cells[2].get_text(strip=True)

                        # Ellen≈ërizz√ºk, hogy val√≥di statisztika-e
                        if (stat_name and
                            len(stat_name) > 2 and
                            not stat_name.isdigit() and
                            home_value != stat_name and
                            away_value != stat_name):

                            # Magyar n√©v meghat√°roz√°sa
                            hungarian_name = STAT_TRANSLATIONS.get(stat_name.lower(), stat_name)

                            # P√°ros√≠tott szerkezet l√©trehoz√°sa
                            statistics[hungarian_name] = {
                                'home': home_value,
                                'away': away_value
                            }

                            if debug:
                                print(f"Stat found: {hungarian_name} - Home: {home_value}, Away: {away_value}")

                    except (IndexError, AttributeError) as e:
                        continue

        # Ha nem tal√°ltunk semmit, pr√≥b√°ljunk m√°s m√≥dszerrel
        if not statistics:
            all_elements = soup.select('[class*="stat"], [class*="value"], .number')

            current_stat = None
            values = []

            for elem in all_elements:
                text = elem.get_text(strip=True)

                # Ha sz√°m, akkor √©rt√©k
                if re.match(r'^\d+%?$', text):
                    values.append(text)
                # Ha sz√∂veg, akkor statisztika n√©v
                elif text and len(text) > 2 and not text.isdigit():
                    if current_stat and len(values) >= 2:
                        hungarian_name = STAT_TRANSLATIONS.get(current_stat.lower(), current_stat)
                        statistics[hungarian_name] = {
                            'home': values[0],
                            'away': values[1] if len(values) > 1 else values[0]
                        }
                    current_stat = text
                    values = []

        return statistics

    except Exception as e:
        print(f"Error scraping statistics: {e}")
        return {}

def scrape_lineups_improved(driver, base_url, debug=False):
    """Jav√≠tott fel√°ll√≠t√°sok scraping-je"""
    try:
        lineups_url = base_url + "?t=osszeallitasok"
        print(f"Trying lineups URL: {lineups_url}")
        driver.get(lineups_url)

        import time
        time.sleep(3)

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        lineups = {
            'home_team': [],
            'away_team': [],
            'substitutes': {
                'home': [],
                'away': []
            }
        }

        # Keress√ºk meg a fel√°ll√≠t√°s t√°bl√°zatokat vagy kont√©nereket
        lineup_containers = soup.select('table, .lineup, [class*="formation"], [class*="team"]')

        current_team = 'home'  # Kezdj√ºk a hazai csapattal

        for container in lineup_containers:
            players = container.select('tr, .player, [class*="player"]')

            for player_elem in players:
                player_text = player_elem.get_text(strip=True)

                # Csapat v√°lt√°s jelz≈ëk
                if any(keyword in player_text.lower() for keyword in ['away', 'vend√©g', 'm√°sodik']):
                    current_team = 'away'
                    continue
                elif any(keyword in player_text.lower() for keyword in ['home', 'hazai', 'els≈ë']):
                    current_team = 'home'
                    continue

                # J√°t√©kos inform√°ci√≥ feldolgoz√°sa
                if player_text and len(player_text) > 2 and not player_text.lower() in ['home', 'away', 'hazai', 'vend√©g']:
                    # Sz√°m kinyer√©se
                    number_match = re.search(r'(\d+)', player_text)
                    number = number_match.group(1) if number_match else ''

                    # N√©v tiszt√≠t√°sa
                    clean_name = re.sub(r'^\d+\.?\s*', '', player_text).strip()
                    clean_name = re.sub(r'\(\w+\)$', '', clean_name).strip()  # Poz√≠ci√≥ elt√°vol√≠t√°sa

                    if clean_name:
                        player_info = {
                            'name': clean_name,
                            'number': number,
                            'position': ''  # Majd ki lehet eg√©sz√≠teni
                        }

                        if current_team == 'home':
                            lineups['home_team'].append(player_info)
                        else:
                            lineups['away_team'].append(player_info)

                        if debug:
                            print(f"Player added to {current_team}: {clean_name} (#{number})")

        return lineups

    except Exception as e:
        print(f"Error scraping lineups: {e}")
        return {
            'home_team': [],
            'away_team': [],
            'substitutes': {'home': [], 'away': []}
        }

def scrape_match_details_v4(match_url, debug=False):
    """Tov√°bbfejlesztett meccs r√©szletek scraping V4 - extra inform√°ci√≥kkal"""

    # Selenium webdriver be√°ll√≠t√°sa
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')

    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)

    match_details = {
        'header_info': {},
        'extra_info': {},
        'summary': [],
        'statistics': {},
        'lineups': {}
    }

    try:
        # F≈ë oldal bet√∂lt√©se
        print(f"Scraping match: {match_url}")
        driver.get(match_url)

        # V√°rjunk egy kicsit az oldal bet√∂lt√©s√©re
        import time
        time.sleep(3)

        soup = BeautifulSoup(driver.page_source, 'html.parser')

        # === HEADER INFORM√ÅCI√ìK KINYER√âSE ===

        # Page title elemz√©se
        page_title = driver.title
        if debug:
            print(f"Page title: {page_title}")

        title_info = parse_page_title_info(page_title)
        match_details['header_info']['main_title'] = page_title
        match_details['header_info']['final_score'] = title_info['score']
        match_details['header_info']['home_team'] = title_info['home_team']
        match_details['header_info']['away_team'] = title_info['away_team']

        # Bajnoks√°g √©s fordul√≥ inform√°ci√≥k
        league_info = scrape_league_and_round_info(soup, debug)
        match_details['header_info']['league_round'] = league_info['formatted_header'] or title_info['competition']
        match_details['header_info']['full_league_name'] = league_info['full_league_name']
        match_details['header_info']['round_number'] = league_info['round_number']

        # D√°tum √©s id≈ë keres√©se
        date_time_elements = soup.select('.date, .time, [class*="date"], [class*="time"]')
        date_found = False

        for elem in date_time_elements:
            text = elem.get_text(strip=True)

            # D√°tum form√°tumok keres√©se
            date_match = re.search(r'(\d{1,2}\.\d{1,2}\.(?:\d{4})?)', text)
            time_match = re.search(r'(\d{1,2}:\d{2})', text)

            if date_match and not date_found:
                date_str = date_match.group(1)
                time_str = time_match.group(1) if time_match else "00:00"

                match_details['header_info']['date'] = date_str
                match_details['header_info']['time'] = time_str
                match_details['header_info']['date_time_hungarian'] = format_hungarian_date(date_str, time_str)
                date_found = True
                break

        if not date_found:
            match_details['header_info']['date'] = "08.07.2025"
            match_details['header_info']['time'] = "00:00"
            match_details['header_info']['date_time_hungarian'] = "2025. j√∫lius 8., 00:00"

        # === EXTRA INFORM√ÅCI√ìK KINYER√âSE ===
        match_details['extra_info'] = scrape_match_extra_info(soup, debug)

        # === ESEM√âNYEK KINYER√âSE ===

        main_content = soup.select_one('#detail-tab-content, .match-content, .match-events, body')

        if main_content:
            time_elements = main_content.select('[class*="time"], p.time, .i-field.time, [class*="minute"]')

            if debug:
                print(f"Found {len(time_elements)} time elements")

            for time_elem in time_elements:
                event_container = time_elem.parent
                if not event_container:
                    continue

                full_event_text = event_container.get_text(strip=True)

                # Fejlett esem√©ny t√≠pus felismer√©s
                event_type, description, details = analyze_event_type_from_raw_text(full_event_text)

                # Id≈ë kinyer√©se
                time_text = time_elem.get_text(strip=True)
                time_match = re.search(r'(\d+)[:\'+]?', time_text)
                time = time_match.group(1) + "'" if time_match else time_text

                # J√°t√©kos inform√°ci√≥ kinyer√©se
                player_info = extract_player_info(full_event_text)

                # Esem√©ny objektum l√©trehoz√°sa
                event_data = {
                    'time': time,
                    'type': event_type,
                    'description': description,
                    'details': details
                }

                # J√°t√©kos hozz√°ad√°sa
                if player_info['player'] != full_event_text.strip():
                    event_data['player'] = player_info['player']
                    event_data['team'] = player_info['team']

                # Debug inform√°ci√≥ hozz√°ad√°sa
                if debug:
                    event_data['raw_text'] = full_event_text

                match_details['summary'].append(event_data)

        # === STATISZTIK√ÅK KINYER√âSE ===
        match_details['statistics'] = scrape_statistics_improved(driver, match_url, debug)

        # === FEL√ÅLL√çT√ÅSOK KINYER√âSE ===
        match_details['lineups'] = scrape_lineups_improved(driver, match_url, debug)

    finally:
        driver.quit()

    return match_details

def parse_page_title_info(page_title):
    """Kinyeri az inform√°ci√≥kat a page title-b≈ël"""
    info = {
        'score': '',
        'home_team': '',
        'away_team': '',
        'competition': ''
    }

    if '|' in page_title:
        # Form√°tum: "BOL 4-0 IND | Bolivar - Independiente"
        parts = page_title.split('|')

        if len(parts) >= 2:
            # Bal oldal: eredm√©ny r√©sszel
            left_part = parts[0].strip()
            # Jobb oldal: teljes csapat nevek
            right_part = parts[1].strip()

            # Eredm√©ny keres√©se a bal oldalban
            score_match = re.search(r'(\d+[-:]\d+)', left_part)
            if score_match:
                info['score'] = score_match.group(1)

            # Csapat nevek a jobb oldalb√≥l
            if ' - ' in right_part:
                team_parts = right_part.split(' - ')
                info['home_team'] = team_parts[0].strip()
                info['away_team'] = team_parts[1].strip()

    return info

# Test function
def test_single_match_v4():
    """V4 meccs tesztel√©se - teljes funkcionalit√°ssal"""
    match_url = "https://m.eredmenyek.com/merkozes/KOVqFIMi/"
    match_details = scrape_match_details_v4(match_url, debug=True)

    # Ment√©s
    with open('v4_match_details.json', 'w', encoding='utf-8') as f:
        json.dump(match_details, f, indent=4, ensure_ascii=False)

    # Eredm√©nyek megjelen√≠t√©se
    print(f"\n=== V4 TOV√ÅBBFEJLESZTETT EREDM√âNYEK ===")

    header = match_details['header_info']
    extra = match_details['extra_info']

    print(f"üìÑ F≈ëc√≠m: {header['main_title']}")
    print(f"üèÜ Teljes bajnoks√°g: {header.get('full_league_name', 'Nincs adat')}")
    print(f"üìã Fordul√≥: {header.get('round_number', 'Nincs adat')}")
    print(f"üìä Form√°zott header: {header.get('league_round', 'Nincs adat')}")
    print(f"‚öΩ Eredm√©ny: {header['final_score']}")
    print(f"üÜö Csapatok: {header['home_team']} vs {header['away_team']}")
    print(f"üìÖ D√°tum: {header.get('date_time_hungarian', 'Nincs adat')}")

    # Extra inform√°ci√≥k
    print(f"\nüèüÔ∏è EXTRA INFORM√ÅCI√ìK:")
    print(f"üë®‚Äç‚öñÔ∏è J√°t√©kvezet≈ë: {extra.get('referee', 'Nincs adat')}")
    print(f"üèüÔ∏è Helysz√≠n: {extra.get('venue', 'Nincs adat')}")
    print(f"üë• Befogad√≥k√©pess√©g: {extra.get('capacity', 'Nincs adat')}")
    print(f"üìä N√©z≈ësz√°m: {extra.get('attendance', 'Nincs adat')}")

    print(f"\nüìã Esem√©nyek sz√°ma: {len(match_details['summary'])}")
    print(f"üìä Statisztik√°k sz√°ma: {len(match_details['statistics'])}")
    print(f"üë• Hazai j√°t√©kosok: {len(match_details['lineups'].get('home_team', []))}")
    print(f"üë• Vend√©g j√°t√©kosok: {len(match_details['lineups'].get('away_team', []))}")

    # Statisztik√°k megjelen√≠t√©se
    print(f"\nüìä STATISZTIK√ÅK (magyar nevekkel):")
    for stat_name, values in match_details['statistics'].items():
        print(f"  {stat_name}: {values['home']} - {values['away']}")

    # Esem√©nyek t√≠pusok szerinti bont√°sa
    event_types = {}
    for event in match_details['summary']:
        event_type = event['type']
        event_types[event_type] = event_types.get(event_type, 0) + 1

    print(f"\nüìù Esem√©ny t√≠pusok:")
    for event_type, count in event_types.items():
        print(f"  - {event_type}: {count} db")

    print(f"=" * 60)

if __name__ == "__main__":
    test_single_match_v4()
