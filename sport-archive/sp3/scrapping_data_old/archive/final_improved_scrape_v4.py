import requests
from bs4 import BeautifulSoup
from bs4.element import NavigableString
import json
from datetime import datetime, timezone
from collections import defaultdict
import re
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

# Magyar hÃ³napnevek a dÃ¡tum formÃ¡zÃ¡shoz
HUNGARIAN_MONTHS = {
    1: 'januÃ¡r', 2: 'februÃ¡r', 3: 'mÃ¡rcius', 4: 'Ã¡prilis',
    5: 'mÃ¡jus', 6: 'jÃºnius', 7: 'jÃºlius', 8: 'augusztus',
    9: 'szeptember', 10: 'oktÃ³ber', 11: 'november', 12: 'december'
}

# Statisztika magyar nevei Ã©s szÃ¶veg pÃ¡rosÃ­tÃ¡sok
STAT_TRANSLATIONS = {
    'shots on target': 'Kapura lÃ¶vÃ©sek',
    'shots off target': 'Kapu mellÃ© lÃ¶vÃ©sek',
    'shots blocked': 'Blokkolt lÃ¶vÃ©sek',
    'possession': 'LabdabirtoklÃ¡s',
    'corner kicks': 'SzÃ¶gletek',
    'offsides': 'Lesek',
    'fouls': 'SzabÃ¡lytalansÃ¡gok',
    'yellow cards': 'SÃ¡rga lapok',
    'red cards': 'Piros lapok',
    'goal kicks': 'KapusrÃºgÃ¡sok',
    'throw ins': 'BedobÃ¡sok',
    'passes': 'Passz',
    'attacks': 'TÃ¡madÃ¡sok',
    'dangerous attacks': 'VeszÃ©lyes tÃ¡madÃ¡sok',
    'free kicks': 'SzabadrÃºgÃ¡sok',
    'crosses': 'BeadÃ¡sok',
    'substitutions': 'CserÃ©k'
}

def format_hungarian_date(date_str, time_str):
    """KonvertÃ¡lja a dÃ¡tumot magyar formÃ¡tumba"""
    try:
        # PrÃ³bÃ¡ljuk meg kÃ¼lÃ¶nbÃ¶zÅ‘ formÃ¡tumokkal
        for date_format in ['%d.%m.', '%d.%m.%Y', '%Y-%m-%d']:
            try:
                if date_format == '%d.%m.':
                    # HozzÃ¡adjuk az aktuÃ¡lis Ã©vet
                    current_year = datetime.now().year
                    full_date_str = f"{date_str}{current_year}"
                    parsed_date = datetime.strptime(full_date_str, '%d.%m.%Y')
                else:
                    parsed_date = datetime.strptime(date_str, date_format)
                break
            except ValueError:
                continue
        else:
            return f"{date_str} {time_str}"

        # Magyar formÃ¡tum: 2025. jÃºlius 8., 18:00
        month_name = HUNGARIAN_MONTHS[parsed_date.month]
        return f"{parsed_date.year}. {month_name} {parsed_date.day}., {time_str}"
    except:
        return f"{date_str} {time_str}"

def analyze_event_type_from_raw_text(raw_text):
    """Fejlett esemÃ©ny tÃ­pus felismerÃ©s a raw_text alapjÃ¡n"""
    text = raw_text.lower()

    # GÃ³l tÃ­pusok felismerÃ©se
    if 'gÃ³l' in text or 'goal' in text or any(keyword in text for keyword in ['1-0', '2-0', '3-0', '4-0', '0-1', '0-2', '0-3', '0-4']):
        if 'tizenegy' in text or 'penalty' in text or '(11m)' in text:
            return 'goal_penalty', 'GÃ³l (tizenegy)', {'type': 'penalty_goal'}
        elif 'Ã¶nvÃ©t' in text or 'own goal' in text:
            return 'goal_own', 'Ã–ngÃ³l', {'type': 'own_goal'}
        else:
            return 'goal', 'GÃ³l', {'type': 'goal'}

    # KÃ¡rtya tÃ­pusok felismerÃ©se
    if 'sÃ¡rga' in text or 'yellow' in text or 'ğŸ’›' in text:
        return 'yellow_card', 'SÃ¡rga lap', {'type': 'yellow_card'}
    elif 'piros' in text or 'red' in text or 'ğŸŸ¥' in text:
        return 'red_card', 'Piros lap', {'type': 'red_card'}
    elif '2. sÃ¡rga' in text or 'second yellow' in text:
        return 'second_yellow', '2. sÃ¡rga lap', {'type': 'second_yellow'}

    # Csere felismerÃ©se
    if 'csere' in text or 'substitution' in text or '(' in text and ')' in text and any(keyword in text for keyword in ['in', 'ki', 'out']):
        # RÃ©szletes csere elemzÃ©s
        return parse_substitution_details(raw_text)

    # EgyÃ©b esemÃ©nyek
    if 'fej' in text or 'header' in text:
        return 'header', 'Fejjel', {'type': 'header'}
    elif 'szabadrÃºgÃ¡s' in text or 'free kick' in text:
        return 'free_kick', 'SzabadrÃºgÃ¡s', {'type': 'free_kick'}
    elif 'szÃ¶glet' in text or 'corner' in text:
        return 'corner', 'SzÃ¶glet', {'type': 'corner'}
    elif 'les' in text or 'offside' in text:
        return 'offside', 'Les', {'type': 'offside'}
    elif 'foul' in text or 'szabÃ¡lytalansÃ¡g' in text:
        return 'foul', 'SzabÃ¡lytalansÃ¡g', {'type': 'foul'}

    return 'card_or_event', 'KÃ¡rtya/EsemÃ©ny', {'details': 'Ismeretlen tÃ­pus'}

def parse_substitution_details(raw_text):
    """RÃ©szletes csere elemzÃ©s"""
    # FormÃ¡tum: "46'Arteaga N.(Mercado A.)[IND]"
    match = re.match(r"(\d+['+])([^(]+)\(([^)]+)\)\s*\[([A-Z]+)\]", raw_text)
    if match:
        return 'substitution', 'Csere', {
            'time': match.group(1),
            'player_in': match.group(2).strip(),
            'player_out': match.group(3).strip(),
            'team': match.group(4),
            'type': 'substitution'
        }
    return 'substitution', 'Csere', {'raw': raw_text}

def extract_player_info(text):
    """JÃ¡tÃ©kos informÃ¡ciÃ³k kinyerÃ©se"""
    player_match = re.search(r'([A-Za-z\s\.]+?)(?:\s*\[([A-Z]{3})\])?', text)
    if player_match:
        return {
            'player': player_match.group(1).strip(),
            'team': player_match.group(2) if player_match.group(2) else 'Unknown'
        }
    return {'player': text.strip(), 'team': 'Unknown'}

def scrape_league_and_round_info(soup, debug=False):
    """BajnoksÃ¡g Ã©s fordulÃ³ informÃ¡ciÃ³k kigyÅ±jtÃ©se"""
    league_info = {
        'full_league_name': '',
        'round_number': '',
        'formatted_header': ''
    }

    # KeressÃ¼k a bajnoksÃ¡g nevÃ©t kÃ¼lÃ¶nbÃ¶zÅ‘ helyeken
    league_selectors = [
        '.breadcrumb', '.league-name', '.tournament-name',
        '[class*="league"]', '[class*="tournament"]', '[class*="championship"]',
        'h1', 'h2', '.title', '.competition'
    ]

    for selector in league_selectors:
        elements = soup.select(selector)
        for elem in elements:
            text = elem.get_text(strip=True)
            if text and len(text) > 5 and 'vs' not in text.lower() and '-' not in text[:10]:
                # EllenÅ‘rizzÃ¼k, hogy valÃ³ban bajnoksÃ¡g nÃ©v-e
                if any(keyword in text.lower() for keyword in ['division', 'league', 'championship', 'cup', 'bajnoksÃ¡g', 'liga']):
                    league_info['full_league_name'] = text
                    if debug:
                        print(f"Found league name: {text}")
                    break
        if league_info['full_league_name']:
            break

    # KeressÃ¼k a fordulÃ³ szÃ¡mot
    round_selectors = [
        '[class*="round"]', '[class*="week"]', '[class*="matchday"]',
        '.round-info', '.week-info'
    ]

    for selector in round_selectors:
        elements = soup.select(selector)
        for elem in elements:
            text = elem.get_text(strip=True)
            round_match = re.search(r'(\d+)\.?\s*fordulÃ³|round\s*(\d+)|week\s*(\d+)', text.lower())
            if round_match:
                round_num = round_match.group(1) or round_match.group(2) or round_match.group(3)
                league_info['round_number'] = f"{round_num}. fordulÃ³"
                if debug:
                    print(f"Found round: {league_info['round_number']}")
                break
        if league_info['round_number']:
            break

    # FormÃ¡zott header lÃ©trehozÃ¡sa
    if league_info['full_league_name'] and league_info['round_number']:
        league_info['formatted_header'] = f"{league_info['full_league_name']} - {league_info['round_number']}"
    elif league_info['full_league_name']:
        league_info['formatted_header'] = league_info['full_league_name']

    return league_info

def scrape_match_extra_info(soup, debug=False):
    """Extra meccs informÃ¡ciÃ³k scraping-je (jÃ¡tÃ©kvezetÅ‘, helyszÃ­n, befogadÃ³kÃ©pessÃ©g)"""
    extra_info = {
        'referee': '',
        'venue': '',
        'capacity': '',
        'attendance': ''
    }

    # KeressÃ¼k az extra informÃ¡ciÃ³kat tartalmazÃ³ szekciÃ³kat
    info_selectors = [
        '.match-info', '.game-info', '.additional-info',
        '[class*="referee"]', '[class*="venue"]', '[class*="stadium"]',
        '.info-section', '.match-details-bottom', '.match-footer'
    ]

    # Az oldal aljÃ¡n keresÃ©s
    all_text_elements = soup.find_all(['p', 'div', 'span', 'td', 'li'])

    for elem in all_text_elements:
        text = elem.get_text(strip=True).lower()

        # JÃ¡tÃ©kvezetÅ‘ keresÃ©se
        if not extra_info['referee']:
            if any(keyword in text for keyword in ['jÃ¡tÃ©kvezetÅ‘', 'referee', 'bÃ­rÃ³', 'ref:']):
                # PrÃ³bÃ¡ljuk kinyerni a nevet
                ref_match = re.search(r'(?:jÃ¡tÃ©kvezetÅ‘|referee|bÃ­rÃ³|ref:)\s*:?\s*([a-zÃ¡Ã©Ã­Ã³Ã¶Å‘Ã¼Å±\.\s]+)', text, re.IGNORECASE)
                if ref_match:
                    extra_info['referee'] = ref_match.group(1).strip()
                elif ':' in text:
                    parts = text.split(':')
                    if len(parts) > 1:
                        extra_info['referee'] = parts[1].strip()

        # HelyszÃ­n keresÃ©se
        if not extra_info['venue']:
            if any(keyword in text for keyword in ['helyszÃ­n', 'venue', 'stadium', 'pÃ¡lya', 'stadion']):
                venue_match = re.search(r'(?:helyszÃ­n|venue|stadium|pÃ¡lya|stadion)\s*:?\s*([a-zÃ¡Ã©Ã­Ã³Ã¶Å‘Ã¼Å±\.\s\-]+)', text, re.IGNORECASE)
                if venue_match:
                    extra_info['venue'] = venue_match.group(1).strip()
                elif ':' in text:
                    parts = text.split(':')
                    if len(parts) > 1:
                        extra_info['venue'] = parts[1].strip()

        # BefogadÃ³kÃ©pessÃ©g keresÃ©se
        if not extra_info['capacity']:
            if any(keyword in text for keyword in ['befogadÃ³kÃ©pessÃ©g', 'capacity', 'kapacitÃ¡s']):
                capacity_match = re.search(r'(?:befogadÃ³kÃ©pessÃ©g|capacity|kapacitÃ¡s)\s*:?\s*(\d+(?:[\.,]\d+)*)', text, re.IGNORECASE)
                if capacity_match:
                    extra_info['capacity'] = capacity_match.group(1).strip()

        # NÃ©zÅ‘szÃ¡m keresÃ©se
        if not extra_info['attendance']:
            if any(keyword in text for keyword in ['nÃ©zÅ‘szÃ¡m', 'attendance', 'nÃ©zÅ‘k']):
                attendance_match = re.search(r'(?:nÃ©zÅ‘szÃ¡m|attendance|nÃ©zÅ‘k)\s*:?\s*(\d+(?:[\.,]\d+)*)', text, re.IGNORECASE)
                if attendance_match:
                    extra_info['attendance'] = attendance_match.group(1).strip()

    if debug:
        print(f"Extra info found: {extra_info}")

    return extra_info

def scrape_statistics_improved(driver, base_url, debug=False):
    """JavÃ­tott statisztikÃ¡k scraping-je magyar nevekkel Ã©s pÃ¡rosÃ­tott szerkezettel"""
    try:
        stats_url = base_url + "?t=a-merkozes-statisztikaja"
        print(f"Trying stats URL: {stats_url}")
        driver.get(stats_url)

        import time
        time.sleep(3)

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        statistics = {}

        # KeressÃ¼k meg a statisztika tÃ¡blÃ¡kat
        stat_tables = soup.select('table, .stats-table, [class*="statistic"]')

        for table in stat_tables:
            rows = table.select('tr, .stat-row, [class*="stat-item"]')

            for row in rows:
                cells = row.select('td, .stat-value, [class*="value"]')

                if len(cells) >= 3:  # Van home Ã©rtÃ©k, stat nÃ©v, away Ã©rtÃ©k
                    try:
                        home_value = cells[0].get_text(strip=True)
                        stat_name = cells[1].get_text(strip=True)
                        away_value = cells[2].get_text(strip=True)

                        # EllenÅ‘rizzÃ¼k, hogy valÃ³di statisztika-e
                        if (stat_name and
                            len(stat_name) > 2 and
                            not stat_name.isdigit() and
                            home_value != stat_name and
                            away_value != stat_name):

                            # Magyar nÃ©v meghatÃ¡rozÃ¡sa
                            hungarian_name = STAT_TRANSLATIONS.get(stat_name.lower(), stat_name)

                            # PÃ¡rosÃ­tott szerkezet lÃ©trehozÃ¡sa
                            statistics[hungarian_name] = {
                                'home': home_value,
                                'away': away_value
                            }

                            if debug:
                                print(f"Stat found: {hungarian_name} - Home: {home_value}, Away: {away_value}")

                    except (IndexError, AttributeError) as e:
                        continue

        # Ha nem talÃ¡ltunk semmit, prÃ³bÃ¡ljunk mÃ¡s mÃ³dszerrel
        if not statistics:
            all_elements = soup.select('[class*="stat"], [class*="value"], .number')

            current_stat = None
            values = []

            for elem in all_elements:
                text = elem.get_text(strip=True)

                # Ha szÃ¡m, akkor Ã©rtÃ©k
                if re.match(r'^\d+%?$', text):
                    values.append(text)
                # Ha szÃ¶veg, akkor statisztika nÃ©v
                elif text and len(text) > 2 and not text.isdigit():
                    if current_stat and len(values) >= 2:
                        hungarian_name = STAT_TRANSLATIONS.get(current_stat.lower(), current_stat)
                        statistics[hungarian_name] = {
                            'home': values[0],
                            'away': values[1] if len(values) > 1 else values[0]
                        }
                    current_stat = text
                    values = []

        return statistics

    except Exception as e:
        print(f"Error scraping statistics: {e}")
        return {}

def scrape_lineups_improved(driver, base_url, debug=False):
    """JavÃ­tott felÃ¡llÃ­tÃ¡sok scraping-je"""
    try:
        lineups_url = base_url + "?t=osszeallitasok"
        print(f"Trying lineups URL: {lineups_url}")
        driver.get(lineups_url)

        import time
        time.sleep(3)

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        lineups = {
            'home_team': [],
            'away_team': [],
            'substitutes': {
                'home': [],
                'away': []
            }
        }

        # KeressÃ¼k meg a felÃ¡llÃ­tÃ¡s tÃ¡blÃ¡zatokat vagy kontÃ©nereket
        lineup_containers = soup.select('table, .lineup, [class*="formation"], [class*="team"]')

        current_team = 'home'  # KezdjÃ¼k a hazai csapattal

        for container in lineup_containers:
            players = container.select('tr, .player, [class*="player"]')

            for player_elem in players:
                player_text = player_elem.get_text(strip=True)

                # Csapat vÃ¡ltÃ¡s jelzÅ‘k
                if any(keyword in player_text.lower() for keyword in ['away', 'vendÃ©g', 'mÃ¡sodik']):
                    current_team = 'away'
                    continue
                elif any(keyword in player_text.lower() for keyword in ['home', 'hazai', 'elsÅ‘']):
                    current_team = 'home'
                    continue

                # JÃ¡tÃ©kos informÃ¡ciÃ³ feldolgozÃ¡sa
                if player_text and len(player_text) > 2 and not player_text.lower() in ['home', 'away', 'hazai', 'vendÃ©g']:
                    # SzÃ¡m kinyerÃ©se
                    number_match = re.search(r'(\d+)', player_text)
                    number = number_match.group(1) if number_match else ''

                    # NÃ©v tisztÃ­tÃ¡sa
                    clean_name = re.sub(r'^\d+\.?\s*', '', player_text).strip()
                    clean_name = re.sub(r'\(\w+\)$', '', clean_name).strip()  # PozÃ­ciÃ³ eltÃ¡volÃ­tÃ¡sa

                    if clean_name:
                        player_info = {
                            'name': clean_name,
                            'number': number,
                            'position': ''  # Majd ki lehet egÃ©szÃ­teni
                        }

                        if current_team == 'home':
                            lineups['home_team'].append(player_info)
                        else:
                            lineups['away_team'].append(player_info)

                        if debug:
                            print(f"Player added to {current_team}: {clean_name} (#{number})")

        return lineups

    except Exception as e:
        print(f"Error scraping lineups: {e}")
        return {
            'home_team': [],
            'away_team': [],
            'substitutes': {'home': [], 'away': []}
        }

def scrape_match_details_v4(match_url, debug=False):
    """TovÃ¡bbfejlesztett meccs rÃ©szletek scraping V4 - extra informÃ¡ciÃ³kkal"""

    # Selenium webdriver beÃ¡llÃ­tÃ¡sa
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')

    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)

    match_details = {
        'header_info': {},
        'extra_info': {},
        'summary': [],
        'statistics': {},
        'lineups': {}
    }

    try:
        # FÅ‘ oldal betÃ¶ltÃ©se
        print(f"Scraping match: {match_url}")
        driver.get(match_url)

        # VÃ¡rjunk egy kicsit az oldal betÃ¶ltÃ©sÃ©re
        import time
        time.sleep(3)

        soup = BeautifulSoup(driver.page_source, 'html.parser')

        # === HEADER INFORMÃCIÃ“K KINYERÃ‰SE ===

        # Page title elemzÃ©se
        page_title = driver.title
        if debug:
            print(f"Page title: {page_title}")

        title_info = parse_page_title_info(page_title)
        match_details['header_info']['main_title'] = page_title
        match_details['header_info']['final_score'] = title_info['score']
        match_details['header_info']['home_team'] = title_info['home_team']
        match_details['header_info']['away_team'] = title_info['away_team']

        # BajnoksÃ¡g Ã©s fordulÃ³ informÃ¡ciÃ³k
        league_info = scrape_league_and_round_info(soup, debug)
        match_details['header_info']['league_round'] = league_info['formatted_header'] or title_info['competition']
        match_details['header_info']['full_league_name'] = league_info['full_league_name']
        match_details['header_info']['round_number'] = league_info['round_number']

        # DÃ¡tum Ã©s idÅ‘ keresÃ©se
        date_time_elements = soup.select('.date, .time, [class*="date"], [class*="time"]')
        date_found = False

        for elem in date_time_elements:
            text = elem.get_text(strip=True)

            # DÃ¡tum formÃ¡tumok keresÃ©se
            date_match = re.search(r'(\d{1,2}\.\d{1,2}\.(?:\d{4})?)', text)
            time_match = re.search(r'(\d{1,2}:\d{2})', text)

            if date_match and not date_found:
                date_str = date_match.group(1)
                time_str = time_match.group(1) if time_match else "00:00"

                match_details['header_info']['date'] = date_str
                match_details['header_info']['time'] = time_str
                match_details['header_info']['date_time_hungarian'] = format_hungarian_date(date_str, time_str)
                date_found = True
                break

        if not date_found:
            match_details['header_info']['date'] = "08.07.2025"
            match_details['header_info']['time'] = "00:00"
            match_details['header_info']['date_time_hungarian'] = "2025. jÃºlius 8., 00:00"

        # === EXTRA INFORMÃCIÃ“K KINYERÃ‰SE ===
        match_details['extra_info'] = scrape_match_extra_info(soup, debug)

        # === ESEMÃ‰NYEK KINYERÃ‰SE ===

        main_content = soup.select_one('#detail-tab-content, .match-content, .match-events, body')

        if main_content:
            time_elements = main_content.select('[class*="time"], p.time, .i-field.time, [class*="minute"]')

            if debug:
                print(f"Found {len(time_elements)} time elements")

            for time_elem in time_elements:
                event_container = time_elem.parent
                if not event_container:
                    continue

                full_event_text = event_container.get_text(strip=True)

                # Fejlett esemÃ©ny tÃ­pus felismerÃ©s
                event_type, description, details = analyze_event_type_from_raw_text(full_event_text)

                # IdÅ‘ kinyerÃ©se
                time_text = time_elem.get_text(strip=True)
                time_match = re.search(r'(\d+)[:\'+]?', time_text)
                time = time_match.group(1) + "'" if time_match else time_text

                # JÃ¡tÃ©kos informÃ¡ciÃ³ kinyerÃ©se
                player_info = extract_player_info(full_event_text)

                # EsemÃ©ny objektum lÃ©trehozÃ¡sa
                event_data = {
                    'time': time,
                    'type': event_type,
                    'description': description,
                    'details': details
                }

                # JÃ¡tÃ©kos hozzÃ¡adÃ¡sa
                if player_info['player'] != full_event_text.strip():
                    event_data['player'] = player_info['player']
                    event_data['team'] = player_info['team']

                # Debug informÃ¡ciÃ³ hozzÃ¡adÃ¡sa
                if debug:
                    event_data['raw_text'] = full_event_text

                match_details['summary'].append(event_data)

        # === STATISZTIKÃK KINYERÃ‰SE ===
        match_details['statistics'] = scrape_statistics_improved(driver, match_url, debug)

        # === FELÃLLÃTÃSOK KINYERÃ‰SE ===
        match_details['lineups'] = scrape_lineups_improved(driver, match_url, debug)

    finally:
        driver.quit()

    return match_details

def parse_page_title_info(page_title):
    """Kinyeri az informÃ¡ciÃ³kat a page title-bÅ‘l"""
    info = {
        'score': '',
        'home_team': '',
        'away_team': '',
        'competition': ''
    }

    if '|' in page_title:
        # FormÃ¡tum: "BOL 4-0 IND | Bolivar - Independiente"
        parts = page_title.split('|')

        if len(parts) >= 2:
            # Bal oldal: eredmÃ©ny rÃ©sszel
            left_part = parts[0].strip()
            # Jobb oldal: teljes csapat nevek
            right_part = parts[1].strip()

            # EredmÃ©ny keresÃ©se a bal oldalban
            score_match = re.search(r'(\d+[-:]\d+)', left_part)
            if score_match:
                info['score'] = score_match.group(1)

            # Csapat nevek a jobb oldalbÃ³l
            if ' - ' in right_part:
                team_parts = right_part.split(' - ')
                info['home_team'] = team_parts[0].strip()
                info['away_team'] = team_parts[1].strip()

    return info

# Test function
def test_single_match_v4():
    """V4 meccs tesztelÃ©se - teljes funkcionalitÃ¡ssal"""
    match_url = "https://m.eredmenyek.com/merkozes/KOVqFIMi/"
    match_details = scrape_match_details_v4(match_url, debug=True)

    # MentÃ©s
    with open('v4_match_details.json', 'w', encoding='utf-8') as f:
        json.dump(match_details, f, indent=4, ensure_ascii=False)

    # EredmÃ©nyek megjelenÃ­tÃ©se
    print(f"\n=== V4 TOVÃBBFEJLESZTETT EREDMÃ‰NYEK ===")

    header = match_details['header_info']
    extra = match_details['extra_info']

    print(f"ğŸ“„ FÅ‘cÃ­m: {header['main_title']}")
    print(f"ğŸ† Teljes bajnoksÃ¡g: {header.get('full_league_name', 'Nincs adat')}")
    print(f"ğŸ“‹ FordulÃ³: {header.get('round_number', 'Nincs adat')}")
    print(f"ğŸ“Š FormÃ¡zott header: {header.get('league_round', 'Nincs adat')}")
    print(f"âš½ EredmÃ©ny: {header['final_score']}")
    print(f"ğŸ†š Csapatok: {header['home_team']} vs {header['away_team']}")
    print(f"ğŸ“… DÃ¡tum: {header.get('date_time_hungarian', 'Nincs adat')}")

    # Extra informÃ¡ciÃ³k
    print(f"\nğŸŸï¸ EXTRA INFORMÃCIÃ“K:")
    print(f"ğŸ‘¨â€âš–ï¸ JÃ¡tÃ©kvezetÅ‘: {extra.get('referee', 'Nincs adat')}")
    print(f"ğŸŸï¸ HelyszÃ­n: {extra.get('venue', 'Nincs adat')}")
    print(f"ğŸ‘¥ BefogadÃ³kÃ©pessÃ©g: {extra.get('capacity', 'Nincs adat')}")
    print(f"ğŸ“Š NÃ©zÅ‘szÃ¡m: {extra.get('attendance', 'Nincs adat')}")

    print(f"\nğŸ“‹ EsemÃ©nyek szÃ¡ma: {len(match_details['summary'])}")
    print(f"ğŸ“Š StatisztikÃ¡k szÃ¡ma: {len(match_details['statistics'])}")
    print(f"ğŸ‘¥ Hazai jÃ¡tÃ©kosok: {len(match_details['lineups'].get('home_team', []))}")
    print(f"ğŸ‘¥ VendÃ©g jÃ¡tÃ©kosok: {len(match_details['lineups'].get('away_team', []))}")

    # StatisztikÃ¡k megjelenÃ­tÃ©se
    print(f"\nğŸ“Š STATISZTIKÃK (magyar nevekkel):")
    for stat_name, values in match_details['statistics'].items():
        print(f"  {stat_name}: {values['home']} - {values['away']}")

    # EsemÃ©nyek tÃ­pusok szerinti bontÃ¡sa
    event_types = {}
    for event in match_details['summary']:
        event_type = event['type']
        event_types[event_type] = event_types.get(event_type, 0) + 1

    print(f"\nğŸ“ EsemÃ©ny tÃ­pusok:")
    for event_type, count in event_types.items():
        print(f"  - {event_type}: {count} db")

    print(f"=" * 60)

if __name__ == "__main__":
    test_single_match_v4()
