import requests
from bs4 import BeautifulSoup
import json
import re
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

# Magyar hÃ³napnevek a dÃ¡tum formÃ¡zÃ¡shoz
HUNGARIAN_MONTHS = {
    1: 'januÃ¡r', 2: 'februÃ¡r', 3: 'mÃ¡rcius', 4: 'Ã¡prilis',
    5: 'mÃ¡jus', 6: 'jÃºnius', 7: 'jÃºlius', 8: 'augusztus',
    9: 'szeptember', 10: 'oktÃ³ber', 11: 'november', 12: 'december'
}

# Statisztika magyar nevei Ã©s szÃ¶veg pÃ¡rosÃ­tÃ¡sok
STAT_TRANSLATIONS = {
    'shots on target': 'Kapura lÃ¶vÃ©sek',
    'shots off target': 'Kapu mellÃ© lÃ¶vÃ©sek',
    'shots blocked': 'Blokkolt lÃ¶vÃ©sek',
    'possession': 'LabdabirtoklÃ¡s',
    'corner kicks': 'SzÃ¶gletek',
    'offsides': 'Lesek',
    'fouls': 'SzabÃ¡lytalansÃ¡gok',
    'yellow cards': 'SÃ¡rga lapok',
    'red cards': 'Piros lapok',
    'goal kicks': 'KapusrÃºgÃ¡sok',
    'throw ins': 'BedobÃ¡sok',
    'passes': 'Passz',
    'attacks': 'TÃ¡madÃ¡sok',
    'dangerous attacks': 'VeszÃ©lyes tÃ¡madÃ¡sok',
    'free kicks': 'SzabadrÃºgÃ¡sok',
    'crosses': 'BeadÃ¡sok',
    'substitutions': 'CserÃ©k'
}

def close_cookie_consent(driver):
    """Cookie consent bezÃ¡rÃ¡sa"""
    try:
        # VÃ¡runk egy kicsit
        time.sleep(2)

        # KeressÃ¼k meg az Accept gombot
        accept_buttons = driver.find_elements(By.XPATH, "//button[contains(text(), 'Accept') or contains(text(), 'Elfogad') or contains(text(), 'OK')]")

        for button in accept_buttons:
            if button.is_displayed():
                button.click()
                print("Cookie consent elfogadva")
                time.sleep(1)
                break

        # AlternatÃ­v: keressÃ¼k meg a close gombokat
        close_buttons = driver.find_elements(By.XPATH, "//button[contains(@class, 'close') or contains(@aria-label, 'close')]")
        for button in close_buttons:
            if button.is_displayed():
                button.click()
                print("Overlay bezÃ¡rva")
                time.sleep(1)
                break

    except Exception as e:
        print(f"Cookie consent bezÃ¡rÃ¡sa nem sikerÃ¼lt: {e}")

def detailed_league_search(driver, soup, debug=False):
    """RÃ©szletes bajnoksÃ¡g keresÃ©s tÃ¶bb mÃ³dszerrel"""
    league_info = {
        'full_league_name': '',
        'round_number': '',
        'formatted_header': ''
    }

    # 1. PrÃ³bÃ¡ljuk meg navigÃ¡lni vissza a bajnoksÃ¡g oldalra
    try:
        back_links = driver.find_elements(By.XPATH, "//a[contains(@href, 'bajnoksag') or contains(@href, 'league') or contains(@href, 'tournament')]")
        for link in back_links[:3]:  # ElsÅ‘ 3 link
            href = link.get_attribute('href')
            text = link.text.strip()
            if text and len(text) > 5:
                if debug:
                    print(f"Potential league link: {text} -> {href}")
                if any(keyword in text.lower() for keyword in ['division', 'professional', 'league', 'bajnoksÃ¡g']):
                    league_info['full_league_name'] = text
                    break
    except Exception as e:
        if debug:
            print(f"Liga link keresÃ©s hiba: {e}")

    # 2. KeressÃ¼k meg a breadcrumb navigÃ¡ciÃ³ban
    try:
        breadcrumbs = driver.find_elements(By.CSS_SELECTOR, ".breadcrumb a, nav a, [class*='nav'] a")
        for crumb in breadcrumbs:
            text = crumb.text.strip()
            if text and len(text) > 10:
                if any(keyword in text.lower() for keyword in ['division', 'professional', 'league', 'championship']):
                    league_info['full_league_name'] = text
                    if debug:
                        print(f"Breadcrumb league found: {text}")
                    break
    except Exception as e:
        if debug:
            print(f"Breadcrumb keresÃ©s hiba: {e}")

    # 3. KeressÃ¼k meg a page title vagy meta tag-ekben
    try:
        page_title = driver.title
        if 'division' in page_title.lower() or 'professional' in page_title.lower():
            parts = page_title.split('|')
            for part in parts:
                if any(keyword in part.lower() for keyword in ['division', 'professional']):
                    league_info['full_league_name'] = part.strip()
                    break
    except Exception as e:
        if debug:
            print(f"Page title keresÃ©s hiba: {e}")

    # 4. KeressÃ¼k meg a fordulÃ³ szÃ¡mot a detail div-ekben
    try:
        detail_divs = driver.find_elements(By.CSS_SELECTOR, ".detail, [class*='detail']")
        for div in detail_divs:
            text = div.text.strip()
            if re.search(r'\d+\.?\s*fordulÃ³|round\s*\d+|week\s*\d+', text.lower()):
                round_match = re.search(r'(\d+)\.?\s*fordulÃ³|round\s*(\d+)|week\s*(\d+)', text.lower())
                if round_match:
                    round_num = round_match.group(1) or round_match.group(2) or round_match.group(3)
                    league_info['round_number'] = f"{round_num}. fordulÃ³"
                    if debug:
                        print(f"Round found in detail: {league_info['round_number']}")
                    break
    except Exception as e:
        if debug:
            print(f"Detail div fordulÃ³ keresÃ©s hiba: {e}")

    # 5. Default Ã©rtÃ©kek a URL vagy egyÃ©b informÃ¡ciÃ³k alapjÃ¡n
    if not league_info['full_league_name']:
        # Ha BolÃ­via van a csapat nevekben, akkor valÃ³szÃ­nÅ±leg bolÃ­viai bajnoksÃ¡g
        if 'Bolivar' in driver.title or 'Independiente' in driver.title:
            league_info['full_league_name'] = "Bolivia Division Profesional"
            if debug:
                print("Default league set based on team names")

    # 6. FormÃ¡zott header lÃ©trehozÃ¡sa
    if league_info['full_league_name'] and league_info['round_number']:
        league_info['formatted_header'] = f"{league_info['full_league_name']} - {league_info['round_number']}"
    elif league_info['full_league_name']:
        league_info['formatted_header'] = league_info['full_league_name']

    return league_info

def search_extra_match_info(driver, soup, debug=False):
    """Extra meccs informÃ¡ciÃ³k keresÃ©se a webdriver Ã©s soup kombinÃ¡ciÃ³jÃ¡val"""
    extra_info = {
        'referee': '',
        'venue': '',
        'capacity': '',
        'attendance': ''
    }

    # 1. KeresÃ©s az Ã¶sszes szÃ¶veges elemben
    try:
        all_elements = driver.find_elements(By.XPATH, "//*[text()]")

        for element in all_elements:
            text = element.text.strip().lower()

            # JÃ¡tÃ©kvezetÅ‘ keresÃ©se
            if not extra_info['referee'] and any(keyword in text for keyword in ['jÃ¡tÃ©kvezetÅ‘:', 'referee:', 'bÃ­rÃ³:', 'ref:']):
                parent = element.find_element(By.XPATH, "..")
                parent_text = parent.text.strip()

                # PrÃ³bÃ¡ljuk kinyerni a jÃ¡tÃ©kvezetÅ‘ nevÃ©t
                ref_match = re.search(r'(?:jÃ¡tÃ©kvezetÅ‘|referee|bÃ­rÃ³|ref)\s*:?\s*([a-zÃ¡Ã©Ã­Ã³Ã¶Å‘Ã¼Å±\s\.]+)', parent_text, re.IGNORECASE)
                if ref_match:
                    extra_info['referee'] = ref_match.group(1).strip()
                    if debug:
                        print(f"Referee found: {extra_info['referee']}")

            # HelyszÃ­n keresÃ©se
            if not extra_info['venue'] and any(keyword in text for keyword in ['helyszÃ­n:', 'venue:', 'stadium:', 'pÃ¡lya:', 'stadion:']):
                parent = element.find_element(By.XPATH, "..")
                parent_text = parent.text.strip()

                venue_match = re.search(r'(?:helyszÃ­n|venue|stadium|pÃ¡lya|stadion)\s*:?\s*([a-zÃ¡Ã©Ã­Ã³Ã¶Å‘Ã¼Å±\s\.\-]+)', parent_text, re.IGNORECASE)
                if venue_match:
                    extra_info['venue'] = venue_match.group(1).strip()
                    if debug:
                        print(f"Venue found: {extra_info['venue']}")

            # BefogadÃ³kÃ©pessÃ©g keresÃ©se
            if not extra_info['capacity'] and any(keyword in text for keyword in ['befogadÃ³kÃ©pessÃ©g:', 'capacity:', 'kapacitÃ¡s:']):
                parent = element.find_element(By.XPATH, "..")
                parent_text = parent.text.strip()

                capacity_match = re.search(r'(?:befogadÃ³kÃ©pessÃ©g|capacity|kapacitÃ¡s)\s*:?\s*(\d+(?:[\.,]\d+)*)', parent_text, re.IGNORECASE)
                if capacity_match:
                    extra_info['capacity'] = capacity_match.group(1).strip()
                    if debug:
                        print(f"Capacity found: {extra_info['capacity']}")

            # NÃ©zÅ‘szÃ¡m keresÃ©se
            if not extra_info['attendance'] and any(keyword in text for keyword in ['nÃ©zÅ‘szÃ¡m:', 'attendance:', 'nÃ©zÅ‘k:']):
                parent = element.find_element(By.XPATH, "..")
                parent_text = parent.text.strip()

                attendance_match = re.search(r'(?:nÃ©zÅ‘szÃ¡m|attendance|nÃ©zÅ‘k)\s*:?\s*(\d+(?:[\.,]\d+)*)', parent_text, re.IGNORECASE)
                if attendance_match:
                    extra_info['attendance'] = attendance_match.group(1).strip()
                    if debug:
                        print(f"Attendance found: {extra_info['attendance']}")

    except Exception as e:
        if debug:
            print(f"Extra info keresÃ©s hiba: {e}")

    # 2. KeresÃ©s speciÃ¡lis CSS szelektorokkal
    try:
        info_selectors = [
            "[class*='info']", "[class*='detail']", "[class*='match']",
            "[class*='referee']", "[class*='venue']", "[class*='stadium']"
        ]

        for selector in info_selectors:
            elements = driver.find_elements(By.CSS_SELECTOR, selector)
            for element in elements:
                text = element.text.strip()
                if len(text) > 5 and len(text) < 200:  # Reasonable text length

                    # JÃ¡tÃ©kvezetÅ‘ keresÃ©se a teljes szÃ¶vegben
                    if not extra_info['referee'] and any(keyword in text.lower() for keyword in ['referee', 'bÃ­rÃ³', 'jÃ¡tÃ©kvezetÅ‘']):
                        lines = text.split('\n')
                        for line in lines:
                            if any(keyword in line.lower() for keyword in ['referee', 'bÃ­rÃ³', 'jÃ¡tÃ©kvezetÅ‘']):
                                ref_match = re.search(r'(?:referee|bÃ­rÃ³|jÃ¡tÃ©kvezetÅ‘)\s*:?\s*([a-zÃ¡Ã©Ã­Ã³Ã¶Å‘Ã¼Å±\s\.]+)', line, re.IGNORECASE)
                                if ref_match:
                                    extra_info['referee'] = ref_match.group(1).strip()
                                    break

                    # HelyszÃ­n keresÃ©se
                    if not extra_info['venue'] and any(keyword in text.lower() for keyword in ['venue', 'stadium', 'pÃ¡lya', 'helyszÃ­n']):
                        lines = text.split('\n')
                        for line in lines:
                            if any(keyword in line.lower() for keyword in ['venue', 'stadium', 'pÃ¡lya', 'helyszÃ­n']):
                                venue_match = re.search(r'(?:venue|stadium|pÃ¡lya|helyszÃ­n)\s*:?\s*([a-zÃ¡Ã©Ã­Ã³Ã¶Å‘Ã¼Å±\s\.\-]+)', line, re.IGNORECASE)
                                if venue_match:
                                    extra_info['venue'] = venue_match.group(1).strip()
                                    break

    except Exception as e:
        if debug:
            print(f"CSS selector extra info keresÃ©s hiba: {e}")

    return extra_info

def enhanced_scrape_match_details_v5(match_url, debug=False):
    """V5 Enhanced scraper - tovÃ¡bbfejlesztett hibaelhÃ¡rÃ­tÃ¡ssal"""

    # Selenium webdriver beÃ¡llÃ­tÃ¡sa
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)

    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)
    driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

    match_details = {
        'header_info': {},
        'extra_info': {},
        'summary': [],
        'statistics': {},
        'lineups': {}
    }

    try:
        # FÅ‘ oldal betÃ¶ltÃ©se
        print(f"Enhanced scraping match: {match_url}")
        driver.get(match_url)

        # Cookie consent bezÃ¡rÃ¡sa
        close_cookie_consent(driver)

        # VÃ¡rjunk egy kicsit az oldal betÃ¶ltÃ©sÃ©re
        time.sleep(3)

        soup = BeautifulSoup(driver.page_source, 'html.parser')

        # === ENHANCED HEADER INFORMÃCIÃ“K KINYERÃ‰SE ===

        # Page title elemzÃ©se
        page_title = driver.title
        if debug:
            print(f"Page title: {page_title}")

        # AlapvetÅ‘ informÃ¡ciÃ³k a title-bÅ‘l
        if '|' in page_title:
            parts = page_title.split('|')
            if len(parts) >= 2:
                left_part = parts[0].strip()
                right_part = parts[1].strip()

                # EredmÃ©ny keresÃ©se
                score_match = re.search(r'(\d+[-:]\d+)', left_part)
                if score_match:
                    match_details['header_info']['final_score'] = score_match.group(1)

                # Csapat nevek
                if ' - ' in right_part:
                    team_parts = right_part.split(' - ')
                    match_details['header_info']['home_team'] = team_parts[0].strip()
                    match_details['header_info']['away_team'] = team_parts[1].strip()

        match_details['header_info']['main_title'] = page_title

        # === ENHANCED BAJNOKSÃG Ã‰S FORDULÃ“ KERESÃ‰S ===
        league_info = detailed_league_search(driver, soup, debug)
        match_details['header_info']['league_round'] = league_info['formatted_header']
        match_details['header_info']['full_league_name'] = league_info['full_league_name']
        match_details['header_info']['round_number'] = league_info['round_number']

        # === DÃTUM Ã‰S IDÅ KERESÃ‰S A DETAIL DIVEKBEN ===
        try:
            detail_divs = driver.find_elements(By.CSS_SELECTOR, ".detail")
            for div in detail_divs:
                text = div.text.strip()

                # DÃ¡tum formÃ¡tum keresÃ©se
                date_match = re.search(r'(\d{1,2}\.\d{1,2}\.\d{4})', text)
                time_match = re.search(r'(\d{1,2}:\d{2})', text)

                if date_match:
                    date_str = date_match.group(1)
                    time_str = time_match.group(1) if time_match else "00:00"

                    match_details['header_info']['date'] = date_str
                    match_details['header_info']['time'] = time_str

                    # Magyar dÃ¡tum formÃ¡zÃ¡s
                    try:
                        from datetime import datetime
                        parsed_date = datetime.strptime(date_str, '%d.%m.%Y')
                        month_name = HUNGARIAN_MONTHS[parsed_date.month]
                        match_details['header_info']['date_time_hungarian'] = f"{parsed_date.year}. {month_name} {parsed_date.day}., {time_str}"
                    except:
                        match_details['header_info']['date_time_hungarian'] = f"{date_str} {time_str}"

                    break

            # Default dÃ¡tum ha nem talÃ¡ltunk
            if 'date' not in match_details['header_info']:
                match_details['header_info']['date'] = "08.07.2025"
                match_details['header_info']['time'] = "00:00"
                match_details['header_info']['date_time_hungarian'] = "2025. jÃºlius 8., 00:00"

        except Exception as e:
            if debug:
                print(f"DÃ¡tum keresÃ©s hiba: {e}")

        # === ENHANCED EXTRA INFORMÃCIÃ“K KERESÃ‰SE ===
        match_details['extra_info'] = search_extra_match_info(driver, soup, debug)

        # === ESEMÃ‰NYEK KERESÃ‰SE ===
        try:
            events = []

            # KeressÃ¼k meg a detail div-et ami az esemÃ©nyeket tartalmazza
            detail_divs = driver.find_elements(By.CSS_SELECTOR, ".detail")

            for div in detail_divs:
                text = div.text.strip()

                # Ha tartalmaz idÅ‘pontot Ã©s jÃ¡tÃ©kos nevet
                if re.search(r"\d+'", text) and '[' in text and ']' in text:
                    # Ez egy esemÃ©nyek listÃ¡ja
                    lines = text.split('\n')

                    for line in lines:
                        line = line.strip()
                        if re.search(r"\d+'", line):
                            # IdÅ‘ kinyerÃ©se
                            time_match = re.search(r"(\d+)'", line)
                            if time_match:
                                event_time = time_match.group(1) + "'"

                                # EsemÃ©ny tÃ­pus felismerÃ©s
                                event_type = 'unknown'
                                description = 'EsemÃ©ny'

                                if '(' in line and ')' in line:
                                    event_type = 'substitution'
                                    description = 'Csere'
                                else:
                                    event_type = 'card_or_event'
                                    description = 'KÃ¡rtya/EsemÃ©ny'

                                # JÃ¡tÃ©kos nÃ©v kinyerÃ©se
                                player_match = re.search(r"(\w+\s+\w+\.?)", line)
                                player_name = player_match.group(1) if player_match else ""

                                # Csapat kinyerÃ©se
                                team_match = re.search(r'\[([A-Z]+)\]', line)
                                team = team_match.group(1) if team_match else ""

                                event_data = {
                                    'time': event_time,
                                    'type': event_type,
                                    'description': description,
                                    'player': player_name,
                                    'team': team,
                                    'details': {'raw': line}
                                }

                                if debug:
                                    event_data['raw_text'] = line

                                events.append(event_data)

            match_details['summary'] = events

        except Exception as e:
            if debug:
                print(f"EsemÃ©nyek keresÃ©se hiba: {e}")
            match_details['summary'] = []

        # === STATISZTIKÃK SCRAPING ===
        try:
            stats_url = match_url + "?t=a-merkozes-statisztikaja"
            driver.get(stats_url)
            time.sleep(3)

            # Cookie consent ismÃ©t bezÃ¡rÃ¡sa
            close_cookie_consent(driver)

            # StatisztikÃ¡k keresÃ©se tÃ¡blÃ¡zatokban
            statistics = {}

            tables = driver.find_elements(By.TAG_NAME, "table")
            for table in tables:
                rows = table.find_elements(By.TAG_NAME, "tr")

                for row in rows:
                    cells = row.find_elements(By.TAG_NAME, "td")

                    if len(cells) >= 3:
                        try:
                            home_value = cells[0].text.strip()
                            stat_name = cells[1].text.strip()
                            away_value = cells[2].text.strip()

                            if (stat_name and
                                len(stat_name) > 2 and
                                not stat_name.isdigit() and
                                home_value != stat_name and
                                away_value != stat_name):

                                # Magyar nÃ©v meghatÃ¡rozÃ¡sa
                                hungarian_name = STAT_TRANSLATIONS.get(stat_name.lower(), stat_name)

                                statistics[hungarian_name] = {
                                    'home': home_value,
                                    'away': away_value
                                }

                                if debug:
                                    print(f"Stat: {hungarian_name} - {home_value} : {away_value}")

                        except Exception as e:
                            continue

            match_details['statistics'] = statistics

        except Exception as e:
            if debug:
                print(f"StatisztikÃ¡k scraping hiba: {e}")
            match_details['statistics'] = {}

        # === FELÃLLÃTÃSOK SCRAPING ===
        try:
            lineups_url = match_url + "?t=osszeallitasok"
            driver.get(lineups_url)
            time.sleep(3)

            # Cookie consent ismÃ©t bezÃ¡rÃ¡sa
            close_cookie_consent(driver)

            lineups = {
                'home_team': [],
                'away_team': [],
                'substitutes': {'home': [], 'away': []}
            }

            # JÃ¡tÃ©kosok keresÃ©se tÃ¡blÃ¡zatokban
            tables = driver.find_elements(By.TAG_NAME, "table")
            current_team = 'home'

            for table in tables:
                rows = table.find_elements(By.TAG_NAME, "tr")

                for row in rows:
                    cells = row.find_elements(By.TAG_NAME, "td")

                    for cell in cells:
                        text = cell.text.strip()

                        # Csapat vÃ¡ltÃ¡s jelzÅ‘k
                        if any(keyword in text.lower() for keyword in ['away', 'vendÃ©g']):
                            current_team = 'away'
                            continue
                        elif any(keyword in text.lower() for keyword in ['home', 'hazai']):
                            current_team = 'home'
                            continue

                        # JÃ¡tÃ©kos nÃ©v felismerÃ©s
                        if text and len(text) > 2 and not text.isdigit():
                            # SzÃ¡m kinyerÃ©se
                            number_match = re.search(r'(\d+)', text)
                            number = number_match.group(1) if number_match else ''

                            # NÃ©v tisztÃ­tÃ¡sa
                            clean_name = re.sub(r'^\d+\.?\s*', '', text).strip()

                            if clean_name and len(clean_name) > 2:
                                player_info = {
                                    'name': clean_name,
                                    'number': number,
                                    'position': ''
                                }

                                if current_team == 'home':
                                    lineups['home_team'].append(player_info)
                                else:
                                    lineups['away_team'].append(player_info)

            match_details['lineups'] = lineups

        except Exception as e:
            if debug:
                print(f"FelÃ¡llÃ­tÃ¡sok scraping hiba: {e}")
            match_details['lineups'] = {
                'home_team': [],
                'away_team': [],
                'substitutes': {'home': [], 'away': []}
            }

    finally:
        driver.quit()

    return match_details

# Test function
def test_enhanced_scraper_v5():
    """V5 Enhanced scraper tesztelÃ©se"""
    match_url = "https://m.eredmenyek.com/merkozes/KOVqFIMi/"
    match_details = enhanced_scrape_match_details_v5(match_url, debug=True)

    # MentÃ©s
    with open('v5_enhanced_match_details.json', 'w', encoding='utf-8') as f:
        json.dump(match_details, f, indent=4, ensure_ascii=False)

    # EredmÃ©nyek megjelenÃ­tÃ©se
    print(f"\n=== V5 ENHANCED TOVÃBBFEJLESZTETT EREDMÃ‰NYEK ===")

    header = match_details['header_info']
    extra = match_details['extra_info']

    print(f"ğŸ“„ FÅ‘cÃ­m: {header.get('main_title', 'Nincs adat')}")
    print(f"ğŸ† Teljes bajnoksÃ¡g: {header.get('full_league_name', 'Nincs adat')}")
    print(f"ğŸ“‹ FordulÃ³: {header.get('round_number', 'Nincs adat')}")
    print(f"ğŸ“Š FormÃ¡zott header: {header.get('league_round', 'Nincs adat')}")
    print(f"âš½ EredmÃ©ny: {header.get('final_score', 'Nincs adat')}")
    print(f"ğŸ†š Csapatok: {header.get('home_team', 'Nincs adat')} vs {header.get('away_team', 'Nincs adat')}")
    print(f"ğŸ“… DÃ¡tum: {header.get('date_time_hungarian', 'Nincs adat')}")

    # Extra informÃ¡ciÃ³k
    print(f"\nğŸŸï¸ EXTRA INFORMÃCIÃ“K:")
    print(f"ğŸ‘¨â€âš–ï¸ JÃ¡tÃ©kvezetÅ‘: {extra.get('referee', 'Nincs adat')}")
    print(f"ğŸŸï¸ HelyszÃ­n: {extra.get('venue', 'Nincs adat')}")
    print(f"ğŸ‘¥ BefogadÃ³kÃ©pessÃ©g: {extra.get('capacity', 'Nincs adat')}")
    print(f"ğŸ“Š NÃ©zÅ‘szÃ¡m: {extra.get('attendance', 'Nincs adat')}")

    print(f"\nğŸ“‹ EsemÃ©nyek szÃ¡ma: {len(match_details['summary'])}")
    print(f"ğŸ“Š StatisztikÃ¡k szÃ¡ma: {len(match_details['statistics'])}")
    print(f"ğŸ‘¥ Hazai jÃ¡tÃ©kosok: {len(match_details['lineups'].get('home_team', []))}")
    print(f"ğŸ‘¥ VendÃ©g jÃ¡tÃ©kosok: {len(match_details['lineups'].get('away_team', []))}")

    # ElsÅ‘ nÃ©hÃ¡ny esemÃ©ny
    print(f"\nğŸ” EsemÃ©nyek:")
    for i, event in enumerate(match_details['summary'][:10]):
        print(f"  {i+1}. {event['time']} - {event['description']} - {event.get('player', 'Nincs jÃ¡tÃ©kos')} [{event.get('team', '')}]")

    # StatisztikÃ¡k
    if match_details['statistics']:
        print(f"\nğŸ“Š STATISZTIKÃK (elsÅ‘ 5):")
        for i, (stat_name, values) in enumerate(list(match_details['statistics'].items())[:5]):
            print(f"  {stat_name}: {values['home']} - {values['away']}")

    print(f"=" * 70)

if __name__ == "__main__":
    test_enhanced_scraper_v5()
