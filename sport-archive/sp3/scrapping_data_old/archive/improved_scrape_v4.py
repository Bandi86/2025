import requests
from bs4 import BeautifulSoup
from bs4.element import NavigableString
import json
from datetime import datetime, timezone
from collections import defaultdict
import re
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

# Magyar hÃ³napnevek a dÃ¡tum formÃ¡zÃ¡shoz
HUNGARIAN_MONTHS = {
    1: 'januÃ¡r', 2: 'februÃ¡r', 3: 'mÃ¡rcius', 4: 'Ã¡prilis',
    5: 'mÃ¡jus', 6: 'jÃºnius', 7: 'jÃºlius', 8: 'augusztus',
    9: 'szeptember', 10: 'oktÃ³ber', 11: 'november', 12: 'december'
}

# Statisztika tÃ­pusok magyar fordÃ­tÃ¡sokkal
STATS_TRANSLATION = {
    'ball possession': 'LabdabirtoklÃ¡s',
    'possession': 'LabdabirtoklÃ¡s',
    'shots': 'LÃ¶vÃ©sek',
    'shots on target': 'Kapura lÃ¶vÃ©sek',
    'shots on goal': 'Kapura lÃ¶vÃ©sek',
    'corners': 'SzÃ¶gletek',
    'corner kicks': 'SzÃ¶gletek',
    'fouls': 'SzabÃ¡lytalansÃ¡gok',
    'yellow cards': 'SÃ¡rga lapok',
    'red cards': 'Piros lapok',
    'offsides': 'Lesek',
    'passes': 'Passzok',
    'pass accuracy': 'PasszpontossÃ¡g',
    'free kicks': 'SzabadrÃºgÃ¡sok',
    'throw ins': 'BedobÃ¡sok',
    'goal kicks': 'KapusrÃºgÃ¡sok',
    'crosses': 'BeadÃ¡sok',
    'tackles': 'SzerelÃ©sek',
    'saves': 'VÃ©dÃ©sek',
    'goalkeeper saves': 'Kapus vÃ©dÃ©sek'
}

def format_hungarian_date(date_str, time_str):
    """KonvertÃ¡lja a dÃ¡tumot magyar formÃ¡tumba"""
    try:
        # PrÃ³bÃ¡ljuk meg kÃ¼lÃ¶nbÃ¶zÅ‘ formÃ¡tumokkal
        for date_format in ['%d.%m.', '%d.%m.%Y', '%Y-%m-%d']:
            try:
                if date_format == '%d.%m.':
                    # HozzÃ¡adjuk az aktuÃ¡lis Ã©vet
                    current_year = datetime.now().year
                    full_date_str = f"{date_str}{current_year}"
                    parsed_date = datetime.strptime(full_date_str, '%d.%m.%Y')
                else:
                    parsed_date = datetime.strptime(date_str, date_format)
                break
            except ValueError:
                continue
        else:
            return f"{date_str} {time_str}"

        # Magyar formÃ¡tum: 2025. jÃºlius 8., 18:00
        month_name = HUNGARIAN_MONTHS[parsed_date.month]
        return f"{parsed_date.year}. {month_name} {parsed_date.day}., {time_str}"
    except:
        return f"{date_str} {time_str}"

def analyze_event_type_from_raw_text(raw_text):
    """Fejlett esemÃ©ny tÃ­pus felismerÃ©s a raw_text alapjÃ¡n"""
    text = raw_text.lower()

    # GÃ³l felismerÃ©s (fejlesztett)
    if any(keyword in text for keyword in ['goal', 'gol', 'gÃ³l']):
        if 'penalty' in text or 'tizenegy' in text or 'pen' in text:
            return 'penalty_goal', 'TizenegyesgÃ³l', parse_goal_details(raw_text)
        else:
            return 'goal', 'GÃ³l', parse_goal_details(raw_text)

    # Csere felismerÃ©s (fejlesztett)
    if '(' in raw_text and ')' in raw_text:
        substitution_details = parse_substitution_details(raw_text)
        if substitution_details.get('type') == 'substitution':
            return 'substitution', 'Csere', substitution_details

    # KÃ¡rtya felismerÃ©s (fejlesztett)
    if any(keyword in text for keyword in ['yellow', 'red', 'card', 'sÃ¡rga', 'piros', 'lap']):
        if any(keyword in text for keyword in ['yellow', 'sÃ¡rga']):
            return 'yellow_card', 'SÃ¡rga lap', parse_card_details(raw_text)
        elif any(keyword in text for keyword in ['red', 'piros']):
            return 'red_card', 'Piros lap', parse_card_details(raw_text)
        else:
            return 'card', 'Lap', parse_card_details(raw_text)

    # EgyÃ©b esemÃ©nyek
    if any(keyword in text for keyword in ['injury', 'sÃ©rÃ¼lÃ©s']):
        return 'injury', 'SÃ©rÃ¼lÃ©s', parse_general_event(raw_text)

    if any(keyword in text for keyword in ['var', 'video']):
        return 'var', 'VAR', parse_general_event(raw_text)

    # AlapÃ©rtelmezett
    return 'event', 'EsemÃ©ny', parse_general_event(raw_text)

def parse_goal_details(raw_text):
    """GÃ³l rÃ©szletek kinyerÃ©se"""
    # FormÃ¡tum: "15'Player Name [TEAM]" vagy "15'Player Name (assist) [TEAM]"
    match = re.match(r"(\d+['+])([^[]+)\[([A-Z]+)\]", raw_text)
    if match:
        time = match.group(1)
        player_info = match.group(2).strip()
        team = match.group(3)

        # GÃ³lpassz keresÃ©se
        assist_match = re.search(r'\(([^)]+)\)', player_info)
        assist = assist_match.group(1).strip() if assist_match else None

        # JÃ¡tÃ©kos nÃ©v tisztÃ­tÃ¡sa
        player = re.sub(r'\([^)]*\)', '', player_info).strip()

        return {
            'player': player,
            'team': team,
            'assist': assist,
            'type': 'goal'
        }

    return parse_general_event(raw_text)

def parse_substitution_details(raw_text):
    """Csere rÃ©szletek kinyerÃ©se"""
    # FormÃ¡tum: "46'Arteaga N.(Mercado A.)[IND]"
    match = re.match(r"(\d+['+])([^(]+)\(([^)]+)\)\s*\[([A-Z]+)\]", raw_text)
    if match:
        return {
            'time': match.group(1),
            'player_in': match.group(2).strip(),
            'player_out': match.group(3).strip(),
            'team': match.group(4),
            'type': 'substitution'
        }
    return parse_general_event(raw_text)

def parse_card_details(raw_text):
    """KÃ¡rtya rÃ©szletek kinyerÃ©se"""
    match = re.match(r"(\d+['+])([^[]+)\[([A-Z]+)\]", raw_text)
    if match:
        return {
            'time': match.group(1),
            'player': match.group(2).strip(),
            'team': match.group(3),
            'type': 'card'
        }
    return parse_general_event(raw_text)

def parse_general_event(raw_text):
    """ÃltalÃ¡nos esemÃ©ny feldolgozÃ¡s"""
    match = re.match(r"(\d+['+])([^[]+)\[([A-Z]+)\]", raw_text)
    if match:
        return {
            'time': match.group(1),
            'player': match.group(2).strip(),
            'team': match.group(3),
            'type': 'general'
        }
    return {'raw': raw_text}

def extract_league_and_round_info(soup, debug=False):
    """BajnoksÃ¡g Ã©s fordulÃ³ informÃ¡ciÃ³ kinyerÃ©se"""
    league_info = {
        'competition': '',
        'round': '',
        'full_name': ''
    }

    # KeressÃ¼nk a navigÃ¡ciÃ³ban vagy breadcrumb-ban
    nav_elements = soup.select('.breadcrumb, .navigation, nav, [class*="league"], [class*="competition"], [class*="round"]')

    for nav in nav_elements:
        text = nav.get_text(strip=True)
        if debug:
            print(f"Nav element text: {text}")

        # KeressÃ¼k a bajnoksÃ¡g nevÃ©t Ã©s fordulÃ³ szÃ¡mot
        if any(keyword in text.lower() for keyword in ['division', 'league', 'cup', 'bajnoksÃ¡g', 'fordulÃ³']):
            # PrÃ³bÃ¡ljuk meg kinyerni a fordulÃ³ szÃ¡mot
            round_match = re.search(r'(\d+)\.?\s*fordulÃ³', text, re.IGNORECASE)
            if round_match:
                league_info['round'] = f"{round_match.group(1)}. fordulÃ³"

            # BajnoksÃ¡g nÃ©v keresÃ©se
            comp_match = re.search(r'([A-Za-z\s]+(?:Division|League|Cup|BajnoksÃ¡g)[A-Za-z\s]*)', text, re.IGNORECASE)
            if comp_match:
                league_info['competition'] = comp_match.group(1).strip()

    # KeressÃ¼nk a header-ben vagy title-ben is
    header_elements = soup.select('h1, h2, h3, .header, .title, [class*="match-header"]')

    for header in header_elements:
        text = header.get_text(strip=True)
        if debug:
            print(f"Header element text: {text}")

        # FormÃ¡tum keresÃ©se: "FociboBolÃ­viaDivision Profesional - 13. fordulÃ³"
        league_round_match = re.search(r'([A-Za-z\s]+(?:Division|League|Cup)[A-Za-z\s]*)\s*-\s*(\d+\.?\s*fordulÃ³)', text, re.IGNORECASE)
        if league_round_match:
            league_info['competition'] = league_round_match.group(1).strip()
            league_info['round'] = league_round_match.group(2).strip()
            break

    # Teljes nÃ©v Ã¶sszeÃ¡llÃ­tÃ¡sa
    if league_info['competition'] and league_info['round']:
        league_info['full_name'] = f"{league_info['competition']} - {league_info['round']}"
    elif league_info['competition']:
        league_info['full_name'] = league_info['competition']

    return league_info

def scrape_statistics_improved(driver, base_url, debug=False):
    """JavÃ­tott statisztikÃ¡k scraping-je magyar elnevezÃ©sekkel"""
    try:
        stats_url = base_url + "?t=a-merkozes-statisztikaja"
        print(f"Trying stats URL: {stats_url}")
        driver.get(stats_url)

        # VÃ¡rjunk egy kicsit
        import time
        time.sleep(2)

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        statistics = {}

        # KeressÃ¼k meg a statisztika tÃ¡blÃ¡zatokat
        stat_tables = soup.select('table, .stats, .statistics, [class*="stat"]')

        if debug:
            print(f"Found {len(stat_tables)} potential stats tables")

        for table in stat_tables:
            rows = table.select('tr, .stat-row, [class*="row"]')

            for row in rows:
                cells = row.select('td, th, .stat-cell, .value, [class*="cell"]')

                if len(cells) >= 3:  # Hazai - Statisztika nÃ©v - VendÃ©g
                    home_value = cells[0].get_text(strip=True)
                    stat_name = cells[1].get_text(strip=True)
                    away_value = cells[2].get_text(strip=True)

                    # Csak ha mindhÃ¡rom Ã©rtÃ©k lÃ©tezik Ã©s a stat_name nem szÃ¡m
                    if home_value and stat_name and away_value and not stat_name.replace('.', '').replace('%', '').isdigit():
                        # Magyar elnevezÃ©s keresÃ©se
                        hungarian_name = translate_stat_name(stat_name)

                        statistics[hungarian_name] = {
                            'hazai': home_value,
                            'vendÃ©g': away_value
                        }

                        if debug:
                            print(f"Stat: {hungarian_name} -> Hazai: {home_value}, VendÃ©g: {away_value}")

        # Ha nincs eredmÃ©ny, prÃ³bÃ¡ljuk meg mÃ¡s mÃ³dszerrel
        if not statistics:
            # KeressÃ¼k meg a szÃ¡mokat Ã©s szÃ¶vegeket pÃ¡rosÃ­tva
            all_elements = soup.select('span, div, td, th')
            potential_stats = []

            for elem in all_elements:
                text = elem.get_text(strip=True)
                if text and len(text) > 1:
                    # Ha szÃ¡mot vagy szÃ¡zalÃ©kot tartalmaz
                    if re.search(r'\d+', text):
                        potential_stats.append(text)

            # PrÃ³bÃ¡ljuk meg pÃ¡rosÃ­tani a statisztikÃ¡kat
            for i in range(0, len(potential_stats)-2, 3):
                try:
                    home_val = potential_stats[i]
                    stat_name = potential_stats[i+1]
                    away_val = potential_stats[i+2]

                    # EllenÅ‘rizzÃ¼k hogy Ã©rtelmes-e
                    if (re.search(r'\d', home_val) and
                        re.search(r'\d', away_val) and
                        not stat_name.replace('.', '').replace('%', '').isdigit() and
                        len(stat_name) > 2):

                        hungarian_name = translate_stat_name(stat_name)
                        statistics[hungarian_name] = {
                            'hazai': home_val,
                            'vendÃ©g': away_val
                        }
                except:
                    continue

        return statistics

    except Exception as e:
        print(f"Error scraping statistics: {e}")
        return {}

def translate_stat_name(stat_name):
    """Statisztika nÃ©v fordÃ­tÃ¡sa magyarra"""
    stat_lower = stat_name.lower().strip()

    # KeressÃ¼k meg a megfelelÅ‘ fordÃ­tÃ¡st
    for english, hungarian in STATS_TRANSLATION.items():
        if english in stat_lower:
            return hungarian

    # Ha nincs fordÃ­tÃ¡s, prÃ³bÃ¡ljuk meg kitalÃ¡lni a tÃ­pust
    if any(word in stat_lower for word in ['possession', 'ball']):
        return 'LabdabirtoklÃ¡s'
    elif any(word in stat_lower for word in ['shot', 'lÃ¶vÃ©s']):
        return 'LÃ¶vÃ©sek'
    elif any(word in stat_lower for word in ['corner', 'szÃ¶glet']):
        return 'SzÃ¶gletek'
    elif any(word in stat_lower for word in ['foul', 'szabÃ¡ly']):
        return 'SzabÃ¡lytalansÃ¡gok'
    elif any(word in stat_lower for word in ['card', 'lap']):
        return 'Lapok'
    elif any(word in stat_lower for word in ['pass', 'passz']):
        return 'Passzok'

    # Ha semmi sem illeszkedik, visszaadjuk az eredetit
    return stat_name

def scrape_lineups(driver, base_url, debug=False):
    """FelÃ¡llÃ­tÃ¡sok scraping-je"""
    try:
        lineups_url = base_url + "?t=osszeallitasok"
        print(f"Trying lineups URL: {lineups_url}")
        driver.get(lineups_url)

        # VÃ¡rjunk egy kicsit
        import time
        time.sleep(2)

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        lineups = {
            'hazai_csapat': [],
            'vendÃ©g_csapat': [],
            'cserÃ©k': {
                'hazai': [],
                'vendÃ©g': []
            }
        }

        # KeressÃ¼k meg a felÃ¡llÃ­tÃ¡s tÃ¡blÃ¡zatokat
        lineup_tables = soup.select('table, .lineup, [class*="formation"], [class*="player"]')

        for table in lineup_tables:
            # KeressÃ¼k meg a jÃ¡tÃ©kosokat
            players = table.select('tr, .player, [class*="player-name"]')

            current_team = None
            for player_elem in players:
                player_text = player_elem.get_text(strip=True)

                # PrÃ³bÃ¡ljuk meghatÃ¡rozni melyik csapathoz tartozik
                if any(keyword in player_text.lower() for keyword in ['home', 'hazai', 'away', 'vendÃ©g']):
                    current_team = 'hazai' if any(keyword in player_text.lower() for keyword in ['home', 'hazai']) else 'vendÃ©g'
                    continue

                # Ha jÃ¡tÃ©kos nevnek tÅ±nik
                if player_text and len(player_text) > 2 and not player_text.isdigit():
                    player_info = {
                        'nÃ©v': player_text,
                        'mezszÃ¡m': extract_player_number(player_text),
                        'pozÃ­ciÃ³': extract_player_position(player_text)
                    }

                    if current_team == 'hazai':
                        lineups['hazai_csapat'].append(player_info)
                    elif current_team == 'vendÃ©g':
                        lineups['vendÃ©g_csapat'].append(player_info)
                    else:
                        # Ha nem tudjuk meghatÃ¡rozni, prÃ³bÃ¡ljuk meg a kontextusbÃ³l
                        # AlapÃ©rtelmezetten hazai csapat, ha kevesebb jÃ¡tÃ©kos van ott
                        if len(lineups['hazai_csapat']) <= len(lineups['vendÃ©g_csapat']):
                            lineups['hazai_csapat'].append(player_info)
                        else:
                            lineups['vendÃ©g_csapat'].append(player_info)

        return lineups

    except Exception as e:
        print(f"Error scraping lineups: {e}")
        return {
            'hazai_csapat': [],
            'vendÃ©g_csapat': [],
            'cserÃ©k': {'hazai': [], 'vendÃ©g': []}
        }

def extract_player_number(player_text):
    """JÃ¡tÃ©kos mezszÃ¡m kinyerÃ©se"""
    # KeressÃ¼k meg a szÃ¡mot a szÃ¶veg elejÃ©n vagy vÃ©gÃ©n
    number_match = re.search(r'(\d+)', player_text)
    return number_match.group(1) if number_match else None

def extract_player_position(player_text):
    """JÃ¡tÃ©kos pozÃ­ciÃ³ kinyerÃ©se (ha van)"""
    # KeressÃ¼k meg a pozÃ­ciÃ³ rÃ¶vidÃ­tÃ©seket
    positions = ['GK', 'DF', 'MF', 'FW', 'SUB', 'K', 'V', 'KV', 'T', 'CS']
    for pos in positions:
        if pos in player_text.upper():
            return pos
    return None

def create_empty_match_details():
    """Ãœres match details struktÃºra lÃ©trehozÃ¡sa"""
    return {
        'header_info': {
            'main_title': '',
            'league_round': '',
            'competition': '',
            'round': '',
            'date_time_hungarian': '',
            'date': '',
            'time': '',
            'final_score': '',
            'home_team': '',
            'away_team': ''
        },
        'summary': [],
        'statistics': {},
        'lineups': {
            'hazai_csapat': [],
            'vendÃ©g_csapat': [],
            'cserÃ©k': {'hazai': [], 'vendÃ©g': []}
        }
    }

def scrape_match_details(url, debug=False):
    """FÅ‘ scraping function javÃ­tott header Ã©s statisztika kezelÃ©ssel"""
    # Chrome driver beÃ¡llÃ­tÃ¡sa
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)

    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)

    try:
        print(f"ğŸŒ Navigating to: {url}")
        driver.get(url)

        # VÃ¡rjunk a teljes betÃ¶ltÃ©sre
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )

        # TovÃ¡bbi vÃ¡rakozÃ¡s a JavaScript betÃ¶ltÃ©sÃ©re
        import time
        time.sleep(5)

        # Cookie banner kezelÃ©se (ha van)
        try:
            cookie_buttons = driver.find_elements(By.XPATH, "//button[contains(text(), 'Accept') or contains(text(), 'Elfogad') or contains(text(), 'OK')]")
            for button in cookie_buttons:
                try:
                    button.click()
                    time.sleep(2)
                    print("âœ… Cookie banner elfogadva")
                    break
                except:
                    continue
        except:
            pass

        # EllenÅ‘rizzÃ¼k az aktuÃ¡lis URL-t
        current_url = driver.current_url
        print(f"ğŸ“ Current URL: {current_url}")

        # BeautifulSoup objektum lÃ©trehozÃ¡sa
        soup = BeautifulSoup(driver.page_source, 'html.parser')

        # EllenÅ‘rizzÃ¼k a page title-t
        page_title = soup.title.string if soup.title else ""
        print(f"ğŸ“„ Page title: {page_title}")

        # KeressÃ¼nk meccs-specifikus elemeket
        team_elements = soup.select('[class*="team"], [class*="home"], [class*="away"], .participant')
        score_elements = soup.select('[class*="score"], [class*="result"]')

        print(f"ğŸŸï¸  Found {len(team_elements)} team elements")
        print(f"âš½ Found {len(score_elements)} score elements")

        # Ha nincsenek meccs elemek, prÃ³bÃ¡ljunk meg egy mÃ¡sik megkÃ¶zelÃ­tÃ©st
        if len(team_elements) < 2 and len(score_elements) < 1:
            print("âš ï¸  Warning: Minimal match elements found, trying alternative selectors...")
            # AlternatÃ­v szelektorok
            team_elements = soup.select('span, div, td')
            potential_teams = []
            for elem in team_elements:
                text = elem.get_text(strip=True)
                if any(team in text for team in ['Bolivar', 'Independiente', 'BOL', 'IND']):
                    potential_teams.append(text)
            print(f"ğŸ” Found potential team mentions: {potential_teams[:5]}")

        # === HEADER INFORMÃCIÃ“K KINYERÃ‰SE (JAVÃTOTT) ===

        match_details = {
            'header_info': {
                'main_title': '',
                'league_round': '',
                'competition': '',
                'round': '',
                'date_time_hungarian': '',
                'date': '',
                'time': '',
                'final_score': '',
                'home_team': '',
                'away_team': ''
            },
            'summary': [],
            'statistics': {},
            'lineups': {}
        }

        # Page title elemzÃ©se
        page_title = soup.title.string if soup.title else ""
        match_details['header_info']['main_title'] = page_title

        # BajnoksÃ¡g Ã©s fordulÃ³ informÃ¡ciÃ³ kinyerÃ©se
        league_info = extract_league_and_round_info(soup, debug)
        match_details['header_info']['competition'] = league_info['competition']
        match_details['header_info']['round'] = league_info['round']
        match_details['header_info']['league_round'] = league_info['full_name']

        # Ha nincs bajnoksÃ¡g info, prÃ³bÃ¡ljuk meg a title-bÅ‘l
        if not league_info['full_name']:
            # KeressÃ¼k meg a breadcrumb vagy navigation elemeket
            breadcrumb_elements = soup.select('.breadcrumb a, nav a, [class*="nav"] a')
            for elem in breadcrumb_elements:
                text = elem.get_text(strip=True)
                if any(keyword in text.lower() for keyword in ['division', 'league', 'bajnoksÃ¡g', 'fordulÃ³']):
                    match_details['header_info']['league_round'] = text
                    break

        # Page title alapÃº informÃ¡ciÃ³k kinyerÃ©se
        title_info = parse_page_title_info(page_title)
        match_details['header_info']['final_score'] = title_info['score']
        match_details['header_info']['home_team'] = title_info['home_team']
        match_details['header_info']['away_team'] = title_info['away_team']

        # DÃ¡tum Ã©s idÅ‘ keresÃ©se
        date_elements = soup.select('.date, .time, [class*="date"], [class*="time"], .match-date, .match-time')

        for date_elem in date_elements:
            text = date_elem.get_text(strip=True)

            # DÃ¡tum felismerÃ©s
            date_match = re.search(r'(\d{1,2}[./]\d{1,2}[./]?\d{0,4})', text)
            if date_match and not match_details['header_info']['date']:
                match_details['header_info']['date'] = date_match.group(1)

            # IdÅ‘ felismerÃ©s
            time_match = re.search(r'(\d{1,2}:\d{2})', text)
            if time_match and not match_details['header_info']['time']:
                match_details['header_info']['time'] = time_match.group(1)

        # Magyar dÃ¡tum formÃ¡zÃ¡s
        if match_details['header_info']['date'] and match_details['header_info']['time']:
            match_details['header_info']['date_time_hungarian'] = format_hungarian_date(
                match_details['header_info']['date'],
                match_details['header_info']['time']
            )

        # === ESEMÃ‰NYEK KINYERÃ‰SE (TOVÃBBFEJLESZTETT) ===

        # KeressÃ¼k meg a fÅ‘ tartalom kontÃ©nert
        main_content = soup.select_one('#detail-tab-content, .match-content, .match-events, body')

        if main_content:
            # KeressÃ¼k meg az Ã¶sszes elemet ami idÅ‘t tartalmaz
            time_elements = main_content.select('[class*="time"], p.time, .i-field.time, [class*="minute"]')

            if debug:
                print(f"Found {len(time_elements)} time elements")

            for time_elem in time_elements:
                # SzÃ¼lÅ‘ elem keresÃ©se ami tartalmazhatja az egÃ©sz esemÃ©nyt
                event_container = time_elem.parent
                if not event_container:
                    continue

                # Az egÃ©sz esemÃ©ny szÃ¶vege
                full_event_text = event_container.get_text(strip=True)

                # Fejlett esemÃ©ny tÃ­pus felismerÃ©s
                event_type, description, details = analyze_event_type_from_raw_text(full_event_text)

                # IdÅ‘ kinyerÃ©se
                time_text = time_elem.get_text(strip=True)
                time_match = re.search(r'(\d+)[:\'+]?', time_text)
                time = time_match.group(1) + "'" if time_match else time_text

                # EsemÃ©ny objektum lÃ©trehozÃ¡sa
                event_data = {
                    'idÅ‘': time,
                    'tÃ­pus': event_type,
                    'leÃ­rÃ¡s': description,
                    'rÃ©szletek': details
                }

                # JÃ¡tÃ©kos nÃ©v hozzÃ¡adÃ¡sa a details alapjÃ¡n
                if isinstance(details, dict):
                    if 'player' in details:
                        event_data['jÃ¡tÃ©kos'] = details['player']
                    elif 'player_in' in details:
                        event_data['jÃ¡tÃ©kos_be'] = details['player_in']
                        event_data['jÃ¡tÃ©kos_ki'] = details['player_out']

                # Raw text hozzÃ¡adÃ¡sa debug mÃ³dban
                if debug:
                    event_data['raw_text'] = full_event_text

                match_details['summary'].append(event_data)

        # === STATISZTIKÃK KINYERÃ‰SE (JAVÃTOTT) ===

        statistics = scrape_statistics_improved(driver, url, debug)
        match_details['statistics'] = statistics

        # === FELÃLLÃTÃSOK KINYERÃ‰SE ===

        lineups = scrape_lineups(driver, url, debug)
        match_details['lineups'] = lineups

        return match_details

    finally:
        driver.quit()

def parse_page_title_info(page_title):
    """Kinyeri az informÃ¡ciÃ³kat a page title-bÅ‘l"""
    info = {
        'score': '',
        'home_team': '',
        'away_team': '',
        'competition': ''
    }

    if '|' in page_title:
        # FormÃ¡tum: "THO 1-4 WES | Thornton Redbacks - West Wallsend"
        parts = page_title.split('|')

        if len(parts) >= 2:
            # Bal oldal: eredmÃ©ny rÃ©sszel
            left_part = parts[0].strip()
            # Jobb oldal: teljes csapat nevek
            right_part = parts[1].strip()

            # EredmÃ©ny keresÃ©se a bal oldalban
            score_match = re.search(r'(\d+[-:]\d+)', left_part)
            if score_match:
                info['score'] = score_match.group(1)

            # Csapat nevek a jobb oldalbÃ³l
            if ' - ' in right_part:
                team_parts = right_part.split(' - ')
                info['home_team'] = team_parts[0].strip()
                info['away_team'] = team_parts[1].strip()

    return info

def test_single_match():
    """Teszt function egy meccs scraperlÃ©sÃ©hez"""
    # PrÃ³bÃ¡ljunk meg egy egyszerÅ±bb URL-t hasznÃ¡lni
    # url = "https://www.flashscore.hu/merkozes/pEekkCHe/#/a-merkozes-osszefoglaloja"
    url = "https://m.eredmenyek.com/merkozes/KOVqFIMi/"  # Mobile verziÃ³, egyszerÅ±bb

    print(f"ğŸ¯ Target URL: {url}")
    print("ğŸš€ Starting scraping...")

    match_details = scrape_match_details(url, debug=True)

    # JSON fÃ¡jlba mentÃ©s
    output_file = '/home/bandi/Documents/code/2025/sp3/scrapping_data/v4_match_details.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(match_details, f, ensure_ascii=False, indent=4)

    print(f"EredmÃ©ny mentve: {output_file}")

    # Ã–sszefoglalÃ³
    header = match_details['header_info']
    print(f"\n" + "="*50)
    print(f"ğŸ“„ FÅ‘cÃ­m: {header['main_title']}")
    print(f"ğŸ† BajnoksÃ¡g: {header['competition']}")
    print(f"ğŸ”„ FordulÃ³: {header['round']}")
    print(f"ğŸ“‹ Teljes nÃ©v: {header['league_round']}")
    print(f"âš½ EredmÃ©ny: {header['final_score']}")
    print(f"ğŸ†š Csapatok: {header['home_team']} vs {header['away_team']}")
    print(f"ğŸ“… DÃ¡tum: {header['date_time_hungarian']}")
    print(f"ğŸ“‹ EsemÃ©nyek szÃ¡ma: {len(match_details['summary'])}")
    print(f"ğŸ“Š StatisztikÃ¡k szÃ¡ma: {len(match_details['statistics'])}")
    print(f"ğŸ‘¥ Hazai jÃ¡tÃ©kosok: {len(match_details['lineups'].get('hazai_csapat', []))}")
    print(f"ğŸ‘¥ VendÃ©g jÃ¡tÃ©kosok: {len(match_details['lineups'].get('vendÃ©g_csapat', []))}")

    # StatisztikÃ¡k mintÃ¡ja
    print(f"\nğŸ“Š StatisztikÃ¡k (elsÅ‘ 5):")
    for i, (stat_name, values) in enumerate(list(match_details['statistics'].items())[:5]):
        print(f"  {i+1}. {stat_name}: {values['hazai']} - {values['vendÃ©g']}")

    # EsemÃ©nyek tÃ­pusok szerinti bontÃ¡sa
    event_types = {}
    for event in match_details['summary']:
        event_type = event['tÃ­pus']
        event_types[event_type] = event_types.get(event_type, 0) + 1

    print(f"\nğŸ“ EsemÃ©ny tÃ­pusok:")
    for event_type, count in event_types.items():
        print(f"  - {event_type}: {count} db")

    # ElsÅ‘ nÃ©hÃ¡ny esemÃ©ny rÃ©szletesen
    print(f"\nğŸ” ElsÅ‘ esemÃ©nyek rÃ©szletesen:")
    for i, event in enumerate(match_details['summary'][:5]):
        print(f"  {i+1}. {event['idÅ‘']} - {event['leÃ­rÃ¡s']}")
        if 'jÃ¡tÃ©kos' in event:
            print(f"     JÃ¡tÃ©kos: {event['jÃ¡tÃ©kos']}")
        if 'jÃ¡tÃ©kos_ki' in event:
            print(f"     Ki: {event['jÃ¡tÃ©kos_ki']}")

    print(f"=" * 50)

if __name__ == "__main__":
    test_single_match()
