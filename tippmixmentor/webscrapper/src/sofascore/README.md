# SofaScore Data Processing Tools

This directory contains tools for processing SofaScore event data from the SofaScore API.

## Directory Structure

```
sofascore/
├── archives/                 # Archived data organized by date
│   └── YYYY-MM-DD/          # Date-based folders (e.g., extracted-events.json, analysis-results.json)
├── data/                     # Contains auxiliary data, like hash files for change detection
│   └── .scheduled-events.hash
├── jsons/                    # Stores raw and extracted JSON data
│   ├── scheduled-events.json # Original data from SofaScore API
│   └── extracted-events.json # Processed data with essential information
├── logs/                     # Log files generated by the Python scripts
│   └── sofascore_update.log
├── reports/                  # Generated reports and filtered datasets
│   ├── analysis-results.json # Statistical analysis of all events
│   ├── filtered-today.json   # Events scheduled for today
│   ├── filtered-tomorrow.json# Events scheduled for tomorrow
│   ├── tournaments/          # Tournament-specific data (e.g., uefa_europa_league.json)
│   └── teams/                # Team-specific data (e.g., legia_warszawa.json)
└── scripts/                  # All Python and shell scripts
    ├── analyze_events.py
    ├── config.py
    ├── daily_update.py
    ├── download_events.py
    ├── extract_events.py
    ├── fetch-sofa.js
    ├── filter_events.py
    ├── process_data.sh
    └── run_daily_update.sh
```

## Available Scripts

### 1. Daily Update (`daily_update.py`)

Main Python script for daily processing of SofaScore data. This script orchestrates the data flow:
- Archives previous data to `archives/`
- Extracts essential data from `jsons/scheduled-events.json` to `jsons/extracted-events.json`
- Generates tournament-specific reports in `reports/tournaments/`
- Generates team-specific reports in `reports/teams/`
- Runs analysis to generate statistics in `reports/analysis-results.json`

```bash
python scripts/daily_update.py
```

### 2. Download Events (`download_events.py`)

Fetches the latest football events data directly from the SofaScore API and saves it to `jsons/scheduled-events.json`.

```bash
python scripts/download_events.py --days-past 3 --days-future 7
```

### 3. Extract Events (`extract_events.py`)

Processes the large `jsons/scheduled-events.json` file and extracts only the key information needed for analysis into `jsons/extracted-events.json`. It also sorts events by date and provides a summary of the data.

```bash
python scripts/extract_events.py
```

### 4. Filter Events (`filter_events.py`)

Filters events from `jsons/extracted-events.json` based on various criteria such as tournament, team, country, status, and date. Output files are saved to `reports/`.

```bash
# Filter events for a specific tournament
python scripts/filter_events.py --tournament "UEFA Europa League" --output reports/filtered_europa_league.json

# Filter events for a specific team
python scripts/filter_events.py --team "Legia Warszawa" --output reports/filtered_legia.json

# Filter events for today (output to reports/filtered-today.json)
python scripts/filter_events.py --today

# Filter events for a specific date range
python scripts/filter_events.py --date-from "2025-07-15" --date-to "2025-07-20" --output reports/filtered_date_range.json

# Combine multiple filters
python scripts/filter_events.py --tournament "Premier League" --status "Ended" --country "England" --output reports/filtered_premier_league_ended.json
```

### 5. Analyze Events (`analyze_events.py`)

Analyzes event data from `jsons/extracted-events.json` and generates statistics about tournaments, teams, and countries. Results are saved to `reports/analysis-results.json`.

```bash
python scripts/analyze_events.py
```

### 6. Fetch SofaScore Data (JavaScript) (`fetch-sofa.js`)

A Node.js script that uses Puppeteer to fetch data from the SofaScore API and saves it to `jsons/scheduled-events.json`.

```bash
node scripts/fetch-sofa.js
```

### 7. Process Data (Shell Script) (`process_data.sh`)

A shell script that runs a sequence of Python scripts (`extract_events.py`, `filter_events.py`, `analyze_events.py`) to process data. This script is useful for manual, sequential data processing.

```bash
./scripts/process_data.sh
```

### 8. Run Daily Update (Shell Script) (`run_daily_update.sh`)

The primary shell script for automated daily execution. It activates the Python virtual environment (if found) and then runs `download_events.py` and `daily_update.py`.

```bash
./scripts/run_daily_update.sh
```

## Configuration (`config.py`)

The `scripts/config.py` file centralizes all important directory and file paths, making the project more maintainable and flexible. It also sets up the logging configuration for all Python scripts.

Example content:

```python
import os
import logging

# Base directory of the project (sofascore folder)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# Define paths for data, jsons, reports, and archives
JSONS_DIR = os.path.join(BASE_DIR, "jsons")
REPORTS_DIR = os.path.join(BASE_DIR, "reports")
ARCHIVES_DIR = os.path.join(BASE_DIR, "archives")
DATA_DIR = os.path.join(BASE_DIR, "data")
LOGS_DIR = os.path.join(BASE_DIR, "logs")

# Ensure directories exist
for _dir in [JSONS_DIR, REPORTS_DIR, ARCHIVES_DIR, DATA_DIR, LOGS_DIR]:
    os.makedirs(_dir, exist_ok=True)

# File names
SCHEDULED_EVENTS_FILE = os.path.join(JSONS_DIR, "scheduled-events.json")
EXTRACTED_EVENTS_FILE = os.path.join(JSONS_DIR, "extracted-events.json")
ANALYSIS_RESULTS_FILE = os.path.join(REPORTS_DIR, "analysis-results.json")
FILTERED_TODAY_FILE = os.path.join(REPORTS_DIR, "filtered-today.json")
FILTERED_TOMORROW_FILE = os.path.join(REPORTS_DIR, "filtered-tomorrow.json")
SCHEDULED_EVENTS_HASH_FILE = os.path.join(DATA_DIR, ".scheduled-events.hash")

# Logging configuration
LOG_FILE = os.path.join(LOGS_DIR, "sofascore_update.log")

def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(LOG_FILE),
            logging.StreamHandler()
        ]
    )
    logging.getLogger("requests").setLevel(logging.WARNING)
    logging.getLogger("urllib3").setLevel(logging.WARNING)

setup_logging()
```

## Logging

All Python scripts now utilize the `logging` module for output. Log messages are written to `logs/sofascore_update.log` and also displayed on the console. The logging level is set to `INFO` by default, capturing informational messages, warnings, and errors.

## Data Processing Workflow

1.  **Automated Update:** Run `./scripts/run_daily_update.sh` to perform a full daily update, including data download, extraction, analysis, and report generation.
2.  **Manual Processing:** Use `./scripts/process_data.sh` for a sequential run of extraction, filtering, and analysis steps.
3.  **Custom Filtering:** Use `python scripts/filter_events.py` to create custom filtered datasets.
4.  **Review Reports:** Check the `reports/`, `reports/tournaments/`, and `reports/teams/` directories for generated output.

## Data Structure

The extracted events (in `jsons/extracted-events.json`) have the following structure:

```json
{
  "id": 14032997,
  "start_time": 1752768000,
  "start_time_formatted": "2025-07-17 18:00:00",
  "event_date": "2025-07-17",
  "status": "Ended",
  "tournament": "UEFA Europa League, Qualification",
  "season": "UEFA Europa League 25/26",
  "round": "Qualification Round 1",
  "home_team": "FK Aktobe",
  "home_team_country": "Kazakhstan",
  "away_team": "Legia Warszawa",
  "away_team_country": "Poland",
  "home_score": 0,
  "away_score": 1,
  "home_score_ht": 0,
  "away_score_ht": 0,
  "winner_code": 2
}
```

## Setting Up Automated Daily Updates

To set up automated daily updates, add the following to your crontab:

```bash
# Run SofaScore data update every day at 6:00 AM
0 6 * * * /path/to/webscrapper/src/sofascore/scripts/run_daily_update.sh
```

Remember to replace `/path/to/webscrapper/src/sofascore/` with the actual absolute path to your `sofascore` directory.

Edit your crontab with:

```bash
crontab -e
```

## Notes

- The `winner_code` field uses the following values:
  - `1`: Home team won
  - `2`: Away team won
  - `0`: Draw
- All timestamps are in Unix format (seconds since epoch)
- The daily update script archives previous data to prevent data loss
- Python dependencies are expected to be managed at the project root level (e.g., via a virtual environment in `../../../.venv/`).
