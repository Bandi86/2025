#!/usr/bin/env python3
"""
Cron Job Monitoring √©s Debugging Rendszer
Ellen≈ërzi, hogy a cron job-ok futnak-e √©s jelent√©st k√©sz√≠t
"""

import os
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional
import subprocess
import psutil

# Logging be√°ll√≠t√°sa
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(levelname)s] - %(message)s',
    handlers=[
        logging.FileHandler('monitoring.log'),
        logging.StreamHandler()
    ]
)

class CronMonitor:
    """Cron job monitoring √©s debugging"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.report_data = {
            'timestamp': datetime.now().isoformat(),
            'cron_jobs': {},
            'data_sources': {},
            'issues': [],
            'recommendations': []
        }
        
    def check_cron_jobs(self) -> Dict:
        """Cron job-ok ellen≈ërz√©se"""
        
        logging.info("üîç Cron job-ok ellen≈ërz√©se...")
        
        # Cron job-ok list√°z√°sa
        try:
            result = subprocess.run(['crontab', '-l'], capture_output=True, text=True)
            if result.returncode == 0:
                cron_content = result.stdout
                self.report_data['cron_jobs']['installed'] = True
                self.report_data['cron_jobs']['content'] = cron_content
                logging.info("‚úÖ Cron job-ok telep√≠tve")
            else:
                self.report_data['cron_jobs']['installed'] = False
                self.report_data['issues'].append("‚ùå Nincs cron job telep√≠tve")
                logging.warning("‚ùå Nincs cron job telep√≠tve")
        except Exception as e:
            self.report_data['cron_jobs']['error'] = str(e)
            self.report_data['issues'].append(f"‚ùå Cron job ellen≈ërz√©si hiba: {e}")
            
        return self.report_data['cron_jobs']
        
    def check_sofascore_status(self) -> Dict:
        """Sofascore scraper st√°tusz ellen≈ërz√©se"""
        
        logging.info("üîç Sofascore st√°tusz ellen≈ërz√©se...")
        
        sofascore_dir = self.project_root / "webscrapper" / "src" / "sofascore"
        log_file = sofascore_dir / "logs" / "sofascore_update.log"
        
        status = {
            'last_run': None,
            'log_exists': log_file.exists(),
            'recent_activity': False,
            'data_files': 0,
            'errors': []
        }
        
        # Log f√°jl ellen≈ërz√©se
        if log_file.exists():
            try:
                # Utols√≥ m√≥dos√≠t√°s ideje
                last_modified = datetime.fromtimestamp(log_file.stat().st_mtime)
                status['last_run'] = last_modified.isoformat()
                
                # Legut√≥bbi aktivit√°s (24 √≥r√°n bel√ºl)
                if datetime.now() - last_modified < timedelta(hours=24):
                    status['recent_activity'] = True
                    logging.info("‚úÖ Sofascore: Legut√≥bbi aktivit√°s 24 √≥r√°n bel√ºl")
                else:
                    status['recent_activity'] = False
                    self.report_data['issues'].append("‚ö†Ô∏è Sofascore: Nincs legut√≥bbi aktivit√°s")
                    
                # Log tartalom ellen≈ërz√©se
                with open(log_file, 'r') as f:
                    log_content = f.read()
                    if 'ERROR' in log_content or 'Failed' in log_content:
                        status['errors'].append("Log tartalmaz hib√°kat")
                        
            except Exception as e:
                status['errors'].append(f"Log olvas√°si hiba: {e}")
        else:
            self.report_data['issues'].append("‚ùå Sofascore log f√°jl nem tal√°lhat√≥")
            
        # Adatf√°jlok ellen≈ërz√©se
        data_dir = sofascore_dir / "jsons"
        if data_dir.exists():
            json_files = list(data_dir.glob("*.json"))
            status['data_files'] = len(json_files)
            
            # Legfrissebb f√°jl ellen≈ërz√©se
            if json_files:
                latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
                latest_modified = datetime.fromtimestamp(latest_file.stat().st_mtime)
                status['latest_data_file'] = {
                    'name': latest_file.name,
                    'modified': latest_modified.isoformat(),
                    'size': latest_file.stat().st_size
                }
                
        self.report_data['data_sources']['sofascore'] = status
        return status
        
    def check_merge_status(self) -> Dict:
        """Merge rendszer st√°tusz ellen≈ërz√©se"""
        
        logging.info("üîç Merge rendszer ellen≈ërz√©se...")
        
        merge_dir = self.project_root / "merge_json_data"
        
        status = {
            'config_exists': (merge_dir / "config.json").exists(),
            'script_exists': (merge_dir / "merge_json.py").exists(),
            'output_files': 0,
            'latest_merge': None,
            'id_issues': []
        }
        
        # Kimeneti f√°jlok ellen≈ërz√©se
        merged_data_dir = merge_dir / "merged_data"
        if merged_data_dir.exists():
            json_files = list(merged_data_dir.glob("merged_matches_*.json"))
            status['output_files'] = len(json_files)
            
            if json_files:
                # Legfrissebb merge f√°jl
                latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
                latest_modified = datetime.fromtimestamp(latest_file.stat().st_mtime)
                status['latest_merge'] = {
                    'file': latest_file.name,
                    'modified': latest_modified.isoformat(),
                    'size': latest_file.stat().st_size
                }
                
                # ID probl√©m√°k ellen≈ërz√©se
                try:
                    with open(latest_file, 'r') as f:
                        data = json.load(f)
                        matches = data.get('matches', [])
                        
                    # ID egyedis√©g ellen≈ërz√©se
                    ids = [match.get('id', '') for match in matches]
                    unique_ids = set(ids)
                    
                    if len(ids) != len(unique_ids):
                        duplicate_count = len(ids) - len(unique_ids)
                        status['id_issues'].append(f"Duplik√°lt ID-k: {duplicate_count}")
                        self.report_data['issues'].append(f"‚ùå Merge: {duplicate_count} duplik√°lt ID")
                        
                    # √úres ID-k ellen≈ërz√©se
                    empty_ids = sum(1 for id in ids if not id or id.strip() == '')
                    if empty_ids > 0:
                        status['id_issues'].append(f"√úres ID-k: {empty_ids}")
                        self.report_data['issues'].append(f"‚ùå Merge: {empty_ids} √ºres ID")
                        
                    # ID form√°tum ellen≈ërz√©se
                    invalid_format = 0
                    for id in ids:
                        if id and ':' not in id:
                            invalid_format += 1
                            
                    if invalid_format > 0:
                        status['id_issues'].append(f"Hib√°s form√°tum√∫ ID-k: {invalid_format}")
                        self.report_data['issues'].append(f"‚ùå Merge: {invalid_format} hib√°s form√°tum√∫ ID")
                        
                except Exception as e:
                    status['id_issues'].append(f"ID ellen≈ërz√©si hiba: {e}")
                    
        self.report_data['data_sources']['merge'] = status
        return status
        
    def check_flashscore_scraper(self) -> Dict:
        """Flashscore scraper ellen≈ërz√©se"""
        
        logging.info("üîç Flashscore scraper ellen≈ërz√©se...")
        
        scraper_dir = self.project_root / "webscrapper" / "automated-flashscore-scraper"
        
        status = {
            'config_exists': (scraper_dir / "src" / "config" / "index.js").exists(),
            'scraped_data_exists': (scraper_dir / "scraped_data").exists(),
            'countries': 0,
            'total_matches': 0,
            'latest_scrape': None
        }
        
        # Scraped data ellen≈ërz√©se
        scraped_data_dir = scraper_dir / "scraped_data"
        if scraped_data_dir.exists():
            countries = [d for d in scraped_data_dir.iterdir() if d.is_dir()]
            status['countries'] = len(countries)
            
            total_matches = 0
            latest_file = None
            latest_time = None
            
            for country_dir in countries:
                for league_dir in country_dir.iterdir():
                    if league_dir.is_dir():
                        for season_dir in league_dir.iterdir():
                            if season_dir.is_dir():
                                json_files = list(season_dir.glob("*.json"))
                                for json_file in json_files:
                                    try:
                                        with open(json_file, 'r') as f:
                                            data = json.load(f)
                                            total_matches += len(data)
                                            
                                        # Legfrissebb f√°jl keres√©se
                                        file_time = datetime.fromtimestamp(json_file.stat().st_mtime)
                                        if latest_time is None or file_time > latest_time:
                                            latest_time = file_time
                                            latest_file = json_file
                                            
                                    except Exception as e:
                                        logging.warning(f"Hiba {json_file} olvas√°sakor: {e}")
                                        
            status['total_matches'] = total_matches
            
            if latest_file and latest_time:
                status['latest_scrape'] = {
                    'file': str(latest_file.relative_to(scraper_dir)),
                    'modified': latest_time.isoformat(),
                    'matches_count': total_matches
                }
                
        self.report_data['data_sources']['flashscore'] = status
        return status
        
    def generate_recommendations(self):
        """Javaslatok gener√°l√°sa a probl√©m√°k alapj√°n"""
        
        logging.info("üí° Javaslatok gener√°l√°sa...")
        
        # Cron job javaslatok
        if not self.report_data['cron_jobs'].get('installed', False):
            self.report_data['recommendations'].append({
                'priority': 'HIGH',
                'category': 'Cron Jobs',
                'issue': 'Nincs cron job be√°ll√≠tva',
                'solution': 'Telep√≠tsd a cron job-okat: crontab merge_json_data/my_cron_jobs.txt',
                'command': 'crontab merge_json_data/my_cron_jobs.txt'
            })
            
        # Sofascore javaslatok
        sofascore = self.report_data['data_sources'].get('sofascore', {})
        if not sofascore.get('recent_activity', False):
            self.report_data['recommendations'].append({
                'priority': 'HIGH',
                'category': 'Sofascore',
                'issue': 'Nincs legut√≥bbi aktivit√°s',
                'solution': 'Ellen≈ërizd a Sofascore scraper m≈±k√∂d√©s√©t',
                'command': 'cd webscrapper/src/sofascore && python3 scripts/daily_update.py'
            })
            
        # Merge javaslatok
        merge = self.report_data['data_sources'].get('merge', {})
        if merge.get('id_issues'):
            self.report_data['recommendations'].append({
                'priority': 'MEDIUM',
                'category': 'Merge System',
                'issue': 'ID probl√©m√°k a merge rendszerben',
                'solution': 'Jav√≠tsd az ID gener√°l√°si logik√°t a merge_json.py-ban',
                'command': 'cd merge_json_data && python3 merge_json.py --fix-ids'
            })
            
    def create_report(self) -> str:
        """R√©szletes jelent√©s k√©sz√≠t√©se"""
        
        report = []
        report.append("# üîç RENDSZER MONITORING JELENT√âS")
        report.append(f"**Gener√°lva:** {self.report_data['timestamp']}")
        report.append("")
        
        # √ñsszefoglal√≥
        total_issues = len(self.report_data['issues'])
        if total_issues == 0:
            report.append("## ‚úÖ √ñSSZEFOGLAL√ì: Minden rendben!")
        else:
            report.append(f"## ‚ö†Ô∏è √ñSSZEFOGLAL√ì: {total_issues} probl√©ma azonos√≠tva")
            
        report.append("")
        
        # Probl√©m√°k
        if self.report_data['issues']:
            report.append("## üö® AZONOS√çTOTT PROBL√âM√ÅK:")
            for issue in self.report_data['issues']:
                report.append(f"- {issue}")
            report.append("")
            
        # Adatforr√°sok st√°tusza
        report.append("## üìä ADATFORR√ÅSOK ST√ÅTUSZA:")
        
        for source_name, source_data in self.report_data['data_sources'].items():
            report.append(f"### {source_name.upper()}")
            
            if source_name == 'sofascore':
                report.append(f"- **Utols√≥ fut√°s:** {source_data.get('last_run', 'N/A')}")
                report.append(f"- **Legut√≥bbi aktivit√°s:** {'‚úÖ' if source_data.get('recent_activity') else '‚ùå'}")
                report.append(f"- **Adatf√°jlok:** {source_data.get('data_files', 0)}")
                
            elif source_name == 'merge':
                report.append(f"- **Kimeneti f√°jlok:** {source_data.get('output_files', 0)}")
                report.append(f"- **Legut√≥bbi merge:** {source_data.get('latest_merge', {}).get('file', 'N/A')}")
                if source_data.get('id_issues'):
                    report.append(f"- **ID probl√©m√°k:** {', '.join(source_data['id_issues'])}")
                    
            elif source_name == 'flashscore':
                report.append(f"- **Orsz√°gok:** {source_data.get('countries', 0)}")
                report.append(f"- **√ñsszes meccs:** {source_data.get('total_matches', 0)}")
                report.append(f"- **Legut√≥bbi scrape:** {source_data.get('latest_scrape', {}).get('file', 'N/A')}")
                
            report.append("")
            
        # Javaslatok
        if self.report_data['recommendations']:
            report.append("## üí° JAVASLATOK:")
            for rec in self.report_data['recommendations']:
                report.append(f"### {rec['priority']} - {rec['category']}")
                report.append(f"**Probl√©ma:** {rec['issue']}")
                report.append(f"**Megold√°s:** {rec['solution']}")
                if rec.get('command'):
                    report.append(f"**Parancs:** `{rec['command']}`")
                report.append("")
                
        return "\n".join(report)
        
    def run_full_check(self) -> Dict:
        """Teljes rendszer ellen≈ërz√©s futtat√°sa"""
        
        logging.info("üöÄ Teljes rendszer ellen≈ërz√©s ind√≠t√°sa...")
        
        # √ñsszes ellen≈ërz√©s futtat√°sa
        self.check_cron_jobs()
        self.check_sofascore_status()
        self.check_merge_status()
        self.check_flashscore_scraper()
        
        # Javaslatok gener√°l√°sa
        self.generate_recommendations()
        
        # Jelent√©s k√©sz√≠t√©se
        report_text = self.create_report()
        
        # Jelent√©s ment√©se
        report_file = Path("monitoring_report.md")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_text)
            
        logging.info(f"üìÑ Jelent√©s mentve: {report_file}")
        
        return self.report_data


if __name__ == "__main__":
    monitor = CronMonitor()
    results = monitor.run_full_check()
    
    # Konzol kimenet
    print("\n" + "="*60)
    print("üîç RENDSZER MONITORING EREDM√âNYEK")
    print("="*60)
    
    print(f"\nüìä √ñSSZEFOGLAL√ì:")
    print(f"- Probl√©m√°k: {len(results['issues'])}")
    print(f"- Javaslatok: {len(results['recommendations'])}")
    
    if results['issues']:
        print(f"\nüö® PROBL√âM√ÅK:")
        for issue in results['issues']:
            print(f"  {issue}")
            
    if results['recommendations']:
        print(f"\nüí° S√úRG≈êS JAVASLATOK:")
        high_priority = [r for r in results['recommendations'] if r['priority'] == 'HIGH']
        for rec in high_priority:
            print(f"  - {rec['issue']}")
            print(f"    Megold√°s: {rec['command']}")
            
    print(f"\nüìÑ R√©szletes jelent√©s: monitoring_report.md")