"""
Meccs eredm√©ny el≈ërejelz≈ë bot
"""

import pandas as pd
import numpy as np
from pathlib import Path
import logging
from datetime import datetime
import joblib
import json
from typing import Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)

class MatchPredictor:
    """Meccs eredm√©ny el≈ërejelz≈ë bot"""
    
    def __init__(self, model_dir: str = None):
        if model_dir is None:
            # Relat√≠v √∫tvonal a betmentors mapp√°b√≥l
            current_dir = Path(__file__).parent.parent.parent
            model_dir = current_dir / "models"
        self.model_dir = Path(model_dir)
        self.model = None
        self.scaler = None
        self.metadata = None
        self.feature_names = []
        
    def load_best_model(self, model_type: str = None) -> bool:
        """Legjobb modell bet√∂lt√©se"""
        
        if not self.model_dir.exists():
            logger.error(f"Model k√∂nyvt√°r nem tal√°lhat√≥: {self.model_dir}")
            return False
            
        # El√©rhet≈ë modellek keres√©se
        available_models = {}
        
        for model_subdir in self.model_dir.iterdir():
            if not model_subdir.is_dir():
                continue
                
            model_name = model_subdir.name
            
            # Legfrissebb modell keres√©se
            model_files = list(model_subdir.glob("model_*.joblib"))
            metadata_files = list(model_subdir.glob("metadata_*.json"))
            
            if model_files and metadata_files:
                # Legfrissebb f√°jlok
                latest_model = max(model_files, key=lambda x: x.stat().st_mtime)
                latest_metadata = max(metadata_files, key=lambda x: x.stat().st_mtime)
                
                # Metadata bet√∂lt√©se
                try:
                    with open(latest_metadata, 'r') as f:
                        metadata = json.load(f)
                        
                    available_models[model_name] = {
                        'model_path': latest_model,
                        'metadata_path': latest_metadata,
                        'metadata': metadata,
                        'accuracy': metadata.get('accuracy', 0)
                    }
                except Exception as e:
                    logger.warning(f"Hiba metadata bet√∂lt√©sekor: {latest_metadata}, {e}")
                    
        if not available_models:
            logger.error("Nem tal√°lhat√≥k tr√©ningelt modellek")
            return False
            
        # Modell kiv√°laszt√°sa
        if model_type and model_type in available_models:
            selected_model = available_models[model_type]
        else:
            # Legjobb accuracy alapj√°n
            selected_model = max(available_models.values(), key=lambda x: x['accuracy'])
            model_type = [k for k, v in available_models.items() if v == selected_model][0]
            
        # Modell bet√∂lt√©se
        try:
            self.model = joblib.load(selected_model['model_path'])
            self.metadata = selected_model['metadata']
            self.feature_names = self.metadata.get('feature_names', [])
            
            logger.info(f"‚úÖ Modell bet√∂ltve: {model_type}")
            logger.info(f"   Accuracy: {self.metadata.get('accuracy', 0):.3f}")
            logger.info(f"   Features: {len(self.feature_names)}")
            
            # Scaler bet√∂lt√©se (ha sz√ºks√©ges)
            if self.metadata.get('use_scaling', False):
                scaler_files = list(self.model_dir.glob("scaler_*.joblib"))
                if scaler_files:
                    latest_scaler = max(scaler_files, key=lambda x: x.stat().st_mtime)
                    self.scaler = joblib.load(latest_scaler)
                    logger.info("‚úÖ Scaler bet√∂ltve")
                else:
                    logger.warning("Scaler sz√ºks√©ges, de nem tal√°lhat√≥")
                    
            return True
            
        except Exception as e:
            logger.error(f"Hiba a modell bet√∂lt√©sekor: {e}")
            return False
            
    def predict_match(self, match_features: Dict) -> Dict:
        """Egy meccs eredm√©ny√©nek el≈ërejelz√©se"""
        
        if self.model is None:
            raise ValueError("Modell nincs bet√∂ltve. Haszn√°ld a load_best_model() met√≥dust.")
            
        # Features DataFrame-m√© alak√≠t√°sa
        df = pd.DataFrame([match_features])
        
        # Hi√°nyz√≥ features p√≥tl√°sa - optimaliz√°lt m√≥dszer
        missing_features = {}
        for feature in self.feature_names:
            if feature not in df.columns:
                missing_features[feature] = 0  # Alap√©rtelmezett √©rt√©k
                
        if missing_features:
            # Egyszerre hozz√°adjuk az √∂sszes hi√°nyz√≥ feature-t
            missing_df = pd.DataFrame([missing_features])
            df = pd.concat([df, missing_df], axis=1)
                
        # Feature sorrend
        X = df[self.feature_names]
        
        # Scaling (ha sz√ºks√©ges)
        if self.scaler is not None:
            X = self.scaler.transform(X)
            
        # Predikci√≥
        prediction = self.model.predict(X)[0]
        probabilities = self.model.predict_proba(X)[0]
        
        # Oszt√°lyok lek√©r√©se
        classes = self.model.classes_
        
        # Eredm√©ny √∂ssze√°ll√≠t√°sa
        result = {
            'prediction': prediction,
            'confidence': max(probabilities),
            'probabilities': {
                class_name: prob for class_name, prob in zip(classes, probabilities)
            },
            'model_info': {
                'model_type': self.metadata.get('model_name', 'unknown'),
                'accuracy': self.metadata.get('accuracy', 0),
                'timestamp': self.metadata.get('timestamp', '')
            }
        }
        
        return result
        
    def predict_matches_batch(self, matches_data: List[Dict]) -> List[Dict]:
        """T√∂bb meccs batch predikci√≥ja"""
        
        results = []
        
        for i, match_data in enumerate(matches_data):
            try:
                prediction = self.predict_match(match_data)
                prediction['match_index'] = i
                results.append(prediction)
                
            except Exception as e:
                logger.error(f"Hiba a {i}. meccs predikci√≥j√°n√°l: {e}")
                results.append({
                    'match_index': i,
                    'error': str(e),
                    'prediction': None
                })
                
        return results
        
    def create_prediction_report(self, predictions: List[Dict], match_info: List[Dict] = None) -> str:
        """Predikci√≥s jelent√©s l√©trehoz√°sa"""
        
        if not predictions:
            return "Nincs predikci√≥"
            
        report = []
        report.append("üîÆ MECCS EL≈êREJELZ√âSEK")
        report.append("=" * 50)
        report.append("")
        
        # Modell inform√°ci√≥
        if predictions[0].get('model_info'):
            model_info = predictions[0]['model_info']
            report.append(f"ü§ñ Modell: {model_info.get('model_type', 'N/A')}")
            report.append(f"üìä Accuracy: {model_info.get('accuracy', 0):.3f}")
            report.append(f"üìÖ Tr√©ning: {model_info.get('timestamp', 'N/A')}")
            report.append("")
            
        # Predikci√≥k
        for i, pred in enumerate(predictions):
            if pred.get('error'):
                report.append(f"‚ùå Meccs {i+1}: Hiba - {pred['error']}")
                continue
                
            match_name = f"Meccs {i+1}"
            if match_info and i < len(match_info):
                info = match_info[i]
                home = info.get('home_team', 'Home')
                away = info.get('away_team', 'Away')
                match_name = f"{home} vs {away}"
                
            report.append(f"‚öΩ {match_name}")
            report.append(f"   üéØ El≈ërejelz√©s: {pred['prediction']}")
            report.append(f"   üé≤ Biztons√°g: {pred['confidence']:.1%}")
            
            # Val√≥sz√≠n≈±s√©gek
            probs = pred['probabilities']
            report.append("   üìä Val√≥sz√≠n≈±s√©gek:")
            for outcome, prob in probs.items():
                report.append(f"      {outcome}: {prob:.1%}")
            report.append("")
            
        # √ñsszefoglal√≥
        valid_predictions = [p for p in predictions if not p.get('error')]
        if valid_predictions:
            prediction_counts = {}
            for pred in valid_predictions:
                outcome = pred['prediction']
                prediction_counts[outcome] = prediction_counts.get(outcome, 0) + 1
                
            report.append("üìà √ñSSZEFOGLAL√ì:")
            for outcome, count in prediction_counts.items():
                percentage = count / len(valid_predictions) * 100
                report.append(f"   {outcome}: {count} meccs ({percentage:.1f}%)")
                
        return "\n".join(report)
        
    def get_model_info(self) -> Dict:
        """Bet√∂lt√∂tt modell inform√°ci√≥i"""
        
        if self.model is None:
            return {"error": "Nincs bet√∂lt√∂tt modell"}
            
        return {
            "model_type": self.metadata.get('model_name', 'unknown'),
            "accuracy": self.metadata.get('accuracy', 0),
            "cv_mean": self.metadata.get('cv_mean', 0),
            "cv_std": self.metadata.get('cv_std', 0),
            "timestamp": self.metadata.get('timestamp', ''),
            "feature_count": len(self.feature_names),
            "uses_scaling": self.metadata.get('use_scaling', False),
            "best_params": self.metadata.get('best_params', {})
        }


if __name__ == "__main__":
    # Teszt predikci√≥
    logging.basicConfig(level=logging.INFO)
    
    predictor = MatchPredictor()
    
    # Modell bet√∂lt√©se
    if predictor.load_best_model():
        
        # Modell info
        info = predictor.get_model_info()
        print("ü§ñ MODELL INFORM√ÅCI√ì:")
        for key, value in info.items():
            print(f"  {key}: {value}")
        print()
        
        # Teszt predikci√≥ (dummy adatok)
        test_match = {
            'ball_possession_home': 55,
            'ball_possession_away': 45,
            'shots_home': 12,
            'shots_away': 8,
            'total_goals': 2.5,
            'is_weekend': 1,
            'is_top_league': 1
        }
        
        try:
            prediction = predictor.predict_match(test_match)
            
            print("üîÆ TESZT PREDIKCI√ì:")
            print(f"El≈ërejelz√©s: {prediction['prediction']}")
            print(f"Biztons√°g: {prediction['confidence']:.1%}")
            print("Val√≥sz√≠n≈±s√©gek:")
            for outcome, prob in prediction['probabilities'].items():
                print(f"  {outcome}: {prob:.1%}")
                
        except Exception as e:
            print(f"‚ùå Hiba a predikci√≥ sor√°n: {e}")
    else:
        print("‚ùå Nem siker√ºlt modellt bet√∂lteni")