import requests
from bs4 import BeautifulSoup
import json
import re
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import time
from datetime import datetime
import logging

# Logging be√°ll√≠t√°sa
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Magyar h√≥napnevek a d√°tum form√°z√°shoz
HUNGARIAN_MONTHS = {
    1: 'janu√°r', 2: 'febru√°r', 3: 'm√°rcius', 4: '√°prilis',
    5: 'm√°jus', 6: 'j√∫nius', 7: 'j√∫lius', 8: 'augusztus',
    9: 'september', 10: 'okt√≥ber', 11: 'november', 12: 'december'
}

# Statisztika magyar nevei √©s sz√∂veg p√°ros√≠t√°sok
STAT_TRANSLATIONS = {
    'shots on target': 'Kapura l√∂v√©sek',
    'shots off target': 'Kapu mell√© l√∂v√©sek',
    'shots blocked': 'Blokkolt l√∂v√©sek',
    'total shots': '√ñsszes l√∂v√©s',
    'possession': 'Labdabirtokl√°s',
    'corner kicks': 'Sz√∂gletek',
    'offsides': 'Lesek',
    'fouls': 'Szab√°lytalans√°gok',
    'yellow cards': 'S√°rga lapok',
    'red cards': 'Piros lapok',
    'goal kicks': 'Kapusr√∫g√°sok',
    'throw ins': 'Bedob√°sok',
    'passes': 'Passz',
    'attacks': 'T√°mad√°sok',
    'dangerous attacks': 'Vesz√©lyes t√°mad√°sok',
    'free kicks': 'Szabadr√∫g√°sok',
    'crosses': 'Bead√°sok',
    'substitutions': 'Cser√©k',
    'saves': 'V√©d√©sek',
    'pass accuracy': 'Passz pontoss√°g'
}

# Esem√©ny t√≠pusok felismer√©se
EVENT_TYPE_PATTERNS = {
    'G√≥l': [
        r'(?:g√≥l|goal|‚öΩ)',
        r'(?:scored|szerzett)',
        r'(?:finds the net|betal√°l)',
    ],
    'Tizenegyesg√≥l': [
        r'(?:penalty|tizenegyes|penalti)',
        r'\(P\)',
        r'(?:from the spot|a pontr√≥l)',
    ],
    '√ñng√≥l': [
        r'(?:own goal|√∂ng√≥l|autogol)',
        r'\(OG\)',
    ],
    'S√°rga lap': [
        r'(?:yellow card|s√°rga lap|amarilla)',
        r'üü®',
        r'(?:booked|k√∂nyvelt√©k)',
    ],
    'Piros lap': [
        r'(?:red card|piros lap|roja)',
        r'üü•',
        r'(?:sent off|ki√°ll√≠tott√°k)',
    ],
    'M√°sodik s√°rga lap': [
        r'(?:second yellow|m√°sodik s√°rga)',
        r'(?:2nd yellow|2\. s√°rga)',
    ],
    'Csere': [
        r'(?:substitution|csere|cambio)',
        r'‚Üí|->',
        r'(?:replaced by|lecser√©lte)',
    ],
    'VAR': [
        r'(?:VAR|video)',
        r'(?:reviewed|ellen≈ërizte)',
    ],
}

class MatchScraper:
    """Enhanced V7 Match Scraper oszt√°ly"""

    def __init__(self, headless=True, debug=False):
        self.debug = debug
        self.headless = headless
        self.driver = None
        self.setup_driver()

    def setup_driver(self):
        """Chrome driver be√°ll√≠t√°sa"""
        chrome_options = webdriver.ChromeOptions()

        if self.headless:
            chrome_options.add_argument('--headless')

        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')

        try:
            self.driver = webdriver.Chrome(
                service=ChromeService(ChromeDriverManager().install()),
                options=chrome_options
            )

            # Webdriver tulajdons√°g elrejt√©se
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

            logger.info("Chrome driver successfully initialized")

        except Exception as e:
            logger.error(f"Failed to initialize Chrome driver: {e}")
            raise

    def close_driver(self):
        """Driver bez√°r√°sa"""
        if self.driver:
            self.driver.quit()
            logger.info("Chrome driver closed")

    def handle_cookie_consent(self):
        """Tov√°bbfejlesztett cookie consent kezel√©s"""
        try:
            time.sleep(2)

            # T√∂bbf√©le cookie banner keres√©se
            cookie_selectors = [
                "button[class*='accept']",
                "button[class*='cookie']",
                "button[class*='consent']",
                "button[id*='accept']",
                "button[id*='cookie']",
                "button[id*='consent']",
                "[class*='cookie-consent'] button",
                "[class*='gdpr'] button",
                "button:contains('Accept')",
                "button:contains('Elfogad')",
                "button:contains('OK')",
            ]

            for selector in cookie_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        if element.is_displayed() and element.is_enabled():
                            self.driver.execute_script("arguments[0].click();", element)
                            logger.info(f"Cookie consent closed with selector: {selector}")
                            time.sleep(1)
                            return True
                except:
                    continue

            # JavaScript alap√∫ bez√°r√°s
            self.driver.execute_script("""
                var cookieElements = document.querySelectorAll('[class*="cookie"], [class*="consent"], [id*="cookie"], [id*="consent"]');
                cookieElements.forEach(function(el) {
                    if (el.style.display !== 'none' && el.offsetParent !== null) {
                        el.style.display = 'none';
                    }
                });

                // Overlay-ek elt√°vol√≠t√°sa
                var overlays = document.querySelectorAll('[class*="overlay"], [class*="modal"], [class*="popup"]');
                overlays.forEach(function(el) {
                    el.style.display = 'none';
                });
            """)

            logger.info("Cookie consent closed via JavaScript")
            return True

        except Exception as e:
            logger.warning(f"Cookie consent handling error: {e}")
            return False

    def extract_league_info(self, soup):
        """Bajnoks√°g √©s fordul√≥ inform√°ci√≥k kinyer√©se"""
        league_info = {
            'full_league_name': '',
            'short_league_name': '',
            'round_number': '',
            'season': '',
            'formatted_header': ''
        }

        try:
            # 1. Title elemb≈ël
            title = soup.find('title')
            if title and title.text:
                title_text = title.text.strip()
                if self.debug:
                    logger.debug(f"Title: {title_text}")

                # Bolivia keres√©se
                if 'bolivia' in title_text.lower():
                    league_info['full_league_name'] = "Bolivia Division Profesional"
                    league_info['short_league_name'] = "BDP"

            # 2. Meta inform√°ci√≥kb√≥l
            meta_elements = soup.find_all('meta')
            for meta in meta_elements:
                content = meta.get('content', '')
                if 'bolivia' in content.lower() or 'division profesional' in content.lower():
                    league_info['full_league_name'] = "Bolivia Division Profesional"
                    league_info['short_league_name'] = "BDP"

            # 3. Struktur√°lt keres√©s a lap tartalm√°ban
            try:
                # Keres√©s speci√°lis szelektorokkal
                league_selectors = [
                    "[class*='league']", "[class*='tournament']", "[class*='competition']",
                    "[class*='championship']", "h1", "h2", ".title", ".header"
                ]

                for selector in league_selectors:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        text = element.text.strip().lower()
                        if 'bolivia' in text or 'division' in text:
                            league_info['full_league_name'] = "Bolivia Division Profesional"
                            league_info['short_league_name'] = "BDP"
                            break

                # 4. Fordul√≥ keres√©se
                round_patterns = [
                    r'(?:round|jornada|fecha|fordul√≥|matchday)\s*(\d+)',
                    r'(\d+)\.?\s*(?:fordul√≥|round|jornada)',
                    r'week\s*(\d+)',
                    r'(\d+)\.?\s*h√©t'
                ]

                page_text = self.driver.find_element(By.TAG_NAME, "body").text
                for pattern in round_patterns:
                    match = re.search(pattern, page_text, re.IGNORECASE)
                    if match:
                        round_num = match.group(1)
                        league_info['round_number'] = f"{round_num}. fordul√≥"
                        break

                # 5. Szezon keres√©se
                season_patterns = [
                    r'(20\d{2}[-/]20?\d{2})',
                    r'(20\d{2})',
                    r'season\s*(20\d{2})'
                ]

                for pattern in season_patterns:
                    match = re.search(pattern, page_text, re.IGNORECASE)
                    if match:
                        league_info['season'] = match.group(1)
                        break

            except Exception as e:
                logger.warning(f"League info extraction error: {e}")

            # 6. Form√°zott header l√©trehoz√°sa
            parts = []
            if league_info['full_league_name']:
                parts.append(league_info['full_league_name'])
            if league_info['season']:
                parts.append(f"({league_info['season']})")
            if league_info['round_number']:
                parts.append(f"- {league_info['round_number']}")

            league_info['formatted_header'] = ' '.join(parts)

        except Exception as e:
            logger.error(f"League info extraction failed: {e}")

        return league_info

    def extract_teams_and_score(self, soup):
        """Csapatok √©s eredm√©ny kinyer√©se"""
        teams_info = {
            'home_team': '',
            'away_team': '',
            'score': {
                'home': '',
                'away': '',
                'full_score': ''
            }
        }

        try:
            # 1. Csapat nevek keres√©se
            team_selectors = [
                "[class*='team']", "[class*='home']", "[class*='away']",
                "[class*='participant']", "[class*='competitor']"
            ]

            teams = []
            for selector in team_selectors:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for element in elements:
                    text = element.text.strip()
                    # Sz≈±r√©s: √©sszer≈± csapatn√©v hossz
                    if 3 <= len(text) <= 30 and text not in teams:
                        # Kiz√°rjuk a sz√°mokat √©s d√°tumokat
                        if not re.match(r'^\d+[-:]\d+$', text) and not re.match(r'^\d{2}[./]\d{2}', text):
                            teams.append(text)

            # Az els≈ë k√©t csapat val√≥sz√≠n≈±leg a hazai √©s vend√©g
            if len(teams) >= 2:
                teams_info['home_team'] = teams[0]
                teams_info['away_team'] = teams[1]

            # 2. Eredm√©ny keres√©se
            score_selectors = [
                "[class*='score']", "[class*='result']", "[class*='goals']"
            ]

            for selector in score_selectors:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for element in elements:
                    score_text = element.text.strip()
                    score_match = re.search(r'(\d+)\s*[-:]\s*(\d+)', score_text)
                    if score_match:
                        teams_info['score'] = {
                            'home': score_match.group(1),
                            'away': score_match.group(2),
                            'full_score': score_text
                        }
                        break

                if teams_info['score']['full_score']:
                    break

        except Exception as e:
            logger.error(f"Teams and score extraction failed: {e}")

        return teams_info

    def extract_datetime_info(self, soup):
        """D√°tum √©s id≈ë inform√°ci√≥k kinyer√©se"""
        datetime_info = {
            'date': '',
            'time': '',
            'datetime_formatted': '',
            'timezone': ''
        }

        try:
            # 1. Meta elemek keres√©se
            meta_elements = soup.find_all('meta')
            for meta in meta_elements:
                if meta.get('property') == 'article:published_time' or meta.get('name') == 'date':
                    content = meta.get('content', '')
                    if content:
                        datetime_info['datetime_formatted'] = content
                        break

            # 2. Struktur√°lt keres√©s
            datetime_selectors = [
                "[class*='date']", "[class*='time']", "[class*='datetime']",
                "[datetime]", "time", "[class*='kickoff']"
            ]

            for selector in datetime_selectors:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for element in elements:
                    text = element.text.strip()

                    # D√°tum keres√©se
                    date_patterns = [
                        r'(\d{1,2})[./](\d{1,2})[./](20\d{2})',
                        r'(20\d{2})[/-](\d{1,2})[/-](\d{1,2})',
                        r'(\d{1,2})\s+(januar|februar|m√°rcius|√°prilis|m√°jus|j√∫nius|j√∫lius|augusztus|szeptember|okt√≥ber|november|december)\s+(20\d{2})'
                    ]

                    for pattern in date_patterns:
                        match = re.search(pattern, text, re.IGNORECASE)
                        if match:
                            datetime_info['date'] = text
                            break

                    # Id≈ë keres√©se
                    time_pattern = r'(\d{1,2}):(\d{2})'
                    time_match = re.search(time_pattern, text)
                    if time_match:
                        datetime_info['time'] = f"{time_match.group(1)}:{time_match.group(2)}"

                    if datetime_info['date'] and datetime_info['time']:
                        break

                if datetime_info['date']:
                    break

        except Exception as e:
            logger.error(f"DateTime extraction failed: {e}")

        return datetime_info

    def extract_enhanced_extra_info(self, soup):
        """Tov√°bbfejlesztett extra inform√°ci√≥k kinyer√©se"""
        extra_info = {
            'referee': '',
            'venue': '',
            'capacity': '',
            'attendance': '',
            'weather': '',
            'temperature': ''
        }

        try:
            # Lapoz√°s a lap alj√°ra
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1)

            # 1. Speci√°lis inform√°ci√≥s blokkok keres√©se
            info_selectors = [
                "[class*='match-detail']", "[class*='game-detail']", "[class*='match-info']",
                "[class*='additional-info']", "[class*='referee']", "[class*='venue']",
                "[class*='stadium']", "[class*='attendance']", "[class*='weather']",
                ".match-facts", ".game-facts", ".additional-facts"
            ]

            for selector in info_selectors:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for element in elements:
                    try:
                        text = element.text.strip()
                        if 5 <= len(text) <= 500:
                            self._parse_extra_info_text(text, extra_info)
                    except:
                        continue

            # 2. T√°bl√°zatok keres√©se
            tables = self.driver.find_elements(By.TAG_NAME, "table")
            for table in tables:
                try:
                    table_text = table.text.strip()
                    if len(table_text) > 10:
                        self._parse_table_extra_info(table, extra_info)
                except:
                    continue

            # 3. JavaScript alap√∫ keres√©s
            js_extra_info = self._extract_extra_info_js()
            for key, value in js_extra_info.items():
                if value and not extra_info[key]:
                    extra_info[key] = value

        except Exception as e:
            logger.error(f"Extra info extraction failed: {e}")

        return extra_info

    def _parse_extra_info_text(self, text, extra_info):
        """Sz√∂veges extra inform√°ci√≥k feldolgoz√°sa"""
        # J√°t√©kvezet≈ë
        if not extra_info['referee']:
            ref_patterns = [
                r'(?:referee|√°rbitro|b√≠r√≥|j√°t√©kvezet≈ë|arbitro|ref)\s*:?\s*([a-z√°√©√≠√≥√∂≈ë√º≈±\w\s\.]+)',
                r'(?:official|hivatalos)\s*:?\s*([a-z√°√©√≠√≥√∂≈ë√º≈±\w\s\.]+)'
            ]
            for pattern in ref_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    referee_name = match.group(1).strip()
                    if 2 < len(referee_name) < 50:
                        extra_info['referee'] = referee_name
                        break

        # Helysz√≠n
        if not extra_info['venue']:
            venue_patterns = [
                r'(?:venue|stadium|helysz√≠n|p√°lya|stadion|estadio)\s*:?\s*([a-z√°√©√≠√≥√∂≈ë√º≈±\w\s\.\-]+)',
                r'(?:played at|j√°tszott|jugado en)\s*:?\s*([a-z√°√©√≠√≥√∂≈ë√º≈±\w\s\.\-]+)'
            ]
            for pattern in venue_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    venue_name = match.group(1).strip()
                    if 2 < len(venue_name) < 100:
                        extra_info['venue'] = venue_name
                        break

        # Befogad√≥k√©pess√©g
        if not extra_info['capacity']:
            capacity_patterns = [
                r'(?:capacity|befogad√≥k√©pess√©g|kapacit√°s|capacidad)\s*:?\s*(\d+(?:[\.,]\d+)*)',
                r'(?:seats|√ºl≈ëhely|asientos)\s*:?\s*(\d+(?:[\.,]\d+)*)'
            ]
            for pattern in capacity_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    extra_info['capacity'] = match.group(1).strip()
                    break

        # N√©z≈ësz√°m
        if not extra_info['attendance']:
            attendance_patterns = [
                r'(?:attendance|n√©z≈ësz√°m|n√©z≈ëk|asistencia)\s*:?\s*(\d+(?:[\.,]\d+)*)',
                r'(?:spectators|k√∂z√∂ns√©g|espectadores)\s*:?\s*(\d+(?:[\.,]\d+)*)'
            ]
            for pattern in attendance_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    extra_info['attendance'] = match.group(1).strip()
                    break

        # Id≈ëj√°r√°s
        if not extra_info['weather']:
            weather_patterns = [
                r'(?:weather|id≈ëj√°r√°s|clima)\s*:?\s*([a-z√°√©√≠√≥√∂≈ë√º≈±\w\s]+)',
                r'(?:conditions|k√∂r√ºlm√©nyek|condiciones)\s*:?\s*([a-z√°√©√≠√≥√∂≈ë√º≈±\w\s]+)'
            ]
            for pattern in weather_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    weather = match.group(1).strip()
                    if 2 < len(weather) < 50:
                        extra_info['weather'] = weather
                        break

        # H≈ëm√©rs√©klet
        if not extra_info['temperature']:
            temp_patterns = [
                r'(?:temperature|h≈ëm√©rs√©klet|temperatura)\s*:?\s*(\d+(?:\.\d+)?¬∞?[CF]?)',
                r'(\d+¬∞[CF])',
                r'(\d+\s*degrees?)'
            ]
            for pattern in temp_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    extra_info['temperature'] = match.group(1).strip()
                    break

    def _parse_table_extra_info(self, table, extra_info):
        """T√°bl√°zat alap√∫ extra inform√°ci√≥k feldolgoz√°sa"""
        try:
            rows = table.find_elements(By.TAG_NAME, "tr")
            for row in rows:
                cells = row.find_elements(By.TAG_NAME, "td")
                if len(cells) >= 2:
                    key_cell = cells[0].text.strip().lower()
                    value_cell = cells[1].text.strip()

                    if 'referee' in key_cell or 'b√≠r√≥' in key_cell:
                        if not extra_info['referee'] and value_cell:
                            extra_info['referee'] = value_cell
                    elif 'venue' in key_cell or 'stadium' in key_cell or 'helysz√≠n' in key_cell:
                        if not extra_info['venue'] and value_cell:
                            extra_info['venue'] = value_cell
                    elif 'attendance' in key_cell or 'n√©z≈ësz√°m' in key_cell:
                        if not extra_info['attendance'] and value_cell:
                            extra_info['attendance'] = value_cell
                    elif 'capacity' in key_cell or 'kapacit√°s' in key_cell:
                        if not extra_info['capacity'] and value_cell:
                            extra_info['capacity'] = value_cell
        except:
            pass

    def _extract_extra_info_js(self):
        """JavaScript alap√∫ extra inform√°ci√≥ kinyer√©s"""
        try:
            js_script = """
            var result = {referee: '', venue: '', capacity: '', attendance: '', weather: '', temperature: ''};
            var allElements = document.querySelectorAll('*');

            for (var i = 0; i < allElements.length; i++) {
                var element = allElements[i];
                var text = element.textContent || element.innerText || '';

                if (text.length < 5 || text.length > 200) continue;

                // Referee keres√©se
                if (!result.referee) {
                    var refMatch = text.match(/(?:referee|√°rbitro|b√≠r√≥|j√°t√©kvezet≈ë)\\s*:?\\s*([a-z√°√©√≠√≥√∂≈ë√º≈±\\w\\s\\.]+)/i);
                    if (refMatch && refMatch[1] && refMatch[1].length > 2 && refMatch[1].length < 50) {
                        result.referee = refMatch[1].trim();
                    }
                }

                // Venue keres√©se
                if (!result.venue) {
                    var venueMatch = text.match(/(?:venue|stadium|helysz√≠n|p√°lya|stadion)\\s*:?\\s*([a-z√°√©√≠√≥√∂≈ë√º≈±\\w\\s\\.\\-]+)/i);
                    if (venueMatch && venueMatch[1] && venueMatch[1].length > 2 && venueMatch[1].length < 100) {
                        result.venue = venueMatch[1].trim();
                    }
                }

                // Tov√°bbi mez≈ëk...
            }

            return result;
            """

            return self.driver.execute_script(js_script) or {}

        except Exception as e:
            logger.warning(f"JavaScript extra info extraction failed: {e}")
            return {}

    def extract_enhanced_events(self, soup):
        """Tov√°bbfejlesztett esem√©nyek kinyer√©se"""
        events = []

        try:
            # Esem√©nyek keres√©se t√∂bb szelektorral
            event_selectors = [
                "[class*='event']", "[class*='incident']", "[class*='timeline']",
                "[class*='summary']", "[class*='highlight']", "[class*='moment']",
                "[class*='action']", "[class*='match-event']"
            ]

            for selector in event_selectors:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                for element in elements:
                    try:
                        event_text = element.text.strip()
                        if len(event_text) < 5:
                            continue

                        event = self._parse_event_text(event_text)
                        if event:
                            events.append(event)

                    except Exception as e:
                        if self.debug:
                            logger.debug(f"Event parsing error: {e}")
                        continue

            # Duplik√°tumok elt√°vol√≠t√°sa
            events = self._remove_duplicate_events(events)

            # Id≈ërend szerinti rendez√©s
            events.sort(key=lambda x: self._parse_event_time(x.get('time', '0')))

        except Exception as e:
            logger.error(f"Events extraction failed: {e}")

        return events

    def _parse_event_text(self, event_text):
        """Esem√©ny sz√∂veg feldolgoz√°sa"""
        # Id≈ë keres√©se
        time_match = re.search(r"(\d{1,2}(?:\+\d+)?)'", event_text)
        if not time_match:
            return None

        event_time = time_match.group(1)

        # Esem√©ny t√≠pus √©s r√©szletek felismer√©se
        event_type = "Esem√©ny"
        player = ""
        team = ""
        description = event_text

        # Esem√©ny t√≠pusok ellen≈ërz√©se
        for event_name, patterns in EVENT_TYPE_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, event_text, re.IGNORECASE):
                    event_type = event_name
                    break
            if event_type != "Esem√©ny":
                break

        # J√°t√©kos √©s csapat kinyer√©se
        player_team_patterns = [
            r"(\w+(?:\s+\w+)*)\s*\[(\w+)\]",
            r"(\w+(?:\s+\w+)*)\s*\((\w+)\)",
            r"(\w+(?:\s+\w+)*)\s*-\s*(\w+)"
        ]

        for pattern in player_team_patterns:
            match = re.search(pattern, event_text)
            if match:
                player = match.group(1).strip()
                team = match.group(2).strip()
                break

        # Csere speci√°lis kezel√©se
        if event_type == "Csere" and "‚Üí" in event_text:
            sub_match = re.search(r"(\w+(?:\s+\w+)*)\s*‚Üí\s*(\w+(?:\s+\w+)*)\s*\[(\w+)\]", event_text)
            if sub_match:
                player = f"{sub_match.group(1)} ‚Üí {sub_match.group(2)}"
                team = sub_match.group(3).strip()

        return {
            "time": event_time,
            "type": event_type,
            "player": player,
            "team": team,
            "description": description.strip()
        }

    def _parse_event_time(self, time_str):
        """Esem√©ny id≈ë konvert√°l√°sa rendez√©shez"""
        try:
            if '+' in time_str:
                base_time, extra_time = time_str.split('+')
                return int(base_time) + int(extra_time)
            return int(time_str.replace("'", ""))
        except:
            return 0

    def _remove_duplicate_events(self, events):
        """Duplik√°lt esem√©nyek elt√°vol√≠t√°sa"""
        seen = set()
        unique_events = []

        for event in events:
            event_key = (event.get('time', ''), event.get('type', ''), event.get('player', ''))
            if event_key not in seen:
                seen.add(event_key)
                unique_events.append(event)

        return unique_events

    def extract_enhanced_statistics(self, soup):
        """Tov√°bbfejlesztett statisztik√°k kinyer√©se"""
        statistics = {}

        try:
            # Statisztika szelektorok
            stat_selectors = [
                "[class*='stat']", "[class*='statistic']", "[class*='stats']",
                "[class*='data']", "[class*='numbers']"
            ]

            for selector in stat_selectors:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                for element in elements:
                    try:
                        stat_text = element.text.strip().lower()

                        # Statisztika n√©v azonos√≠t√°sa
                        stat_name = None
                        for eng_name, hun_name in STAT_TRANSLATIONS.items():
                            if eng_name in stat_text:
                                stat_name = hun_name
                                break

                        if stat_name:
                            # Sz√°mok keres√©se
                            numbers = re.findall(r'\d+%?', element.text)
                            if len(numbers) >= 2:
                                statistics[stat_name] = {
                                    'home': numbers[0],
                                    'away': numbers[1],
                                    'raw_text': element.text.strip()
                                }
                            elif len(numbers) == 1:
                                # Sz√°zal√©kos √©rt√©k eset√©n
                                if '%' in numbers[0]:
                                    statistics[stat_name] = {
                                        'home': numbers[0],
                                        'away': '',
                                        'raw_text': element.text.strip()
                                    }

                    except Exception as e:
                        if self.debug:
                            logger.debug(f"Statistic parsing error: {e}")
                        continue

        except Exception as e:
            logger.error(f"Statistics extraction failed: {e}")

        return statistics

    def extract_lineups(self, soup):
        """Csapat√∂ssze√°ll√≠t√°sok kinyer√©se"""
        lineups = {
            'home_team': [],
            'away_team': [],
            'formations': {
                'home': '',
                'away': ''
            }
        }

        try:
            # Lineup szelektorok
            lineup_selectors = [
                "[class*='lineup']", "[class*='formation']", "[class*='team-list']",
                "[class*='players']", "[class*='starting']"
            ]

            for selector in lineup_selectors:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                for element in elements:
                    try:
                        lineup_text = element.text.strip()
                        if len(lineup_text) > 10:

                            # J√°t√©kos nevek kinyer√©se (nevek nagy bet≈±vel kezd≈ëdnek)
                            player_names = re.findall(
                                r'[A-Z√Å√â√ç√ì√ñ≈ê√ú≈∞][a-z√°√©√≠√≥√∂≈ë√º≈±]+(?:\s+[A-Z√Å√â√ç√ì√ñ≈ê√ú≈∞][a-z√°√©√≠√≥√∂≈ë√º≈±]+)*',
                                lineup_text
                            )

                            # Sz≈±r√©s: csak val√≥di nevek
                            filtered_players = []
                            for name in player_names:
                                if (2 < len(name) < 30 and
                                    not re.match(r'^\d+$', name) and
                                    name.lower() not in ['team', 'formation', 'lineup', 'players']):
                                    filtered_players.append(name)

                            # Feloszt√°s hazai √©s vend√©g csapatra
                            if len(filtered_players) > 10:  # Legal√°bb 11 j√°t√©kos
                                mid_point = len(filtered_players) // 2
                                lineups['home_team'] = filtered_players[:mid_point]
                                lineups['away_team'] = filtered_players[mid_point:]
                                break

                    except Exception as e:
                        if self.debug:
                            logger.debug(f"Lineup parsing error: {e}")
                        continue

                if lineups['home_team'] or lineups['away_team']:
                    break

            # Form√°ci√≥k keres√©se
            formation_patterns = [
                r'(\d{1}-\d{1}-\d{1})',
                r'(\d{1}-\d{1}-\d{1}-\d{1})',
                r'(\d{1}-\d{2}-\d{1})',
                r'(\d{1}-\d{2}-\d{2})'
            ]

            page_text = self.driver.find_element(By.TAG_NAME, "body").text
            formations_found = []

            for pattern in formation_patterns:
                matches = re.findall(pattern, page_text)
                formations_found.extend(matches)

            if len(formations_found) >= 2:
                lineups['formations']['home'] = formations_found[0]
                lineups['formations']['away'] = formations_found[1]
            elif len(formations_found) == 1:
                lineups['formations']['home'] = formations_found[0]

        except Exception as e:
            logger.error(f"Lineups extraction failed: {e}")

        return lineups

    def scrape_match_details(self, match_url):
        """F≈ë scraping funkci√≥"""
        logger.info(f"üöÄ V7 Enhanced Scraping: {match_url}")

        try:
            # Oldal bet√∂lt√©se
            self.driver.get(match_url)
            time.sleep(3)

            # Cookie consent kezel√©se
            self.handle_cookie_consent()
            time.sleep(2)

            # BeautifulSoup inicializ√°l√°sa
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')

            # Alap√©rtelmezett strukt√∫ra
            match_details = {
                'header': {},
                'summary': [],
                'lineups': {},
                'statistics': {},
                'extra_info': {},
                'scraping_metadata': {
                    'version': 'v7',
                    'timestamp': datetime.now().isoformat(),
                    'source_url': match_url,
                    'user_agent': 'Enhanced Scraper V7'
                }
            }

            # Adatok kinyer√©se
            logger.info("Extracting league information...")
            league_info = self.extract_league_info(soup)

            logger.info("Extracting teams and score...")
            teams_info = self.extract_teams_and_score(soup)

            logger.info("Extracting datetime information...")
            datetime_info = self.extract_datetime_info(soup)

            logger.info("Extracting extra information...")
            extra_info = self.extract_enhanced_extra_info(soup)

            logger.info("Extracting events...")
            events = self.extract_enhanced_events(soup)

            logger.info("Extracting statistics...")
            statistics = self.extract_enhanced_statistics(soup)

            logger.info("Extracting lineups...")
            lineups = self.extract_lineups(soup)

            # Adatok √∂sszevon√°sa
            match_details['header'] = {**league_info, **teams_info, **datetime_info}
            match_details['extra_info'] = extra_info
            match_details['summary'] = events
            match_details['statistics'] = statistics
            match_details['lineups'] = lineups

            logger.info("‚úÖ Scraping completed successfully")
            return match_details

        except Exception as e:
            logger.error(f"‚ùå Scraping failed: {e}")
            return None

def test_enhanced_scraper_v7():
    """V7 scraper tesztel√©se"""
    test_url = "https://www.eredmenyek.com/fodbold/bolivia/division-profesional/bolivar-vs-independiente/fVLU1Wtb/"

    print("=" * 70)
    print("üöÄ ENHANCED V7 SCRAPER TESZT")
    print("=" * 70)

    scraper = MatchScraper(headless=True, debug=True)

    try:
        match_details = scraper.scrape_match_details(test_url)

        if not match_details:
            print("‚ùå Scraping failed!")
            return

        # JSON ment√©se
        filename = "/home/bandi/Documents/code/2025/sp3/scrapping_data/v7_enhanced_match_details.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(match_details, f, ensure_ascii=False, indent=2)

        print(f"\n‚úÖ Eredm√©ny mentve: {filename}")

        # √ñsszefoglal√≥ ki√≠r√°sa
        print_summary(match_details)

    finally:
        scraper.close_driver()

def print_summary(match_details):
    """√ñsszefoglal√≥ ki√≠r√°sa"""
    header = match_details['header']
    extra = match_details['extra_info']

    print(f"\nüìã HEADER INFORM√ÅCI√ìK:")
    print(f"üèÜ Bajnoks√°g: {header.get('full_league_name', 'Nincs adat')}")
    print(f"üìÖ Szezon: {header.get('season', 'Nincs adat')}")
    print(f"üìÖ Fordul√≥: {header.get('round_number', 'Nincs adat')}")
    print(f"üìù Form√°zott header: {header.get('formatted_header', 'Nincs adat')}")
    print(f"üè† Hazai csapat: {header.get('home_team', 'Nincs adat')}")
    print(f"‚úàÔ∏è Vend√©g csapat: {header.get('away_team', 'Nincs adat')}")
    print(f"‚öΩ Eredm√©ny: {header.get('score', {}).get('full_score', 'Nincs adat')}")
    print(f"üìÖ D√°tum: {header.get('date', 'Nincs adat')}")
    print(f"üïê Id≈ë: {header.get('time', 'Nincs adat')}")

    print(f"\nüèüÔ∏è EXTRA INFORM√ÅCI√ìK:")
    print(f"üë®‚Äç‚öñÔ∏è J√°t√©kvezet≈ë: {extra.get('referee', 'Nincs adat')}")
    print(f"üèüÔ∏è Helysz√≠n: {extra.get('venue', 'Nincs adat')}")
    print(f"üë• Befogad√≥k√©pess√©g: {extra.get('capacity', 'Nincs adat')}")
    print(f"üìä N√©z≈ësz√°m: {extra.get('attendance', 'Nincs adat')}")
    print(f"üå§Ô∏è Id≈ëj√°r√°s: {extra.get('weather', 'Nincs adat')}")
    print(f"üå°Ô∏è H≈ëm√©rs√©klet: {extra.get('temperature', 'Nincs adat')}")

    print(f"\nüìä √ñSSZES√çT√âS:")
    print(f"üìã Esem√©nyek sz√°ma: {len(match_details['summary'])}")
    print(f"üìä Statisztik√°k sz√°ma: {len(match_details['statistics'])}")
    print(f"üë• Hazai j√°t√©kosok: {len(match_details['lineups'].get('home_team', []))}")
    print(f"üë• Vend√©g j√°t√©kosok: {len(match_details['lineups'].get('away_team', []))}")
    print(f"‚öΩ Hazai form√°ci√≥: {match_details['lineups'].get('formations', {}).get('home', 'Nincs adat')}")
    print(f"‚öΩ Vend√©g form√°ci√≥: {match_details['lineups'].get('formations', {}).get('away', 'Nincs adat')}")

    # Els≈ë n√©h√°ny esem√©ny
    if match_details['summary']:
        print(f"\nüîç ESEM√âNYEK (els≈ë 10):")
        for i, event in enumerate(match_details['summary'][:10]):
            print(f"  {i+1}. {event['time']} - {event['type']} - {event.get('player', 'Nincs j√°t√©kos')} [{event.get('team', '')}]")

    # Statisztik√°k
    if match_details['statistics']:
        print(f"\nüìä STATISZTIK√ÅK (els≈ë 8):")
        for i, (stat_name, values) in enumerate(list(match_details['statistics'].items())[:8]):
            print(f"  {stat_name}: {values['home']} - {values['away']}")

    print(f"=" * 70)

if __name__ == "__main__":
    test_enhanced_scraper_v7()
