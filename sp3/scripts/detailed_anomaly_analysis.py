#!/home/bandi/Documents/code/2025/sp3/.venv/bin/python3

"""
R√©szletes duplik√°ci√≥ √©s anom√°lia elemz√©s
Megvizsg√°lja:
1. Mi volt a duplik√°ci√≥ ha tiszta volt a DB?
2. Mi√©rt ilyen nagy k√ºl√∂nbs√©g a TXT √©s JSON k√∂z√∂tt?
3. Mi okozza az anom√°li√°kat?
"""

import json
import os
import psycopg2
from collections import defaultdict, Counter
from typing import Dict, List, Any
import re

# Database config
DB_CONFIG = {
    'host': 'localhost',
    'database': 'sp3_db',
    'user': 'sp3_user',
    'password': 'sp3_password',
    'port': 55432
}

def analyze_json_duplicates():
    """R√©szletes JSON duplik√°ci√≥ elemz√©s"""
    print("üîç JSON DUPLIK√ÅCI√ì R√âSZLETES ELEMZ√âSE")
    print("=" * 50)

    json_dir = "/home/bandi/Documents/code/2025/sp3/ml_pipeline/betting_extractor/jsons/processed"

    all_matches = []
    match_id_counts = defaultdict(list)

    # Collect all matches
    for filename in os.listdir(json_dir):
        if filename.endswith('.json'):
            filepath = os.path.join(json_dir, filename)
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
                matches = data.get('matches', [])

                for i, match in enumerate(matches):
                    match_id = f"{match.get('date', 'NO_DATE')}_{match.get('team1', 'NO_TEAM1')}_{match.get('team2', 'NO_TEAM2')}_{match.get('competition', 'NO_COMP')}"

                    match_info = {
                        'match_id': match_id,
                        'file': filename,
                        'index': i,
                        'date': match.get('date'),
                        'team1': match.get('team1'),
                        'team2': match.get('team2'),
                        'competition': match.get('competition'),
                        'league': match.get('league'),
                        'time': match.get('time'),
                        'markets_count': len(match.get('markets', [])),
                        'markets': match.get('markets', [])
                    }

                    all_matches.append(match_info)
                    match_id_counts[match_id].append(match_info)

    print(f"üìä √ñsszes JSON meccs: {len(all_matches)}")
    print(f"üìä Egyedi match ID-k: {len(match_id_counts)}")

    # Find duplicates
    duplicates = {mid: matches for mid, matches in match_id_counts.items() if len(matches) > 1}
    print(f"üìä Duplik√°lt match ID-k: {len(duplicates)}")
    print(f"üìä Duplik√°lt meccsek sz√°ma: {sum(len(matches) for matches in duplicates.values())}")

    if duplicates:
        print(f"\nüîç DUPLIK√ÅTUMOK R√âSZLETEI:")

        # Analyze duplicate patterns
        duplicate_patterns = defaultdict(int)
        file_combinations = defaultdict(int)

        for match_id, duplicate_matches in list(duplicates.items())[:10]:
            print(f"\nüìù Match ID: {match_id}")

            files = [m['file'] for m in duplicate_matches]
            file_combinations[tuple(sorted(files))] += 1

            for i, match in enumerate(duplicate_matches):
                print(f"   {i+1}. {match['file']} - {match['markets_count']} piac")
                print(f"      Date: {match['date']}")
                print(f"      Teams: {match['team1']} vs {match['team2']}")
                print(f"      Competition: {match['competition']}")
                print(f"      League: {match['league']}")

                # Check for content differences
                if i > 0:
                    prev_match = duplicate_matches[i-1]
                    if match['markets'] != prev_match['markets']:
                        print(f"      ‚ö†Ô∏è Markets DIFFER from previous!")
                        print(f"         Prev: {len(prev_match['markets'])} markets")
                        print(f"         This: {len(match['markets'])} markets")
                        duplicate_patterns['different_markets'] += 1
                    else:
                        print(f"      ‚úÖ Markets identical to previous")
                        duplicate_patterns['identical_markets'] += 1

        print(f"\nüìà DUPLIK√ÅTUM MINT√ÅK:")
        for pattern, count in duplicate_patterns.items():
            print(f"   {pattern}: {count}")

        print(f"\nüìà F√ÅJL KOMBIN√ÅCI√ìK:")
        for file_combo, count in sorted(file_combinations.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"   {' + '.join(file_combo)}: {count} duplik√°tum")

    return len(all_matches), len(match_id_counts), len(duplicates)

def analyze_txt_vs_json_difference():
    """Elemzi a TXT √©s JSON k√∂z√∂tti nagy k√ºl√∂nbs√©geket"""
    print(f"\nüîç TXT vs JSON K√úL√ñNBS√âGEK ELEMZ√âSE")
    print("=" * 50)

    txt_dir = "/home/bandi/Documents/code/2025/sp3/ml_pipeline/betting_extractor/txts"
    json_dir = "/home/bandi/Documents/code/2025/sp3/ml_pipeline/betting_extractor/jsons/processed"

    # Analyze a specific TXT file in detail
    txt_file = "Web__47sz__P__06-13_lines.txt"
    json_file = "Web__47sz__P__06-13_lines.json"

    txt_path = os.path.join(txt_dir, txt_file)
    json_path = os.path.join(json_dir, json_file)

    print(f"üìÑ R√©szletes elemz√©s: {txt_file}")

    # Read TXT file
    with open(txt_path, 'r', encoding='utf-8') as f:
        txt_lines = f.readlines()

    print(f"üìä TXT sorok sz√°ma: {len(txt_lines)}")

    # Analyze TXT patterns
    team_vs_patterns = []
    time_patterns = []
    odds_patterns = []
    other_lines = []

    for i, line in enumerate(txt_lines[:50]):  # First 50 lines
        line = line.strip()
        if not line:
            continue

        # Check for team vs team pattern
        if ' vs ' in line.lower() or ' - ' in line:
            team_vs_patterns.append((i, line))
        # Check for time pattern
        elif re.search(r'\d{1,2}:\d{2}', line):
            time_patterns.append((i, line))
        # Check for odds pattern (decimal numbers)
        elif re.search(r'\d+\.\d+', line):
            odds_patterns.append((i, line))
        else:
            other_lines.append((i, line))

    print(f"\nüìà TXT PATTERN ELEMZ√âS (els≈ë 50 sor):")
    print(f"   Team vs Team pattern: {len(team_vs_patterns)}")
    print(f"   Time patterns: {len(time_patterns)}")
    print(f"   Odds patterns: {len(odds_patterns)}")
    print(f"   Other lines: {len(other_lines)}")

    print(f"\nüìù P√âLDA SOROK:")
    print(f"Team vs Team mint√°k:")
    for i, (line_num, line) in enumerate(team_vs_patterns[:3]):
        print(f"   {line_num}: {line}")

    print(f"Time mint√°k:")
    for i, (line_num, line) in enumerate(time_patterns[:3]):
        print(f"   {line_num}: {line}")

    print(f"Odds mint√°k:")
    for i, (line_num, line) in enumerate(odds_patterns[:3]):
        print(f"   {line_num}: {line}")

    print(f"Other sorok:")
    for i, (line_num, line) in enumerate(other_lines[:3]):
        print(f"   {line_num}: {line}")

    # Read JSON file
    with open(json_path, 'r', encoding='utf-8') as f:
        json_data = json.load(f)

    json_matches = json_data.get('matches', [])
    print(f"\nüìä JSON meccsek sz√°ma: {len(json_matches)}")

    # Analyze JSON content
    competition_counts = Counter()
    league_counts = Counter()
    market_counts = []

    for match in json_matches:
        competition_counts[match.get('competition')] += 1
        league_counts[match.get('league')] += 1
        market_counts.append(len(match.get('markets', [])))

    print(f"\nüìà JSON TARTALOM ELEMZ√âS:")
    print(f"   Competition √©rt√©kek:")
    for comp, count in competition_counts.most_common(5):
        print(f"      '{comp}': {count}")

    print(f"   League √©rt√©kek:")
    for league, count in league_counts.most_common(5):
        print(f"      '{league}': {count}")

    print(f"   Piacok sz√°ma (statisztika):")
    print(f"      Min: {min(market_counts) if market_counts else 0}")
    print(f"      Max: {max(market_counts) if market_counts else 0}")
    print(f"      √Åtlag: {sum(market_counts)/len(market_counts) if market_counts else 0:.1f}")

    return len(txt_lines), len(json_matches)

def analyze_database_vs_json():
    """Elemzi a database √©s JSON k√∂z√∂tti kapcsolatot"""
    print(f"\nüîç DATABASE vs JSON ELEMZ√âS")
    print("=" * 50)

    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()

        # Get DB counts
        cur.execute("SELECT COUNT(*) FROM matches")
        db_matches = cur.fetchone()[0]

        cur.execute("SELECT COUNT(*) FROM markets")
        db_markets = cur.fetchone()[0]

        cur.execute("SELECT COUNT(*) FROM odds")
        db_odds = cur.fetchone()[0]

        print(f"üìä Database statisztik√°k:")
        print(f"   Meccsek: {db_matches}")
        print(f"   Piacok: {db_markets}")
        print(f"   Odds: {db_odds}")

        # Check for duplicate detection in DB
        cur.execute("""
            SELECT
                m.date::date,
                ht.name as home_team,
                at.name as away_team,
                c.name as competition,
                COUNT(*) as count
            FROM matches m
            LEFT JOIN teams ht ON ht.id = m."homeTeamId"
            LEFT JOIN teams at ON at.id = m."awayTeamId"
            LEFT JOIN competitions c ON c.id = m."competitionId"
            GROUP BY m.date::date, ht.name, at.name, c.name
            HAVING COUNT(*) > 1
            ORDER BY count DESC
            LIMIT 5
        """)

        db_duplicates = cur.fetchall()

        if db_duplicates:
            print(f"\n‚ö†Ô∏è DB-ben tal√°lt duplik√°tumok:")
            for dup in db_duplicates:
                print(f"   {dup[0]} {dup[1]} vs {dup[2]} ({dup[3]}): {dup[4]} p√©ld√°ny")
        else:
            print(f"\n‚úÖ Nincsenek duplik√°tumok a DB-ben")

        # Get sample matches to see what got imported
        cur.execute("""
            SELECT
                m.date::date,
                ht.name as home_team,
                at.name as away_team,
                c.name as competition,
                COUNT(mk.id) as market_count
            FROM matches m
            LEFT JOIN teams ht ON ht.id = m."homeTeamId"
            LEFT JOIN teams at ON at.id = m."awayTeamId"
            LEFT JOIN competitions c ON c.id = m."competitionId"
            LEFT JOIN markets mk ON mk."matchId" = m.id
            GROUP BY m.id, m.date, ht.name, at.name, c.name
            ORDER BY m.date
            LIMIT 10
        """)

        sample_matches = cur.fetchall()

        print(f"\nüìù Minta meccsek a DB-ben:")
        for match in sample_matches:
            print(f"   {match[0]} {match[1]} vs {match[2]} ({match[3]}) - {match[4]} piac")

        cur.close()
        conn.close()

    except Exception as e:
        print(f"‚ùå Database hiba: {e}")

def main():
    print("=" * 70)
    print("SP3 R√âSZLETES ANOM√ÅLIA √âS DUPLIK√ÅCI√ì ELEMZ√âS")
    print("=" * 70)

    # 1. JSON duplik√°ci√≥ elemz√©s
    total_json, unique_json, duplicated_json = analyze_json_duplicates()

    # 2. TXT vs JSON k√ºl√∂nbs√©g elemz√©s
    txt_lines, json_matches = analyze_txt_vs_json_difference()

    # 3. Database vs JSON elemz√©s
    analyze_database_vs_json()

    print(f"\nüìã √ñSSZEGZ√âS")
    print("=" * 50)
    print(f"üìä JSON √∂sszesen: {total_json} meccs")
    print(f"üìä JSON egyedi: {unique_json} meccs")
    print(f"üìä JSON duplik√°lt: {duplicated_json} match ID")
    print(f"üìä TXT sorok: {txt_lines}")
    print(f"üìä JSON meccsek (sample): {json_matches}")

    conversion_rate = (json_matches / txt_lines * 100) if txt_lines > 0 else 0
    duplication_rate = ((total_json - unique_json) / total_json * 100) if total_json > 0 else 0

    print(f"üìà TXT‚ÜíJSON konverzi√≥s r√°ta: {conversion_rate:.1f}%")
    print(f"üìà JSON duplik√°ci√≥s r√°ta: {duplication_rate:.1f}%")

if __name__ == '__main__':
    main()
